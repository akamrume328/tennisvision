{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc77a65d",
   "metadata": {},
   "source": [
    "# データ準備とYOLOv8用データセット構築\n",
    "\n",
    "このノートブックは、YOLOv8モデルのトレーニングに使用するデータセットを準備するプロセスをガイドします。以下のステップを実行します。\n",
    "\n",
    "1.  **動画からのフレーム抽出**: 指定されたディレクトリ内の動画ファイルからフレームを抽出します。\n",
    "2.  **アノテーションの準備**: 抽出されたフレームにアノテーションを付けるための準備とガイダンスを提供します。\n",
    "3.  **データセットの分割**: アノテーション済みの画像とラベルを、訓練セット、検証セット、およびオプションでテストセットに分割します。\n",
    "4.  **`data.yaml` の生成**: YOLOv8がトレーニングに必要なデータセット構成ファイル (`data.yaml`) を生成します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256755c5",
   "metadata": {},
   "source": [
    "## 1. ライブラリのインポート\n",
    "\n",
    "まず、必要なPythonライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4dfddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"ライブラリが正常にインポートされました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a21f43",
   "metadata": {},
   "source": [
    "## 2. 設定\n",
    "\n",
    "データ処理に必要なパスとパラメータを設定します。\n",
    "\n",
    "- `RAW_VIDEO_DIR`: フレームを抽出する元の動画ファイルが格納されているディレクトリ。\n",
    "- `DATASET_BASE_DIR`: 処理済みデータセット（抽出されたフレーム、アノテーションファイル、分割済みデータセット、`data.yaml`）が保存されるベースディレクトリ。\n",
    "- `FRAME_WIDTH`, `FRAME_HEIGHT`: 抽出するフレームの幅と高さ。YOLOv8の入力サイズに合わせて調整します。\n",
    "- `FRAME_RATE`: 動画から抽出するフレームのレート（1秒あたりのフレーム数）。`None` の場合は動画のオリジナルFPSを使用。\n",
    "- `CLASS_NAMES`: データセット内のクラス名リスト。`data.yaml` に記述されます。\n",
    "- `TRAIN_RATIO`, `VAL_RATIO`: データセットを訓練セットと検証セットに分割する際の比率。残りがテストセットになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c31095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 設定項目 ---\n",
    "\n",
    "# 入力動画ディレクトリ (例: '../data/raw_videos/')\n",
    "RAW_VIDEO_DIR = '../data/raw/' \n",
    "\n",
    "# データセットのベースディレクトリ (例: '../data/yolo_dataset/')\n",
    "# このディレクトリ以下に images, labels, train, val, test フォルダが作成されます。\n",
    "DATASET_BASE_DIR = '../data/processed/yolo_prepared_dataset/'\n",
    "\n",
    "# フレームサイズ\n",
    "FRAME_WIDTH = 640\n",
    "FRAME_HEIGHT = 480\n",
    "\n",
    "# フレームレート (None の場合、動画のオリジナルFPSを使用)\n",
    "# 特定のFPSで抽出したい場合は数値を指定 (例: 10)\n",
    "FRAME_RATE_EXTRACTION = None \n",
    "\n",
    "# クラス名 (data.yaml用) - プロジェクトに合わせて変更してください\n",
    "CLASS_NAMES = ['player', 'ball', 'net'] # 例\n",
    "\n",
    "# データ分割比率\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "# TEST_RATIO は (1.0 - TRAIN_RATIO - VAL_RATIO) で自動計算されます\n",
    "\n",
    "# --- 設定項目ここまで ---\n",
    "\n",
    "# パスオブジェクトの作成\n",
    "raw_video_path = Path(RAW_VIDEO_DIR)\n",
    "dataset_base_path = Path(DATASET_BASE_DIR)\n",
    "extracted_images_path = dataset_base_path / 'images' # 抽出された全フレームを一時的に保存\n",
    "extracted_labels_path = dataset_base_path / 'labels' # アノテーションファイルを保存する場所\n",
    "\n",
    "# 必要なディレクトリを作成\n",
    "extracted_images_path.mkdir(parents=True, exist_ok=True)\n",
    "extracted_labels_path.mkdir(parents=True, exist_ok=True) # アノテーション用\n",
    "\n",
    "print(f\"入力動画ディレクトリ: {raw_video_path.resolve()}\")\n",
    "print(f\"データセットベースディレクトリ: {dataset_base_path.resolve()}\")\n",
    "print(f\"抽出フレーム保存先: {extracted_images_path.resolve()}\")\n",
    "print(f\"アノテーションファイル保存先 (期待される場所): {extracted_labels_path.resolve()}\")\n",
    "print(f\"フレームサイズ: {FRAME_WIDTH}x{FRAME_HEIGHT}\")\n",
    "if FRAME_RATE_EXTRACTION:\n",
    "    print(f\"フレーム抽出レート: {FRAME_RATE_EXTRACTION} fps\")\n",
    "else:\n",
    "    print(\"フレーム抽出レート: オリジナル動画のFPSを使用\")\n",
    "print(f\"クラス名: {CLASS_NAMES}\")\n",
    "print(f\"訓練セット比率: {TRAIN_RATIO}, 検証セット比率: {VAL_RATIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d94d4e",
   "metadata": {},
   "source": [
    "## 3. 動画からのフレーム抽出\n",
    "\n",
    "指定された `RAW_VIDEO_DIR` 内のすべての動画ファイル（.mp4, .avi, .mov, .mkv）からフレームを抽出します。\n",
    "抽出されたフレームはリサイズされ、`DATASET_BASE_DIR/images/` ディレクトリに `videoName_frame_XXXXXX.png` の形式で保存されます。\n",
    "\n",
    "**注意:** `ffmpeg` がシステムにインストールされ、PATHが通っている必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_videos(video_dir, output_image_dir, width, height, fps=None):\n",
    "    \"\"\"\n",
    "    動画ディレクトリからフレームを抽出し、指定されたサイズにリサイズして保存する。\n",
    "\n",
    "    Args:\n",
    "        video_dir (Path): 動画ファイルが格納されているディレクトリ。\n",
    "        output_image_dir (Path): 抽出されたフレームを保存するディレクトリ。\n",
    "        width (int): フレームの幅。\n",
    "        height (int): フレームの高さ。\n",
    "        fps (int, optional): 抽出するフレームレート。Noneの場合はオリジナルFPS。\n",
    "    \"\"\"\n",
    "    video_files = [f for f in video_dir.iterdir() if f.is_file() and f.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv']]\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"{video_dir} に動画ファイルが見つかりませんでした。\")\n",
    "        return\n",
    "\n",
    "    print(f\"{len(video_files)} 本の動画ファイルを処理します...\")\n",
    "\n",
    "    for video_file in tqdm(video_files, desc=\"動画処理中\"):\n",
    "        video_name = video_file.stem\n",
    "        \n",
    "        # ffmpeg コマンドの構築\n",
    "        command = [\n",
    "            'ffmpeg',\n",
    "            '-i', str(video_file),\n",
    "            '-vf', f'scale={width}:{height}' + (f',fps={fps}' if fps else ''),\n",
    "            '-qscale:v', '2',  # 高画質でフレームを抽出\n",
    "            str(output_image_dir / f'{video_name}_frame_%06d.png')\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # ffmpegコマンドの標準出力と標準エラー出力を抑制する\n",
    "            process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout, stderr = process.communicate()\n",
    "            if process.returncode != 0:\n",
    "                print(f\"動画 {video_file.name} の処理中にffmpegエラーが発生しました。\")\n",
    "                print(f\"コマンド: {' '.join(command)}\")\n",
    "                print(f\"エラー出力: {stderr.decode('utf-8', errors='ignore')}\")\n",
    "                continue # 次の動画へ\n",
    "            # print(f\"動画 {video_file.name} からフレームを抽出しました。\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"エラー: ffmpeg コマンドが見つかりません。ffmpegがインストールされ、PATHが通っていることを確認してください。\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"動画 {video_file.name} の処理中に予期せぬエラーが発生しました: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"全動画のフレーム抽出が完了しました。フレームは {output_image_dir} に保存されています。\")\n",
    "\n",
    "# フレーム抽出の実行\n",
    "extract_frames_from_videos(raw_video_path, extracted_images_path, FRAME_WIDTH, FRAME_HEIGHT, FRAME_RATE_EXTRACTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3953a",
   "metadata": {},
   "source": [
    "## 4. フレームのアノテーション\n",
    "\n",
    "フレームの抽出が完了したら、次にこれらのフレームにアノテーションを付ける必要があります。\n",
    "アノテーションは、画像内のオブジェクトの位置とクラスを定義する作業です。\n",
    "\n",
    "**アノテーションツール:**\n",
    "[LabelImg](https://github.com/HumanSignal/labelImg), [CVAT](https://github.com/cvat-ai/cvat), [Label Studio](https://labelstud.io/) などのアノテーションツールを使用できます。\n",
    "これらのツールは、YOLO形式でのアノテーションエクスポートをサポートしています。\n",
    "\n",
    "**YOLOアノテーション形式:**\n",
    "各画像に対して、同じ名前（拡張子を除く）の `.txt` ファイルを作成します。例えば、`my_video_frame_000001.png` のアノテーションは `my_video_frame_000001.txt` になります。\n",
    "各 `.txt` ファイルには、画像内のオブジェクトごとに1行の記述が含まれます。\n",
    "各行の形式は次のとおりです: `<class_id> <x_center_norm> <y_center_norm> <width_norm> <height_norm>`\n",
    "- `<class_id>`: オブジェクトのクラスを示す整数（0から始まるインデックス）。これは `CLASS_NAMES` リストのインデックスに対応します。\n",
    "- `<x_center_norm>`, `<y_center_norm>`: オブジェクトのバウンディングボックスの中心のx座標とy座標（画像の幅と高さで正規化された値、0から1の範囲）。\n",
    "- `<width_norm>`, `<height_norm>`: オブジェクトのバウンディングボックスの幅と高さ（画像の幅と高さで正規化された値、0から1の範囲）。\n",
    "\n",
    "**手順:**\n",
    "1.  上記で設定した `extracted_images_path` (`{DATASET_BASE_DIR}/images/`) にあるフレームに対してアノテーションを行います。\n",
    "2.  生成された `.txt` アノテーションファイルを、`extracted_labels_path` (`{DATASET_BASE_DIR}/labels/`) に保存します。\n",
    "    各画像ファイル（例: `frame_001.png`）に対して、対応するラベルファイル（例: `frame_001.txt`）が同じディレクトリ構造で保存されるようにしてください。\n",
    "\n",
    "**このノートブックの次のセルに進む前に、すべてのアノテーション作業を完了し、ラベルファイルを正しい場所に保存してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e70f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーションが完了したことを確認するための簡単なチェック\n",
    "# extracted_labels_path に .txt ファイルが存在するかどうかを確認します。\n",
    "\n",
    "label_files = [f for f in extracted_labels_path.iterdir() if f.is_file() and f.suffix.lower() == '.txt']\n",
    "image_files_for_check = [f for f in extracted_images_path.iterdir() if f.is_file() and f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "\n",
    "if not image_files_for_check:\n",
    "    print(f\"警告: {extracted_images_path} に画像ファイルが見つかりません。フレーム抽出が正しく行われたか確認してください。\")\n",
    "elif not label_files:\n",
    "    print(f\"警告: {extracted_labels_path} にアノテーションファイル (.txt) が見つかりません。\")\n",
    "    print(\"アノテーション作業を完了し、ラベルファイルを上記のディレクトリに保存してください。\")\n",
    "else:\n",
    "    print(f\"{extracted_labels_path} に {len(label_files)} 個のアノテーションファイルが見つかりました。\")\n",
    "    # 画像ファイルとラベルファイルの対応関係を一部チェック (オプション)\n",
    "    missing_labels = 0\n",
    "    for img_f in image_files_for_check[:min(len(image_files_for_check), 5)] : # 最初の5件でチェック\n",
    "        expected_label_f = extracted_labels_path / (img_f.stem + \".txt\")\n",
    "        if not expected_label_f.exists():\n",
    "            missing_labels +=1\n",
    "            print(f\"  - 画像 {img_f.name} に対応するラベルファイル {expected_label_f.name} が見つかりません。\")\n",
    "    if missing_labels == 0 and image_files_for_check:\n",
    "         print(\"基本的な画像とラベルのペアリングは問題なさそうです（最初の数件で確認）。\")\n",
    "\n",
    "print(f\"\n",
    "アノテーションが完了したら、次の「データセットの分割と data.yaml の生成」セルを実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b1fff",
   "metadata": {},
   "source": [
    "## 5. データセットの分割と `data.yaml` の生成\n",
    "\n",
    "アノテーション済みの画像とラベルを、訓練 (train)、検証 (val)、およびオプションでテスト (test) セットに分割します。\n",
    "その後、YOLOv8がデータセットの場所とクラス情報を知るために必要な `data.yaml` ファイルを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedafa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_organize_dataset(base_dir, images_source_dir, labels_source_dir, \n",
    "                               train_ratio=0.7, val_ratio=0.15, class_names=None, data_yaml_filename='data.yaml'):\n",
    "    \"\"\"\n",
    "    画像とラベルを train/val/test セットに分割し、YOLO形式のディレクトリ構造を構築し、data.yaml を生成する。\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)\n",
    "    images_source_dir = Path(images_source_dir)\n",
    "    labels_source_dir = Path(labels_source_dir)\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = ['object'] # デフォルト\n",
    "\n",
    "    # 新しいディレクトリ構造のパスを定義\n",
    "    train_images_dir = base_dir / 'train' / 'images'\n",
    "    train_labels_dir = base_dir / 'train' / 'labels'\n",
    "    val_images_dir = base_dir / 'val' / 'images'\n",
    "    val_labels_dir = base_dir / 'val' / 'labels'\n",
    "    test_images_dir = base_dir / 'test' / 'images'\n",
    "    test_labels_dir = base_dir / 'test' / 'labels'\n",
    "\n",
    "    # ディレクトリを作成\n",
    "    for d in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir, test_images_dir, test_labels_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 画像ファイルを取得\n",
    "    image_files = [f for f in images_source_dir.iterdir() if f.is_file() and f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "    if not image_files:\n",
    "        print(f\"エラー: {images_source_dir} に画像ファイルが見つかりません。\")\n",
    "        return\n",
    "\n",
    "    dataset_pairs = []\n",
    "    for img_path in image_files:\n",
    "        label_filename = img_path.stem + '.txt'\n",
    "        label_path = labels_source_dir / label_filename\n",
    "        if label_path.exists():\n",
    "            dataset_pairs.append((img_path, label_path))\n",
    "        else:\n",
    "            print(f\"警告: 画像 {img_path.name} に対応するラベルファイル {label_path.name} が {labels_source_dir} に見つかりません。スキップします。\")\n",
    "\n",
    "    if not dataset_pairs:\n",
    "        print(\"エラー: 有効な画像とラベルのペアが見つかりませんでした。\")\n",
    "        return\n",
    "\n",
    "    random.shuffle(dataset_pairs)\n",
    "    total_pairs = len(dataset_pairs)\n",
    "    train_end_idx = int(total_pairs * train_ratio)\n",
    "    val_end_idx = train_end_idx + int(total_pairs * val_ratio)\n",
    "\n",
    "    train_pairs = dataset_pairs[:train_end_idx]\n",
    "    val_pairs = dataset_pairs[train_end_idx:val_end_idx]\n",
    "    test_pairs = dataset_pairs[val_end_idx:]\n",
    "\n",
    "    def move_pairs(pairs, target_img_dir, target_lbl_dir, set_name):\n",
    "        if not pairs:\n",
    "            print(f\"{set_name} セットにはファイルがありません。\")\n",
    "            return\n",
    "        print(f\"{len(pairs)} ペアを {set_name} セットに移動中...\")\n",
    "        for img_path, lbl_path in tqdm(pairs, desc=f\"{set_name} セット移動\"):\n",
    "            try:\n",
    "                shutil.copy(str(img_path), str(target_img_dir / img_path.name)) # copyの代わりにmoveも可\n",
    "                shutil.copy(str(lbl_path), str(target_lbl_dir / lbl_path.name)) # copyの代わりにmoveも可\n",
    "            except Exception as e:\n",
    "                print(f\"ファイル移動エラー ({img_path.name} または {lbl_path.name}): {e}\")\n",
    "    \n",
    "    move_pairs(train_pairs, train_images_dir, train_labels_dir, \"訓練\")\n",
    "    move_pairs(val_pairs, val_images_dir, val_labels_dir, \"検証\")\n",
    "    move_pairs(test_pairs, test_images_dir, test_labels_dir, \"テスト\")\n",
    "    \n",
    "    # data.yaml の作成\n",
    "    data_yaml_path = base_dir / data_yaml_filename\n",
    "    \n",
    "    # base_dir からの相対パスで記述\n",
    "    # YOLOv8の ultralytics ライブラリは、data.yaml 内のパスを data.yaml ファイル自身の場所からの相対パスとして解釈することが多い。\n",
    "    # そのため、'../train/images' のような形式ではなく、data.yaml が dataset_base_dir にある場合、\n",
    "    # 'train/images' のように記述する。\n",
    "    # `path` ディレクティブは data.yaml の親ディレクトリを指すように設定する。\n",
    "    \n",
    "    data_config = {\n",
    "        'path': str(base_dir.resolve()), # データセットのルートパス (絶対パスを推奨)\n",
    "        'train': str((train_images_dir).relative_to(base_dir)), #'train/images', \n",
    "        'val': str((val_images_dir).relative_to(base_dir)), #'val/images',\n",
    "        'nc': len(class_names),\n",
    "        'names': class_names\n",
    "    }\n",
    "    if test_pairs: # テストセットが実際に作成された場合\n",
    "        data_config['test'] = str((test_images_dir).relative_to(base_dir)) #'test/images'\n",
    "    \n",
    "    try:\n",
    "        with open(data_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f, sort_keys=False, default_flow_style=None)\n",
    "        print(f\"{data_yaml_path} を作成/更新しました。\")\n",
    "        print(\"--- data.yaml の内容 ---\")\n",
    "        print(yaml.dump(data_config, sort_keys=False, default_flow_style=None))\n",
    "        print(\"------------------------\")\n",
    "    except Exception as e:\n",
    "        print(f\"エラー: {data_yaml_path} の書き込みに失敗しました: {e}\")\n",
    "\n",
    "    print(\"データセットの分割と data.yaml の生成が完了しました。\")\n",
    "    print(f\"訓練データ: {train_images_dir}, {train_labels_dir}\")\n",
    "    print(f\"検証データ: {val_images_dir}, {val_labels_dir}\")\n",
    "    if test_pairs:\n",
    "        print(f\"テストデータ: {test_images_dir}, {test_labels_dir}\")\n",
    "    else:\n",
    "        print(\"テストセットは作成されませんでした。\")\n",
    "\n",
    "# データセット分割と data.yaml 生成の実行\n",
    "# extracted_images_path と extracted_labels_path は、アノテーション済みの全画像と全ラベルが格納されている場所\n",
    "split_and_organize_dataset(\n",
    "    dataset_base_path, \n",
    "    extracted_images_path, \n",
    "    extracted_labels_path,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    class_names=CLASS_NAMES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e32ab",
   "metadata": {},
   "source": [
    "## 6. まとめと次のステップ\n",
    "\n",
    "このノートブックでは、以下の処理を行いました。\n",
    "1.  元の動画からフレームを抽出し、指定されたサイズにリサイズして `{DATASET_BASE_DIR}/images/` に保存しました。\n",
    "2.  抽出されたフレームに対するアノテーションの実施方法と、アノテーションファイル (`.txt`) を `{DATASET_BASE_DIR}/labels/` に保存するよう指示しました。\n",
    "3.  アノテーション済みの画像とラベルを、訓練・検証・テストセットに分割し、YOLOv8が要求するディレクトリ構造 (`{DATASET_BASE_DIR}/train/`, `{DATASET_BASE_DIR}/val/`, `{DATASET_BASE_DIR}/test/`) に整理しました。\n",
    "4.  YOLOv8のトレーニングに必要な `data.yaml` ファイルを `{DATASET_BASE_DIR}/` に生成しました。\n",
    "\n",
    "**次のステップ:**\n",
    "これで、YOLOv8モデルのトレーニングを開始する準備が整いました。\n",
    "生成された `data.yaml` ファイルのパスをトレーニングスクリプトまたはノートブックに指定して、モデルのトレーニングを実行してください。\n",
    "\n",
    "**生成されたディレクトリ構造の確認:**\n",
    "`{DATASET_BASE_DIR}` ディレクトリを開き、以下の構造になっていることを確認してください。\n",
    "```\n",
    "{DATASET_BASE_DIR}/\n",
    "├── data.yaml\n",
    "├── images/              # (オプション: 元の全抽出フレーム、分割後は空でも良い)\n",
    "│   ├── video1_frame_000001.png\n",
    "│   └── ...\n",
    "├── labels/              # (オプション: 元の全アノテーション、分割後は空でも良い)\n",
    "│   ├── video1_frame_000001.txt\n",
    "│   └── ...\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   │   └── ... (訓練用画像)\n",
    "│   └── labels/\n",
    "│       └── ... (訓練用ラベル)\n",
    "├── val/\n",
    "│   ├── images/\n",
    "│   │   └── ... (検証用画像)\n",
    "│   └── labels/\n",
    "│       └── ... (検証用ラベル)\n",
    "└── test/  (オプション)\n",
    "    ├── images/\n",
    "    │   └── ... (テスト用画像)\n",
    "    └── labels/\n",
    "        └── ... (テスト用ラベル)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
