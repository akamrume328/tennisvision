{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルのトレーニング (YOLOv8 Ultralytics)\n",
    "\n",
    "このノートブックは、準備されたデータセット (`data.yaml` を使用) を用いて、Ultralytics YOLOv8モデルをトレーニングします。\n",
    "\n",
    "**主なステップ:**\n",
    "1.  **必要なライブラリのインポート:** `ultralytics` をインポートします。\n",
    "2.  **設定の定義:** `data.yaml` ファイルのパス、使用するYOLOv8モデルのバリアント (例: `yolov8n.pt`)、エポック数、画像サイズなどを設定します。\n",
    "3.  **モデルのトレーニング:** YOLOオブジェクトの `train()` メソッドを呼び出してトレーニングを実行します。\n",
    "4.  **結果の確認:** トレーニング結果 (重みファイルやログなど) は、通常 `runs/detect/train` のようなディレクトリに保存されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch # PyTorchのインポートも念のため残しておきます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス: cuda\n",
      "data.yaml を使用します: c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\data\\processed\\dataset\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# --- トレーニング設定 ---\n",
    "\n",
    "# data.yaml ファイルへのパス\n",
    "# 前のノートブック (3_dataset_preparation_for_yolo.ipynb) で生成されたものを指定します。\n",
    "# 例: '../data/processed/tennis_dataset_yolo_prepared/data.yaml'\n",
    "DATA_YAML_PATH = '../data/processed/dataset/data.yaml' \n",
    "\n",
    "# 使用するYOLOv8モデルの事前学習済みウェイト\n",
    "# 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt' など\n",
    "# または、カスタムモデルの場合は .pt ファイルへのパス\n",
    "MODEL_VARIANT = 'yolov8s.pt'\n",
    "\n",
    "# トレーニングのエポック数\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# トレーニング時の入力画像サイズ\n",
    "IMAGE_SIZE = 1280\n",
    "\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 16 # GPUメモリに応じて調整してください\n",
    "\n",
    "# トレーニング結果が保存されるプロジェクト名 (runs/detect/PROJECT_NAME になる)\n",
    "PROJECT_NAME = 'tennis_detection_project'\n",
    "# トレーニング実行名 (runs/detect/PROJECT_NAME/RUN_NAME になる)\n",
    "RUN_NAME = 'exp1'\n",
    "\n",
    "# GPUを使用するかどうか (利用可能であれば自動的に使用されます)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"使用デバイス: {DEVICE}\")\n",
    "\n",
    "# data.yaml の存在確認\n",
    "if not os.path.exists(DATA_YAML_PATH):\n",
    "    print(f\"警告: data.yaml が見つかりません: {os.path.abspath(DATA_YAML_PATH)}\")\n",
    "    print(\"前のノートブックで data.yaml を生成したか、パスが正しいか確認してください。\")\n",
    "else:\n",
    "    print(f\"data.yaml を使用します: {os.path.abspath(DATA_YAML_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YOLOv8モデルの初期化とトレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "トレーニングを開始します...\n",
      "New https://pypi.org/project/ultralytics/8.3.140 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.139  Python-3.10.11 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/processed/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=exp13, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=tennis_detection_project, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=tennis_detection_project\\exp13, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\akama\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 11.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2118370  ultralytics.nn.modules.head.Detect           [6, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,137,922 parameters, 11,137,906 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 43.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "トレーニング中にエラーが発生しました: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from C:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\data\\processed\\dataset\\train\\images\n",
      "See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\data\\base.py\", line 175, in get_img_files\n",
      "    assert im_files, f\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\n",
      "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found in C:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\data\\processed\\dataset\\train\\images. Supported formats are:\n",
      "images: {'webp', 'heic', 'jpg', 'tif', 'png', 'dng', 'pfm', 'jpeg', 'tiff', 'bmp', 'mpo'}\n",
      "videos: {'mov', 'mpeg', 'asf', 'avi', 'mpg', 'mkv', 'wmv', 'mp4', 'ts', 'webm', 'gif', 'm4v'}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akama\\AppData\\Local\\Temp\\ipykernel_11328\\3299308150.py\", line 9, in <module>\n",
      "    results = model.train(\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 793, in train\n",
      "    self.trainer.train()\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 211, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 332, in _do_train\n",
      "    self._setup_train(world_size)\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 291, in _setup_train\n",
      "    self.train_loader = self.get_dataloader(\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py\", line 82, in get_dataloader\n",
      "    dataset = self.build_dataset(dataset_path, mode, batch_size)\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py\", line 65, in build_dataset\n",
      "    return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == \"val\", stride=gs)\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\data\\build.py\", line 109, in build_yolo_dataset\n",
      "    return dataset(\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\data\\dataset.py\", line 87, in __init__\n",
      "    super().__init__(*args, channels=self.data[\"channels\"], **kwargs)\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\data\\base.py\", line 112, in __init__\n",
      "    self.im_files = self.get_img_files(self.img_path)\n",
      "  File \"c:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\venv\\lib\\site-packages\\ultralytics\\data\\base.py\", line 177, in get_img_files\n",
      "    raise FileNotFoundError(f\"{self.prefix}Error loading data from {img_path}\\n{HELP_URL}\") from e\n",
      "FileNotFoundError: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from C:\\Users\\akama\\AppData\\Local\\Programs\\Python\\Python310\\python_file\\projects\\tennisvision\\data\\processed\\dataset\\train\\images\n",
      "See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    }
   ],
   "source": [
    "# YOLOモデルをロード (事前学習済みウェイトを使用)\n",
    "# MODEL_VARIANT が .pt ファイルへのパスでない場合、Ultralyticsが自動的にダウンロードします。\n",
    "model = YOLO(MODEL_VARIANT)\n",
    "\n",
    "# モデルをトレーニング\n",
    "if os.path.exists(DATA_YAML_PATH):\n",
    "    print(\"\\nトレーニングを開始します...\")\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=DATA_YAML_PATH,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            imgsz=IMAGE_SIZE,\n",
    "            batch=BATCH_SIZE,\n",
    "            project=PROJECT_NAME,\n",
    "            name=RUN_NAME,\n",
    "            device=DEVICE, # 明示的にデバイスを指定\n",
    "            # patience=10, # Early stopping の設定 (オプション)\n",
    "            # workers=8,   # データローダーのワーカー数 (オプション)\n",
    "            # verbose=True # 詳細なログ出力 (デフォルトはTrue)\n",
    "        )\n",
    "        print(\"\\nトレーニングが完了しました。\")\n",
    "        print(f\"結果は {results.save_dir} に保存されました。\")\n",
    "        print(f\"最適な重みは {results.best} に保存されています。\")\n",
    "    except Exception as e:\n",
    "        print(f\"トレーニング中にエラーが発生しました: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"data.yaml が見つからないため、トレーニングをスキップします。パスを確認してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. トレーニング結果の確認と次のステップ\n",
    "\n",
    "トレーニングが正常に完了すると、結果は `runs/detect/<PROJECT_NAME>/<RUN_NAME>` ディレクトリ (例: `runs/detect/tennis_detection_project/exp1`) に保存されます。このディレクトリには以下のものが含まれます:\n",
    "\n",
    "*   **重みファイル (`weights/`):**\n",
    "    *   `best.pt`: 検証セットで最良のパフォーマンスを示したモデルの重み。\n",
    "    *   `last.pt`: 最後のエポック完了時のモデルの重み。\n",
    "*   **結果のプロット:**\n",
    "    *   `results.png`: 損失やメトリクス (mAPなど) のグラフ。\n",
    "    *   `confusion_matrix.png`: 混同行列。\n",
    "    *   その他、検証バッチの予測結果の画像など。\n",
    "*   **ログファイル:**\n",
    "    *   `results.csv`: 各エポックのメトリクスが記録されたCSVファイル。\n",
    "    *   `args.yaml`: トレーニングに使用された設定。\n",
    "\n",
    "**次のステップ:**\n",
    "1.  **結果の評価:** `results.png` や `results.csv` を確認して、モデルの学習進捗や最終的なパフォーマンスを評価します。\n",
    "2.  **推論:** 保存された重みファイル (`best.pt` など) を使用して、新しい画像や動画で物体検出を行います。\n",
    "    ```python\n",
    "    # from ultralytics import YOLO\n",
    "    # model = YOLO('runs/detect/tennis_detection_project/exp1/weights/best.pt')\n",
    "    # results = model.predict(source='path/to/your/image_or_video.mp4', save=True)\n",
    "    ```\n",
    "3.  **ハイパーパラメータ調整:** 必要に応じて、エポック数、学習率 (YOLOv8では通常自動調整)、バッチサイズ、モデルアーキテクチャなどを変更して再トレーニングを行います。\n",
    "\n",
    "**注意:**\n",
    "*   `DATA_YAML_PATH` が正しく設定されていることを確認してください。\n",
    "*   GPUメモリが不足する場合は、`BATCH_SIZE` を小さくするか、`IMAGE_SIZE` を小さくしてみてください。\n",
    "*   トレーニングには時間がかかることがあります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
