import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import joblib

# PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
import cv2

# æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ï¼‰
from train_lstm_model import TennisLSTMModel, setup_gpu_config

# GPUè¨­å®š
DEVICE = setup_gpu_config()
GPU_AVAILABLE = DEVICE.type == 'cuda'

plt.style.use('default')
sns.set_palette("husl")

class TennisLSTMPredictor:
    """
    å­¦ç¿’æ¸ˆã¿PyTorch LSTMãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒ†ãƒ‹ã‚¹å±€é¢åˆ†é¡äºˆæ¸¬ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, model_path: str = None, metadata_path: str = None, 
                 scaler_path: str = None, training_data_dir: str = "training_data"):
        """
        åˆæœŸåŒ–
        
        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (.pth)
            metadata_path: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (.json)
            scaler_path: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (.pkl)
            training_data_dir: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.training_data_dir = Path(training_data_dir)
        self.models_dir = self.training_data_dir / "lstm_models"
        
        # ãƒ¢ãƒ‡ãƒ«é–¢é€£ã®å¤‰æ•°
        self.model = None
        self.scaler = None
        self.metadata = None
        self.phase_labels = []
        self.sequence_length = 30
        self.overlap_ratio = 0.5
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œç´¢ã¾ãŸã¯æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿
        if model_path and metadata_path and scaler_path:
            self.load_model(model_path, metadata_path, scaler_path)
        else:
            self.auto_load_latest_model()
        
        print(f"PyTorch LSTMå±€é¢åˆ†é¡äºˆæ¸¬å™¨ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {DEVICE}")
        print(f"ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {self.sequence_length}ãƒ•ãƒ¬ãƒ¼ãƒ ")
    
    def auto_load_latest_model(self):
        """æœ€æ–°ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œç´¢ã—ã¦èª­ã¿è¾¼ã¿"""
        model_files = list(self.models_dir.glob("tennis_pytorch_model_*.pth"))
        
        if not model_files:
            print("âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("train_lstm_model.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
            return False
        
        # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
        latest_model_file = max(model_files, key=lambda x: x.stat().st_mtime)
        timestamp = latest_model_file.stem.replace("tennis_pytorch_model_", "")
        
        # å¯¾å¿œã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        metadata_file = self.models_dir / f"tennis_pytorch_metadata_{timestamp}.json"
        scaler_file = self.models_dir / f"tennis_pytorch_scaler_{timestamp}.pkl"
        
        if not metadata_file.exists() or not scaler_file.exists():
            print("âŒ å¯¾å¿œã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        print(f"æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿: {latest_model_file.name}")
        return self.load_model(str(latest_model_file), str(metadata_file), str(scaler_file))
    
    def load_model(self, model_path: str, metadata_path: str, scaler_path: str) -> bool:
        """æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            with open(metadata_path, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
            
            # ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’å–å¾—
            self.phase_labels = self.metadata['phase_labels']
            self.sequence_length = self.metadata['sequence_length']
            self.overlap_ratio = self.metadata.get('overlap_ratio', 0.5)
            
            print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {Path(metadata_path).name}")
            print(f"   ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.metadata['model_type']}")
            print(f"   ç²¾åº¦: {self.metadata['test_accuracy']:.4f}")
            print(f"   F1ã‚¹ã‚³ã‚¢: {self.metadata['f1_score']:.4f}")
            print(f"   å±€é¢ãƒ©ãƒ™ãƒ«: {self.phase_labels}")
            
            # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼èª­ã¿è¾¼ã¿
            self.scaler = joblib.load(scaler_path)
            print(f"âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼èª­ã¿è¾¼ã¿: {Path(scaler_path).name}")
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            checkpoint = torch.load(model_path, map_location=DEVICE)
            model_config = checkpoint['model_config']
            
            # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            self.model = TennisLSTMModel(
                input_size=model_config['input_size'],
                hidden_sizes=model_config['hidden_sizes'],
                num_classes=model_config['num_classes'],
                dropout_rate=model_config['dropout_rate'],
                model_type=model_config['model_type']
            )
            
            # çŠ¶æ…‹è¾æ›¸ã‚’èª­ã¿è¾¼ã¿
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model = self.model.to(DEVICE)
            self.model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {Path(model_path).name}")
            print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def predict_from_features(self, features_df: pd.DataFrame, 
                            video_name: str = "unknown") -> Dict[str, Any]:
        """
        ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å±€é¢ã‚’äºˆæ¸¬
        
        Args:
            features_df: ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            video_name: å‹•ç”»åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            äºˆæ¸¬çµæœè¾æ›¸
        """
        if self.model is None:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return {}
        
        print(f"\n=== å±€é¢äºˆæ¸¬å®Ÿè¡Œ ===")
        print(f"å‹•ç”»: {video_name}")
        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(features_df)}")
        
        # ç‰¹å¾´é‡ã‚’æº–å‚™
        exclude_columns = ['label', 'video_name', 'frame_number']
        feature_columns = [col for col in features_df.columns if col not in exclude_columns]
        
        # æ•°å€¤ç‰¹å¾´é‡ã®ã¿ä½¿ç”¨
        numeric_features = features_df[feature_columns].select_dtypes(include=[np.number]).columns
        X_features = features_df[numeric_features].values
        
        print(f"ä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(numeric_features)}")
        
        # ç„¡é™å€¤ã¨NaNã‚’å‡¦ç†
        X_features = np.nan_to_num(X_features, nan=0.0, posinf=1e6, neginf=-1e6)
        
        # æ¨™æº–åŒ–
        X_scaled = self.scaler.transform(X_features)
        
        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆ
        sequences = self.create_sequences_for_prediction(X_scaled)
        
        if len(sequences) == 0:
            print("âŒ äºˆæ¸¬ç”¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return {}
        
        print(f"ä½œæˆã•ã‚ŒãŸã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°: {len(sequences)}")
        
        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        X_tensor = torch.FloatTensor(sequences).to(DEVICE)
        
        # äºˆæ¸¬å®Ÿè¡Œ
        self.model.eval()
        all_predictions = []
        all_probabilities = []
        
        with torch.no_grad():
            # ãƒãƒƒãƒå‡¦ç†ã§äºˆæ¸¬
            batch_size = 64
            for i in range(0, len(X_tensor), batch_size):
                batch = X_tensor[i:i + batch_size]
                
                if GPU_AVAILABLE:
                    with torch.cuda.amp.autocast():
                        outputs = self.model(batch)
                else:
                    outputs = self.model(batch)
                
                probabilities = F.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)
                
                all_predictions.extend(predicted.cpu().numpy())
                all_probabilities.extend(probabilities.cpu().numpy())
        
        # çµæœã‚’ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã«å±•é–‹
        frame_predictions = self.expand_predictions_to_frames(
            all_predictions, all_probabilities, len(features_df)
        )
        
        # çµæœã‚’æ•´ç†
        results = {
            'video_name': video_name,
            'total_frames': len(features_df),
            'sequence_count': len(sequences),
            'frame_predictions': frame_predictions,
            'phase_distribution': self.calculate_phase_distribution(frame_predictions),
            'confidence_stats': self.calculate_confidence_stats(all_probabilities)
        }
        
        print(f"âœ… äºˆæ¸¬å®Œäº†")
        print(f"   ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {results['total_frames']}")
        print(f"   ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°: {results['sequence_count']}")
        
        return results
    
    def create_sequences_for_prediction(self, features: np.ndarray) -> List[np.ndarray]:
        """äºˆæ¸¬ç”¨ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆ"""
        sequences = []
        step_size = max(1, int(self.sequence_length * (1 - self.overlap_ratio)))
        
        for i in range(0, len(features) - self.sequence_length + 1, step_size):
            seq_features = features[i:i + self.sequence_length]
            sequences.append(seq_features)
        
        return sequences
    
    def expand_predictions_to_frames(self, predictions: List[int], 
                                   probabilities: List[np.ndarray], 
                                   total_frames: int) -> List[Dict]:
        """ã‚·ãƒ¼ã‚±ãƒ³ã‚¹äºˆæ¸¬ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã«å±•é–‹"""
        frame_predictions = []
        step_size = max(1, int(self.sequence_length * (1 - self.overlap_ratio)))
        
        # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®äºˆæ¸¬ã‚’é›†è¨ˆ
        frame_votes = [[] for _ in range(total_frames)]
        frame_probs = [[] for _ in range(total_frames)]
        
        for seq_idx, (pred, prob) in enumerate(zip(predictions, probabilities)):
            # ã“ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒå¯¾å¿œã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²
            start_frame = seq_idx * step_size
            end_frame = start_frame + self.sequence_length
            
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†…ã®å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«æŠ•ç¥¨
            for frame_idx in range(start_frame, min(end_frame, total_frames)):
                frame_votes[frame_idx].append(pred)
                frame_probs[frame_idx].append(prob)
        
        # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®æœ€çµ‚äºˆæ¸¬ã‚’æ±ºå®š
        for frame_idx in range(total_frames):
            if frame_votes[frame_idx]:
                # å¤šæ•°æ±ºã§äºˆæ¸¬ã‚’æ±ºå®š
                unique_preds, counts = np.unique(frame_votes[frame_idx], return_counts=True)
                final_pred = unique_preds[np.argmax(counts)]
                
                # ç¢ºç‡ã®å¹³å‡ã‚’è¨ˆç®—
                avg_prob = np.mean(frame_probs[frame_idx], axis=0)
                confidence = np.max(avg_prob)
                
                frame_predictions.append({
                    'frame': frame_idx,
                    'predicted_phase_id': int(final_pred),
                    'predicted_phase_name': self.phase_labels[final_pred],
                    'confidence': float(confidence),
                    'probabilities': avg_prob.tolist(),
                    'vote_count': len(frame_votes[frame_idx])
                })
            else:
                # äºˆæ¸¬ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                frame_predictions.append({
                    'frame': frame_idx,
                    'predicted_phase_id': 0,
                    'predicted_phase_name': self.phase_labels[0],
                    'confidence': 0.0,
                    'probabilities': [0.0] * len(self.phase_labels),
                    'vote_count': 0
                })
        
        return frame_predictions
    
    def calculate_phase_distribution(self, frame_predictions: List[Dict]) -> Dict:
        """å±€é¢åˆ†å¸ƒã‚’è¨ˆç®—"""
        phase_counts = {}
        total_frames = len(frame_predictions)
        
        for pred in frame_predictions:
            phase_name = pred['predicted_phase_name']
            phase_counts[phase_name] = phase_counts.get(phase_name, 0) + 1
        
        phase_distribution = {}
        for phase_name, count in phase_counts.items():
            phase_distribution[phase_name] = {
                'count': count,
                'percentage': (count / total_frames) * 100
            }
        
        return phase_distribution
    
    def calculate_confidence_stats(self, probabilities: List[np.ndarray]) -> Dict:
        """ä¿¡é ¼åº¦çµ±è¨ˆã‚’è¨ˆç®—"""
        confidences = [np.max(prob) for prob in probabilities]
        
        return {
            'mean_confidence': float(np.mean(confidences)),
            'std_confidence': float(np.std(confidences)),
            'min_confidence': float(np.min(confidences)),
            'max_confidence': float(np.max(confidences)),
            'median_confidence': float(np.median(confidences))
        }
    
    def predict_from_csv(self, csv_path: str) -> Dict[str, Any]:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã‚“ã§äºˆæ¸¬"""
        try:
            df = pd.read_csv(csv_path)
            video_name = Path(csv_path).stem
            
            print(f"âœ… CSVèª­ã¿è¾¼ã¿: {csv_path}")
            print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")
            print(f"   ç‰¹å¾´é‡æ•°: {len(df.columns)}")
            
            return self.predict_from_features(df, video_name)
            
        except Exception as e:
            print(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def visualize_predictions(self, results: Dict[str, Any], save_path: str = None):
        """äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–"""
        if not results or 'frame_predictions' not in results:
            print("å¯è¦–åŒ–ã™ã‚‹äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        frame_predictions = results['frame_predictions']
        frames = [pred['frame'] for pred in frame_predictions]
        phase_ids = [pred['predicted_phase_id'] for pred in frame_predictions]
        confidences = [pred['confidence'] for pred in frame_predictions]
        
        fig, axes = plt.subplots(3, 1, figsize=(15, 12))
        
        # å±€é¢äºˆæ¸¬ã®æ™‚ç³»åˆ—è¡¨ç¤º
        axes[0].plot(frames, phase_ids, 'o-', markersize=3, linewidth=1)
        axes[0].set_title(f'Predicted Tennis Phases - {results["video_name"]}')
        axes[0].set_xlabel('Frame Number')
        axes[0].set_ylabel('Phase ID')
        axes[0].set_yticks(range(len(self.phase_labels)))
        axes[0].set_yticklabels(self.phase_labels, rotation=45)
        axes[0].grid(True, alpha=0.3)
        
        # ä¿¡é ¼åº¦ã®æ™‚ç³»åˆ—è¡¨ç¤º
        axes[1].plot(frames, confidences, 'g-', linewidth=1)
        axes[1].set_title('Prediction Confidence')
        axes[1].set_xlabel('Frame Number')
        axes[1].set_ylabel('Confidence')
        axes[1].set_ylim(0, 1)
        axes[1].grid(True, alpha=0.3)
        
        # å±€é¢åˆ†å¸ƒã®æ£’ã‚°ãƒ©ãƒ•
        phase_dist = results['phase_distribution']
        phase_names = list(phase_dist.keys())
        percentages = [phase_dist[name]['percentage'] for name in phase_names]
        
        bars = axes[2].bar(phase_names, percentages, color='skyblue', alpha=0.7)
        axes[2].set_title('Phase Distribution')
        axes[2].set_xlabel('Phase')
        axes[2].set_ylabel('Percentage (%)')
        axes[2].tick_params(axis='x', rotation=45)
        
        # æ£’ã‚°ãƒ©ãƒ•ã«æ•°å€¤ã‚’è¡¨ç¤º
        for bar, pct in zip(bars, percentages):
            height = bar.get_height()
            axes[2].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                        f'{pct:.1f}%', ha='center', va='bottom')
        
        plt.tight_layout()
        
        # ä¿å­˜
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å¯è¦–åŒ–çµæœã‚’ä¿å­˜: {save_path}")
        
        plt.show()
    
    def save_predictions_to_csv(self, results: Dict[str, Any], output_path: str):
        """äºˆæ¸¬çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not results or 'frame_predictions' not in results:
            print("ä¿å­˜ã™ã‚‹äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        df_data = []
        for pred in results['frame_predictions']:
            row = {
                'frame': pred['frame'],
                'predicted_phase_id': pred['predicted_phase_id'],
                'predicted_phase_name': pred['predicted_phase_name'],
                'confidence': pred['confidence'],
                'vote_count': pred['vote_count']
            }
            
            # å„å±€é¢ã®ç¢ºç‡ã‚’è¿½åŠ 
            for i, prob in enumerate(pred['probabilities']):
                row[f'prob_{self.phase_labels[i]}'] = prob
            
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        df.to_csv(output_path, index=False)
        
        print(f"âœ… äºˆæ¸¬çµæœã‚’CSVã«ä¿å­˜: {output_path}")
        print(f"   ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(df)}")
    
    def predict_video_pipeline(self, features_csv_path: str, 
                             output_dir: str = None) -> Dict[str, Any]:
        """å‹•ç”»ã®å®Œå…¨ãªäºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        print("=== ãƒ†ãƒ‹ã‚¹å‹•ç”»å±€é¢äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===")
        
        if output_dir is None:
            output_dir = Path(features_csv_path).parent / "predictions"
        
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # äºˆæ¸¬å®Ÿè¡Œ
        results = self.predict_from_csv(features_csv_path)
        
        if not results:
            print("âŒ äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return {}
        
        # çµæœã‚’è¡¨ç¤º
        print(f"\n=== äºˆæ¸¬çµæœã‚µãƒãƒªãƒ¼ ===")
        print(f"å‹•ç”»: {results['video_name']}")
        print(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {results['total_frames']}")
        print(f"å¹³å‡ä¿¡é ¼åº¦: {results['confidence_stats']['mean_confidence']:.3f}")
        
        print("\nå±€é¢åˆ†å¸ƒ:")
        for phase, stats in results['phase_distribution'].items():
            print(f"  {phase}: {stats['count']}ãƒ•ãƒ¬ãƒ¼ãƒ  ({stats['percentage']:.1f}%)")
        
        # çµæœä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        video_name = results['video_name']
        
        # CSVä¿å­˜
        csv_output_path = output_dir / f"predictions_{video_name}_{timestamp}.csv"
        self.save_predictions_to_csv(results, csv_output_path)
        
        # å¯è¦–åŒ–ä¿å­˜
        viz_output_path = output_dir / f"predictions_viz_{video_name}_{timestamp}.png"
        self.visualize_predictions(results, viz_output_path)
        
        # JSONä¿å­˜ï¼ˆè©³ç´°çµæœï¼‰
        json_output_path = output_dir / f"predictions_detail_{video_name}_{timestamp}.json"
        with open(json_output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… äºˆæ¸¬å®Œäº†ï¼çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        
        return results

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=== ãƒ†ãƒ‹ã‚¹å‹•ç”»å±€é¢åˆ†é¡PyTorch LSTMäºˆæ¸¬ãƒ„ãƒ¼ãƒ« ===")
    
    # äºˆæ¸¬å™¨ã‚’åˆæœŸåŒ–
    try:
        predictor = TennisLSTMPredictor()
    except Exception as e:
        print(f"âŒ äºˆæ¸¬å™¨ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
        return
    
    # ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    training_data_dir = Path("training_data")
    feature_files = list(training_data_dir.glob("tennis_features_dataset_*.csv"))
    
    print(f"\n=== ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª ===")
    print(f"åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«: {len(feature_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    if not feature_files:
        print("âŒ ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("feature_extractor.py ã‚’å®Ÿè¡Œã—ã¦ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„")
        return
    
    for file in feature_files:
        print(f"  - {file.name}")
    
    # æœ€æ–°ã®ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã§äºˆæ¸¬å®Ÿè¡Œ
    latest_feature_file = max(feature_files, key=lambda x: x.stat().st_mtime)
    print(f"\næœ€æ–°ã®ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã§äºˆæ¸¬å®Ÿè¡Œ: {latest_feature_file.name}")
    
    try:
        # äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        results = predictor.predict_video_pipeline(str(latest_feature_file))
        
        if results:
            print(f"\nğŸ‰ äºˆæ¸¬å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            print(f"\nâŒ äºˆæ¸¬å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
