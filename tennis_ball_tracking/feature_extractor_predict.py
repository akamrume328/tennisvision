import json
import pandas as pd
import numpy as np
import os
import glob
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import warnings
from tqdm import tqdm
import numba # â˜… Numbaã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

warnings.filterwarnings('ignore')

class TennisInferenceFeatureExtractor:
    """
    ãƒ†ãƒ‹ã‚¹å‹•ç”»ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ã‹ã‚‰ã€æ¨è«–ç”¨ã®ç‰¹å¾´é‡ã‚’ä½œæˆã™ã‚‹ã‚¯ãƒ©ã‚¹
    ï¼ˆå±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã¯ä½¿ç”¨ã—ãªã„ï¼‰
    """
    
    def __init__(self, inference_data_dir: str = "inference_data", court_data_dir: Optional[str] = None):
        self.inference_data_dir = Path(inference_data_dir)
        self.court_data_dir = Path(court_data_dir) if court_data_dir else None
        self.features_dir = Path("./training_data/predict_features")
        self.features_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°): {self.inference_data_dir}")
        if self.court_data_dir:
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ã‚³ãƒ¼ãƒˆåº§æ¨™): {self.court_data_dir}")
        else:
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ã‚³ãƒ¼ãƒˆåº§æ¨™): æŒ‡å®šãªã— (ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.inference_data_dir}' å†…ã‚’æ¢ç´¢)")
        print(f"ç‰¹å¾´é‡ä¿å­˜å…ˆ: {self.features_dir}")
    
    def load_tracking_features(self, video_name: str = None) -> Dict[str, Dict]:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰"""
        pattern = "tracking_features_*.json"
        if video_name:
            pattern = f"tracking_features_{video_name}_*.json"
        
        tracking_files = list(self.inference_data_dir.glob(pattern))
        
        if not tracking_files:
            print(f"âš ï¸  ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern} in {self.inference_data_dir}")
            return {}
        
        all_tracking = {}
        for file_path in tracking_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                filename_parts = file_path.stem.split('_')
                if len(filename_parts) >= 3:
                    video_key = '_'.join(filename_parts[2:-1])
                else:
                    video_key = file_path.stem
                
                if isinstance(data, dict) and 'metadata' in data and 'frames' in data:
                    all_tracking[video_key] = data
                    print(f"âœ… ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆæ–°å½¢å¼ï¼‰: {file_path.name}")
                    print(f"   å‹•ç”»: {video_key}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(data['frames'])}")
                    if 'frame_skip' in data['metadata']:
                        print(f"   ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {data['metadata']['frame_skip']}")
                elif isinstance(data, list):
                    all_tracking[video_key] = {
                        'metadata': {'frame_skip': 1, 'legacy_format': True},
                        'frames': data
                    }
                    print(f"âœ… ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆæ—§å½¢å¼ï¼‰: {file_path.name}")
                    print(f"   å‹•ç”»: {video_key}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(data)}")
                    print(f"   æ³¨æ„: æ—§å½¢å¼ã®ãŸã‚ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãªã—")
                else:
                    print(f"âš ï¸  ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿å½¢å¼: {file_path.name}")
                    continue
                
            except Exception as e:
                print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
        
        return all_tracking
    
    def load_court_coordinates(self, video_name: str = None) -> Dict[str, Dict]:
        """ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        pattern = "court_coords_*.json"
        if video_name:
            pattern = f"court_coords_{video_name}_*.json"
        
        data_source_dir = self.court_data_dir if self.court_data_dir else self.inference_data_dir
        
        court_files = list(data_source_dir.glob(pattern))
        
        if not court_files:
            print(f"âš ï¸  ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern} in {data_source_dir}")
            return {}
        
        all_court_coords = {}
        for file_path in court_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                filename_parts = file_path.stem.split('_')
                if len(filename_parts) >= 3:
                    video_key = '_'.join(filename_parts[2:])
                else:
                    video_key = file_path.stem
                
                all_court_coords[video_key] = data
                print(f"âœ… ã‚³ãƒ¼ãƒˆåº§æ¨™èª­ã¿è¾¼ã¿: {file_path.name}")
                print(f"   å‹•ç”»: {video_key}")
                
            except Exception as e:
                print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
        
        return all_court_coords
    
    def match_video_data(self, tracking_features: Dict, court_coordinates: Dict = None) -> List[Tuple[str, Dict, Dict]]:
        """å‹•ç”»åã§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ãƒãƒƒãƒãƒ³ã‚°"""
        matched_data = []
        
        print("\n=== ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚° (æ¨è«–ç”¨) ===")
        print(f"ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡å‹•ç”»æ•°: {len(tracking_features)}")
        print(f"ã‚³ãƒ¼ãƒˆåº§æ¨™å‹•ç”»æ•°: {len(court_coordinates) if court_coordinates else 0}")
        
        print("\n--- åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ« ---")
        print("ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡:")
        for key in tracking_features.keys():
            print(f"  - {key}")
        if court_coordinates:
            print("ã‚³ãƒ¼ãƒˆåº§æ¨™:")
            for key in court_coordinates.keys():
                print(f"  - {key}")
        
        print("\n--- ãƒãƒƒãƒãƒ³ã‚°å‡¦ç† ---")
        
        for video_name in tracking_features.keys():
            tracking_data = tracking_features[video_name]
            court_data = None
            court_match_type = "ãªã—"
            court_matched_key = ""
            
            print(f"\nğŸ¯ å‡¦ç†ä¸­: {video_name}")
            
            if court_coordinates:
                if video_name in court_coordinates:
                    court_data = court_coordinates[video_name]
                    court_match_type = "å®Œå…¨ä¸€è‡´"
                    court_matched_key = video_name
                    print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… å®Œå…¨ä¸€è‡´ - {video_name}")
                else:
                    for court_key in court_coordinates.keys():
                        if video_name in court_key:
                            court_data = court_coordinates[court_key]
                            court_match_type = "éƒ¨åˆ†ä¸€è‡´(å‹•ç”»åãŒã‚­ãƒ¼ã«å«ã¾ã‚Œã‚‹)"
                            court_matched_key = court_key
                            print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… éƒ¨åˆ†ä¸€è‡´ - {video_name} âŠ† {court_key}")
                            break
                        elif court_key in video_name:
                            court_data = court_coordinates[court_key]
                            court_match_type = "éƒ¨åˆ†ä¸€è‡´(ã‚­ãƒ¼ãŒå‹•ç”»åã«å«ã¾ã‚Œã‚‹)"
                            court_matched_key = court_key
                            print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… éƒ¨åˆ†ä¸€è‡´ - {court_key} âŠ† {video_name}")
                            break
                    if not court_data:
                        print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âŒ ãƒãƒƒãƒãªã—")
            else:
                print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âŒ ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            matched_data.append((
                video_name,
                tracking_data,
                court_data
            ))
            
            frame_count = self.get_actual_frame_count(tracking_data)
            print(f"  âœ… ãƒãƒƒãƒãƒ³ã‚°æˆåŠŸ:")
            print(f"     ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°: {video_name}")
            print(f"     å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
            if isinstance(tracking_data, dict) and 'metadata' in tracking_data:
                frame_skip = tracking_data['metadata'].get('frame_skip', 1)
                print(f"     ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {frame_skip}")
            if court_data:
                print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: {court_matched_key} ({court_match_type})")
            else:
                print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: ãªã—")
        
        print(f"\n=== ãƒãƒƒãƒãƒ³ã‚°çµæœã‚µãƒãƒªãƒ¼ ===")
        print(f"âœ… ãƒãƒƒãƒãƒ³ã‚°æ•°: {len(matched_data)}")
        
        if matched_data:
            print("\nğŸ“‹ ãƒãƒƒãƒãƒ³ã‚°ä¸€è¦§:")
            for i, (video_name, tracking_data, court_data) in enumerate(matched_data, 1):
                frame_count = self.get_actual_frame_count(tracking_data)
                court_status = "ã‚ã‚Š" if court_data else "ãªã—"
                print(f"  {i}. {video_name}")
                print(f"     ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
                print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: {court_status}")
        
        print(f"æœ€çµ‚ãƒãƒƒãƒãƒ³ã‚°æ•°: {len(matched_data)}")
        return matched_data
    
    def get_actual_frame_count(self, tracking_data) -> int:
        """å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«é–¢ä¿‚ãªãï¼‰"""
        if isinstance(tracking_data, list):
            return len(tracking_data)
        elif isinstance(tracking_data, dict):
            if 'frames' in tracking_data:
                frames = tracking_data['frames']
                return len(frames) if hasattr(frames, '__len__') else 0
            elif 'frame_data' in tracking_data:
                frame_data = tracking_data['frame_data']
                return len(frame_data) if hasattr(frame_data, '__len__') else 0
            else:
                numeric_keys = [k for k in tracking_data.keys() if str(k).isdigit()]
                return len(numeric_keys)
        else:
            return 0

    def validate_tracking_data_consistency(self, tracking_data_dict: Dict) -> Dict:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã‚’æ¤œè¨¼ï¼ˆè¨˜éŒ²ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
        validation_result = {
            'is_valid': True,
            'warnings': [],
            'frame_count': 0,
            'frame_skip_detected': False,
            'recorded_frame_skip': 1,
            'actual_frame_skip_interval': 1,
            'missing_frames': [],
            'duplicate_frames': [],
            'interpolated_count': 0,
            'metadata_available': False,
            'processing_mode': 'unknown'
        }
        
        if isinstance(tracking_data_dict, list):
            tracking_data = tracking_data_dict
            validation_result['warnings'].append("æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        elif isinstance(tracking_data_dict, dict) and 'frames' in tracking_data_dict:
            tracking_data = tracking_data_dict['frames']
            metadata = tracking_data_dict.get('metadata', {})
            validation_result['metadata_available'] = True
            
            recorded_skip = metadata.get('frame_skip', 1)
            processing_mode = metadata.get('processing_mode', 'unknown')
            
            validation_result['recorded_frame_skip'] = recorded_skip
            validation_result['processing_mode'] = processing_mode
            
            if recorded_skip > 1:
                validation_result['frame_skip_detected'] = True
                validation_result['warnings'].append(
                    f"è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {recorded_skip} (ãƒ¢ãƒ¼ãƒ‰: {processing_mode})"
                )
            
            if 'original_fps' in metadata:
                validation_result['original_fps'] = metadata['original_fps']
            if 'processing_fps' in metadata:
                validation_result['processing_fps'] = metadata['processing_fps']
            if 'total_original_frames' in metadata:
                validation_result['total_original_frames'] = metadata['total_original_frames']
        else:
            validation_result['is_valid'] = False
            validation_result['warnings'].append("ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã™")
            return validation_result
        
        validation_result['frame_count'] = len(tracking_data)
        
        if not tracking_data:
            validation_result['is_valid'] = False
            validation_result['warnings'].append("ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return validation_result
        
        frame_numbers = [data.get('frame_number', 0) for data in tracking_data]
        frame_numbers.sort()
        
        from collections import Counter
        frame_counts = Counter(frame_numbers)
        duplicates = [frame for frame, count in frame_counts.items() if count > 1]
        if duplicates:
            validation_result['duplicate_frames'] = duplicates
            validation_result['warnings'].append(f"é‡è¤‡ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {duplicates}")
        
        intervals = []
        missing_frames = []
        
        for i in range(1, len(frame_numbers)):
            interval = frame_numbers[i] - frame_numbers[i-1]
            if interval > 1:
                intervals.append(interval)
                for missing in range(frame_numbers[i-1] + 1, frame_numbers[i]):
                    missing_frames.append(missing)
            elif interval == 1:
                intervals.append(1)
        
        if intervals:
            interval_counts = Counter(intervals)
            most_common_interval = interval_counts.most_common(1)[0][0]
            
            validation_result['actual_frame_skip_interval'] = most_common_interval
            
            recorded_skip = validation_result['recorded_frame_skip']
            if recorded_skip > 1:
                if most_common_interval == recorded_skip:
                    validation_result['warnings'].append(
                        f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æ•´åˆæ€§ç¢ºèª: è¨˜éŒ²å€¤({recorded_skip}) = å®Ÿæ¸¬å€¤({most_common_interval})"
                    )
                else:
                    validation_result['warnings'].append(
                        f"âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ä¸æ•´åˆ: è¨˜éŒ²å€¤({recorded_skip}) â‰  å®Ÿæ¸¬å€¤({most_common_interval})"
                    )
            elif most_common_interval > 1:
                validation_result['warnings'].append(
                    f"âš ï¸  è¨˜éŒ²ãªã—ã‚¹ã‚­ãƒƒãƒ—æ¤œå‡º: å®Ÿæ¸¬é–“éš”({most_common_interval})"
                )
        
        validation_result['missing_frames'] = missing_frames
        
        interpolated_count = sum(1 for data in tracking_data if data.get('interpolated', False))
        validation_result['interpolated_count'] = interpolated_count
        
        if interpolated_count > 0:
            validation_result['warnings'].append(f"è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {interpolated_count}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        
        if len(tracking_data) > 0:
            ball_detection_rate = sum(1 for data in tracking_data if data.get('ball_detected', 0)) / len(tracking_data)
            validation_result['ball_detection_rate'] = ball_detection_rate
            if ball_detection_rate < 0.3:
                validation_result['warnings'].append(f"ãƒœãƒ¼ãƒ«æ¤œå‡ºç‡ãŒä½ã„ã§ã™: {ball_detection_rate:.1%}")
        else:
            validation_result['ball_detection_rate'] = 0

        return validation_result
    
    def diagnose_tracking_data_structure(self, tracking_data_dict: Dict, video_name: str):
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®è©³ç´°è¨ºæ–­"""
        print(f"\n=== {video_name} ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨ºæ–­ ===")
        
        if isinstance(tracking_data_dict, dict):
            print("ãƒ‡ãƒ¼ã‚¿æ§‹é€ : è¾æ›¸å‹")
            print(f"ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚­ãƒ¼: {list(tracking_data_dict.keys())}")
            
            if 'frames' in tracking_data_dict:
                frames_data = tracking_data_dict['frames']
                print(f"framesè¦ç´ å‹: {type(frames_data)}")
                print(f"framesè¦ç´ æ•°: {len(frames_data) if hasattr(frames_data, '__len__') else 'N/A'}")
                
                if isinstance(frames_data, list) and len(frames_data) > 0:
                    sample_frame = frames_data[0]
                    print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ å‹: {type(sample_frame)}")
                    if isinstance(sample_frame, dict):
                        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚­ãƒ¼æ•°: {len(sample_frame.keys())}")
                        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚­ãƒ¼ä¾‹: {list(sample_frame.keys())[:10]}")
                
            if 'metadata' in tracking_data_dict:
                metadata = tracking_data_dict['metadata']
                print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata}")
        
        elif isinstance(tracking_data_dict, list):
            print("ãƒ‡ãƒ¼ã‚¿æ§‹é€ : ãƒªã‚¹ãƒˆå‹")
            print(f"è¦ç´ æ•°: {len(tracking_data_dict)}")
            if len(tracking_data_dict) > 0:
                sample = tracking_data_dict[0]
                print(f"ã‚µãƒ³ãƒ—ãƒ«è¦ç´ å‹: {type(sample)}")
        
        else:
            print(f"ãƒ‡ãƒ¼ã‚¿æ§‹é€ : ä¸æ˜ãªå‹ - {type(tracking_data_dict)}")
    
    def attempt_alternative_data_loading(self, video_name: str) -> List[Dict]:
        """ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è©¦è¡Œ"""
        print(f"=== {video_name} ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è©¦è¡Œ ===")
        
        pattern = f"tracking_features_{video_name}_*.json"
        tracking_files = list(self.inference_data_dir.glob(pattern))
        
        if not tracking_files:
            print(f"å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
            return []
        
        for file_path in tracking_files:
            try:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«å†èª­ã¿è¾¼ã¿è©¦è¡Œ: {file_path.name}")
                
                with open(file_path, 'r', encoding='utf-8') as f:
                    raw_data = json.load(f)
                
                print(f"ç”Ÿãƒ‡ãƒ¼ã‚¿å‹: {type(raw_data)}")
                
                if isinstance(raw_data, list):
                    print(f"ãƒªã‚¹ãƒˆå½¢å¼: {len(raw_data)}è¦ç´ ")
                    return raw_data
                elif isinstance(raw_data, dict):
                    print(f"è¾æ›¸å½¢å¼ã‚­ãƒ¼: {list(raw_data.keys())}")
                    
                    if 'frames' in raw_data:
                        frames = raw_data['frames']
                        if isinstance(frames, list): return frames
                    
                    if 'frame_data' in raw_data:
                        frame_data = raw_data['frame_data']
                        if isinstance(frame_data, list): return frame_data
                    
                    numeric_keys = [k for k in raw_data.keys() if str(k).isdigit()]
                    if numeric_keys:
                        frame_list = []
                        for key in sorted(numeric_keys, key=int):
                            frame_data = raw_data[key]
                            if isinstance(frame_data, dict):
                                frame_data['frame_number'] = int(key)
                                frame_list.append(frame_data)
                        if frame_list: return frame_list
                
                print("âš ï¸  èªè­˜å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
                
            except Exception as e:
                print(f"ä»£æ›¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return []
    
    def normalize_frame_numbers(self, tracking_data_dict: Dict) -> List[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’æ­£è¦åŒ–ã—ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚’è€ƒæ…®ã—ãŸå±•é–‹ã‚’è¡Œã†"""
        print("=== ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–ãƒ»å±•é–‹å‡¦ç† ===")
        
        if isinstance(tracking_data_dict, list):
            print("âš ï¸  æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return self.legacy_normalize_frame_numbers_fast(tracking_data_dict)
        
        metadata = tracking_data_dict.get('metadata', {})
        frame_skip = metadata.get('frame_skip', 1)
        
        print(f"âœ… è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±: {frame_skip}")
        
        if frame_skip == 1:
            frames_data = tracking_data_dict.get('frames', [])
            print("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ãªã— - é€šå¸¸ã®æ­£è¦åŒ–ã‚’å®Ÿè¡Œ")
            return frames_data
        else:
            print(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—({frame_skip})ã‚’æ¤œå‡º - å…ƒã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¸ã®å±•é–‹ã‚’å®Ÿè¡Œ")
            expanded_frames = self.expand_frames_to_original_sequence_fast(tracking_data_dict)
            return expanded_frames
    
    def legacy_normalize_frame_numbers_fast(self, tracking_data: List[Dict]) -> List[Dict]:
        """æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–ï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        if not tracking_data:
            return []
        
        frame_numbers = np.array([frame.get('frame_number', 0) for frame in tracking_data])
        sorted_indices = np.argsort(frame_numbers)
        
        sorted_data = [tracking_data[i] for i in sorted_indices]
        
        for i, frame_data in enumerate(sorted_data):
            frame_data['original_frame_number'] = frame_data.get('frame_number', 0)
            frame_data['frame_number'] = i
            frame_data['interpolated'] = False
        
        return sorted_data
    
    def expand_frames_to_original_sequence_fast(self, tracking_data_dict: Dict) -> List[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å±•é–‹å‡¦ç†ï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        print("=== ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å±•é–‹å‡¦ç† (NumPyé«˜é€ŸåŒ–) ===")
        
        metadata = tracking_data_dict['metadata']
        frames_data = tracking_data_dict['frames']
        frame_skip = metadata.get('frame_skip', 1)
        total_original_frames = metadata.get('total_original_frames')
        
        print(f"è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {frame_skip}")
        print(f"å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(frames_data)}")
        
        if not frames_data:
            return []
        
        frame_numbers = np.array([frame.get('frame_number', 0) for frame in frames_data])
        sorted_indices = np.argsort(frame_numbers)
        sorted_frames = [frames_data[i] for i in sorted_indices]
        sorted_frame_numbers = frame_numbers[sorted_indices]
        
        last_frame = sorted_frame_numbers[-1]
        
        if total_original_frames is None:
            total_original_frames = last_frame + frame_skip
        
        print(f"æ¨å®šç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_original_frames}")
        
        processed_frame_map = {frame_num: frame for frame_num, frame in zip(sorted_frame_numbers, sorted_frames)}
        
        all_frame_numbers = np.arange(total_original_frames)
        
        expanded_frames = []
        interpolated_count = 0
        
        for frame_num in all_frame_numbers:
            if frame_num in processed_frame_map:
                frame_data = processed_frame_map[frame_num].copy()
                frame_data['original_frame_number'] = frame_num
                frame_data['interpolated'] = False
                expanded_frames.append(frame_data)
            else:
                interpolated_frame = self.create_interpolated_frame_from_skip_fast(
                    frame_num, processed_frame_map, sorted_frame_numbers, frame_skip
                )
                expanded_frames.append(interpolated_frame)
                interpolated_count += 1
        
        print(f"âœ… å±•é–‹å®Œäº†: ç·{len(expanded_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ , è£œé–“{interpolated_count}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        return expanded_frames
    
    def create_interpolated_frame_from_skip_fast(self, target_frame_num: int, 
                                               processed_frame_map: Dict, 
                                               sorted_frame_numbers: np.ndarray, 
                                               frame_skip: int) -> Dict:
        """è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        prev_mask = sorted_frame_numbers < target_frame_num
        next_mask = sorted_frame_numbers > target_frame_num
        
        prev_frame_data = None
        next_frame_data = None
        
        if np.any(prev_mask):
            prev_frame_num = sorted_frame_numbers[prev_mask][-1]
            prev_frame_data = processed_frame_map[prev_frame_num]
        
        if np.any(next_mask):
            next_frame_num = sorted_frame_numbers[next_mask][0]
            next_frame_data = processed_frame_map[next_frame_num]
        
        interpolated_frame = {
            'frame_number': target_frame_num,
            'original_frame_number': target_frame_num,
            'interpolated': True,
            'timestamp': '',
            'ball_detected': 0, 'ball_x': None, 'ball_y': None, 'ball_x_normalized': 0,
            'ball_y_normalized': 0, 'ball_movement_score': 0, 'ball_tracking_confidence': 0,
            'ball_velocity_x': 0, 'ball_velocity_y': 0, 'ball_speed': 0,
            'player_front_count': 0, 'player_back_count': 0, 'total_players': 0,
            'candidate_balls_count': 0, 'disappeared_count': 0, 'trajectory_length': 0,
            'prediction_active': 0
        }
        
        if prev_frame_data and next_frame_data:
            prev_frame_num = prev_frame_data.get('frame_number', 0)
            next_frame_num = next_frame_data.get('frame_number', 0)
            
            if next_frame_num > prev_frame_num:
                ratio = (target_frame_num - prev_frame_num) / (next_frame_num - prev_frame_num)
                ratio = np.clip(ratio, 0, 1)
                
                numeric_keys = [
                    'ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized', 'ball_velocity_x', 
                    'ball_velocity_y', 'ball_speed', 'ball_movement_score', 'ball_tracking_confidence',
                    'player_front_x', 'player_front_y', 'player_front_x_normalized', 'player_front_y_normalized',
                    'player_back_x', 'player_back_y', 'player_back_x_normalized', 'player_back_y_normalized',
                    'player_front_confidence', 'player_back_confidence', 'player_distance', 'player_distance_normalized'
                ]
                
                prev_values = np.array([prev_frame_data.get(key, 0) or 0 for key in numeric_keys], dtype=float)
                next_values = np.array([next_frame_data.get(key, 0) or 0 for key in numeric_keys], dtype=float)
                
                interpolated_values = prev_values + (next_values - prev_values) * ratio
                
                for key, value in zip(numeric_keys, interpolated_values):
                    interpolated_frame[key] = value
        
        elif prev_frame_data:
            inherit_keys = ['ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized',
                           'player_front_x', 'player_front_y', 'player_back_x', 'player_back_y']
            for key in inherit_keys:
                if key in prev_frame_data and prev_frame_data[key] is not None:
                    interpolated_frame[key] = prev_frame_data[key]
        
        return interpolated_frame

    def create_temporal_features(self, features_df: pd.DataFrame, window_sizes: List[int] = [3, 5, 10, 15]) -> pd.DataFrame:
        """æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆNumbaé«˜é€ŸåŒ–å¯¾å¿œï¼‰"""
        temporal_df = features_df.copy()
        
        numeric_columns = features_df.select_dtypes(include=[np.number]).columns
        target_columns = [col for col in numeric_columns if col not in ['frame_number', 'original_frame_number']]
        
        print(f"æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆå¯¾è±¡: {len(target_columns)}ç‰¹å¾´é‡ (Numbaé«˜é€ŸåŒ–å¯¾å¿œ)")
        
        is_interpolated = features_df.get('interpolated', pd.Series([False] * len(features_df))).values
        
        print("  ãƒ‡ãƒ¼ã‚¿ã‚’NumPyé…åˆ—ã«å¤‰æ›ä¸­...")
        data_matrix = features_df[target_columns].values.astype(np.float64)
        data_matrix = np.nan_to_num(data_matrix, nan=0.0)
        
        new_features = {}
        
        for window in tqdm(window_sizes, desc="æ™‚ç³»åˆ—ç‰¹å¾´é‡(ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ¥)", leave=False):
            print(f"  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º {window} ã®ç‰¹å¾´é‡ä½œæˆä¸­... (Numba é«˜é€ŸåŒ–)")
            
            ma_results, std_results, max_results, min_results = TennisInferenceFeatureExtractor.vectorized_rolling_stats(
                data_matrix, window, is_interpolated
            )
            
            for i, col in enumerate(target_columns):
                new_features[f'{col}_ma_{window}'] = ma_results[:, i]
                new_features[f'{col}_std_{window}'] = std_results[:, i]
                new_features[f'{col}_max_{window}'] = max_results[:, i]
                new_features[f'{col}_min_{window}'] = min_results[:, i]
                
                if window <= 5:
                    diff1, diff2 = self.vectorized_diff_features(
                        data_matrix[:, i], is_interpolated
                    )
                    new_features[f'{col}_diff'] = diff1
                    new_features[f'{col}_diff_abs'] = np.abs(diff1)
                    new_features[f'{col}_diff2'] = diff2
                    new_features[f'{col}_diff2_abs'] = np.abs(diff2)
                
                if window == 5:
                    trend_values = self.vectorized_rolling_trend(data_matrix[:, i], window)
                    new_features[f'{col}_trend_{window}'] = trend_values
                    
                    ma_vals = ma_results[:, i]
                    std_vals = std_results[:, i]
                    cv_values = np.divide(std_vals, np.abs(ma_vals), 
                                        out=np.zeros_like(std_vals), where=ma_vals!=0)
                    new_features[f'{col}_cv_{window}'] = cv_values
        
        new_features['data_quality'] = (~is_interpolated).astype(float)
        
        interpolation_kernel = np.ones(10) / 10
        interpolation_ratio = np.convolve(is_interpolated.astype(float), interpolation_kernel, mode='same')
        new_features['interpolation_ratio'] = interpolation_ratio
        
        print("  æ–°ã—ã„ç‰¹å¾´é‡ã‚’DataFrameã«çµ±åˆä¸­...")
        for feature_name, feature_values in new_features.items():
            temporal_df[feature_name] = feature_values
        
        print(f"æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(new_features)}ç‰¹å¾´é‡è¿½åŠ ")
        return temporal_df

    @staticmethod
    @numba.jit(nopython=True, parallel=True)
    def vectorized_rolling_stats(data_matrix: np.ndarray, window: int, 
                                is_interpolated: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸç§»å‹•çµ±è¨ˆè¨ˆç®— (Numba JITã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¯¾å¿œã€axiså¼•æ•°å•é¡Œã‚’å®Œå…¨ä¿®æ­£)"""
        n_rows, n_cols = data_matrix.shape
        
        ma_results = np.zeros_like(data_matrix)
        std_results = np.zeros_like(data_matrix)
        max_results = np.zeros_like(data_matrix)
        min_results = np.zeros_like(data_matrix)
        
        half_window = window // 2
        
        # --- ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç† (æ‰‹å‹•å®Ÿè£…) ---
        padded_data = np.empty((n_rows + 2 * half_window, n_cols), dtype=np.float64)
        padded_data[half_window:half_window + n_rows] = data_matrix
        for i in range(half_window):
            padded_data[i] = data_matrix[0]
            padded_data[n_rows + half_window + i] = data_matrix[-1]

        weights = np.where(is_interpolated, 0.3, 0.8)
        
        padded_weights = np.empty(n_rows + 2 * half_window, dtype=np.float64)
        padded_weights[half_window:half_window + n_rows] = weights
        for i in range(half_window):
            padded_weights[i] = weights[0]
            padded_weights[n_rows + half_window + i] = weights[-1]

        # --- ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®è¨ˆç®— (ä¸¦åˆ—åŒ–) ---
        for i in numba.prange(n_rows):
            window_start = i
            window_end = i + window
            
            window_data = padded_data[window_start:window_end]
            window_weights = padded_weights[window_start:window_end]
            
            # --- å¹³å‡å€¤ (mean) ã®è¨ˆç®— ---
            weight_sum = np.sum(window_weights)
            if weight_sum > 0:
                weighted_data = window_data * window_weights.reshape(-1, 1)
                ma_results[i, :] = np.sum(weighted_data, axis=0) / weight_sum
            else:
                ma_results[i, :] = np.sum(window_data, axis=0) / window_data.shape[0]

            # â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒä»Šå›ã®ä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜…

            # --- æ¨™æº–åå·® (std) ã®è¨ˆç®— (æ‰‹å‹•å®Ÿè£…) ---
            # E[X^2] - (E[X])^2 ã‚’åˆ©ç”¨
            mean_val = np.sum(window_data, axis=0) / window_data.shape[0]
            mean_sq_val = np.sum(window_data**2, axis=0) / window_data.shape[0]
            variance = mean_sq_val - mean_val**2
            # æµ®å‹•å°æ•°ç‚¹èª¤å·®ã§è² ã«ãªã‚‹ã®ã‚’é˜²ã
            for j in range(n_cols):
                if variance[j] < 0:
                    variance[j] = 0
            std_results[i, :] = np.sqrt(variance)

            # --- æœ€å¤§å€¤ (max) ã®è¨ˆç®— (æ‰‹å‹•å®Ÿè£…) ---
            # å„åˆ—ã”ã¨ã«æœ€å¤§å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ«ãƒ¼ãƒ—
            for j in range(n_cols):
                max_results[i, j] = np.max(window_data[:, j])

            # --- æœ€å°å€¤ (min) ã®è¨ˆç®— (æ‰‹å‹•å®Ÿè£…) ---
            # å„åˆ—ã”ã¨ã«æœ€å°å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ«ãƒ¼ãƒ—
            for j in range(n_cols):
                min_results[i, j] = np.min(window_data[:, j])
        
        return ma_results, std_results, max_results, min_results

    def vectorized_diff_features(self, data_array: np.ndarray, 
                               is_interpolated: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸå·®åˆ†ç‰¹å¾´é‡è¨ˆç®—"""
        diff1 = np.diff(data_array, prepend=data_array[0])
        
        if np.any(is_interpolated):
            diff_weights = (~is_interpolated).astype(float) * 1.0 + is_interpolated.astype(float) * 0.5
            diff1 = diff1 * diff_weights
        
        diff2 = np.diff(diff1, prepend=diff1[0])
        
        return diff1, diff2
    
    def vectorized_rolling_trend(self, data_array: np.ndarray, window: int) -> np.ndarray:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸç§»å‹•ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        n = len(data_array)
        trend_values = np.zeros(n)
        half_window = window // 2
        
        padded_data = np.pad(data_array, half_window, mode='edge')
        
        x = np.arange(window) - half_window
        x_mean = np.mean(x)
        x_centered = x - x_mean
        x_var = np.sum(x_centered ** 2)
        
        if x_var == 0:
            return trend_values
        
        for i in range(n):
            y = padded_data[i:i+window]
            y_mean = np.mean(y)
            y_centered = y - y_mean
            
            covariance = np.sum(x_centered * y_centered)
            trend_values[i] = covariance / x_var
        
        return trend_values

    def create_contextual_features(self, features_df: pd.DataFrame) -> pd.DataFrame:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆçœŸã®NumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        context_df = features_df.copy()
        
        print("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆä¸­... (çœŸã®NumPyé«˜é€ŸåŒ–)")
        
        available_fields = set(context_df.columns)
        data_length = len(context_df)
        
        numeric_data = {}
        for field in available_fields:
            if context_df[field].dtype in [np.number, 'float64', 'float32', 'int64', 'int32']:
                numeric_data[field] = context_df[field].fillna(0).values
        
        ball_activity = self.calculate_ball_activity_vectorized(numeric_data, available_fields, data_length)
        context_df['ball_activity'] = ball_activity
        
        players_interaction, players_confidence_avg = self.calculate_player_features_vectorized(
            numeric_data, available_fields, data_length
        )
        context_df['players_interaction'] = players_interaction
        context_df['players_confidence_avg'] = players_confidence_avg
        
        distance_features = self.calculate_distances_vectorized(numeric_data, available_fields, data_length)
        for feature_name, feature_values in distance_features.items():
            context_df[feature_name] = feature_values
        
        position_features = self.calculate_position_features_vectorized(numeric_data, available_fields, data_length)
        for feature_name, feature_values in position_features.items():
            context_df[feature_name] = feature_values
        
        tracking_quality = self.calculate_tracking_quality_vectorized(numeric_data, available_fields, data_length)
        context_df['tracking_quality'] = tracking_quality
        
        temporal_context_features = self.calculate_temporal_context_vectorized(
            numeric_data, available_fields, data_length
        )
        for feature_name, feature_values in temporal_context_features.items():
            context_df[feature_name] = feature_values
        
        added_features = len(context_df.columns) - len(features_df.columns)
        print(f"  ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†: {added_features}ç‰¹å¾´é‡è¿½åŠ ")
        return context_df
    
    def calculate_ball_activity_vectorized(self, numeric_data: Dict[str, np.ndarray], 
                                         available_fields: set, data_length: int) -> np.ndarray:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒœãƒ¼ãƒ«æ´»å‹•åº¦è¨ˆç®—"""
        components = []
        if 'ball_detected' in available_fields: components.append(numeric_data['ball_detected'])
        if 'ball_movement_score' in available_fields: components.append(numeric_data['ball_movement_score'])
        elif 'ball_speed' in available_fields: components.append(numeric_data['ball_speed'] / 100.0)
        if 'ball_tracking_confidence' in available_fields: components.append(numeric_data['ball_tracking_confidence'])
        
        if components:
            ball_activity = np.ones(data_length)
            for component in components:
                ball_activity *= component
            return ball_activity
        else:
            return np.zeros(data_length)
    
    def calculate_player_features_vectorized(self, numeric_data: Dict[str, np.ndarray], 
                                           available_fields: set, data_length: int) -> Tuple[np.ndarray, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ç‰¹å¾´é‡è¨ˆç®—"""
        player_counts = []
        if 'player_front_count' in available_fields: player_counts.append(numeric_data['player_front_count'])
        if 'player_back_count' in available_fields: player_counts.append(numeric_data['player_back_count'])
        
        players_interaction = np.mean(player_counts, axis=0) if player_counts else np.zeros(data_length)
        
        confidence_components = []
        if 'player_front_confidence' in available_fields: confidence_components.append(numeric_data['player_front_confidence'])
        if 'player_back_confidence' in available_fields: confidence_components.append(numeric_data['player_back_confidence'])
        
        players_confidence_avg = np.mean(confidence_components, axis=0) if confidence_components else np.zeros(data_length)
        
        return players_interaction, players_confidence_avg
    
    def calculate_distances_vectorized(self, numeric_data: Dict[str, np.ndarray], 
                                     available_fields: set, data_length: int) -> Dict[str, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸè·é›¢è¨ˆç®—"""
        distance_features = {}
        
        ball_pos_available = all(col in available_fields for col in ['ball_x', 'ball_y'])
        front_pos_available = all(col in available_fields for col in ['player_front_x', 'player_front_y'])
        back_pos_available = all(col in available_fields for col in ['player_back_x', 'player_back_y'])
        
        if ball_pos_available and front_pos_available:
            dist = np.sqrt((numeric_data['ball_x'] - numeric_data['player_front_x'])**2 + (numeric_data['ball_y'] - numeric_data['player_front_y'])**2)
            distance_features['ball_to_front_distance'] = np.where(np.isnan(dist) | np.isinf(dist), 1000, dist)
        else:
            distance_features['ball_to_front_distance'] = np.full(data_length, 1000.0)
        
        if ball_pos_available and back_pos_available:
            dist = np.sqrt((numeric_data['ball_x'] - numeric_data['player_back_x'])**2 + (numeric_data['ball_y'] - numeric_data['player_back_y'])**2)
            distance_features['ball_to_back_distance'] = np.where(np.isnan(dist) | np.isinf(dist), 1000, dist)
        else:
            distance_features['ball_to_back_distance'] = np.full(data_length, 1000.0)
        
        if 'ball_to_front_distance' in distance_features and 'ball_to_back_distance' in distance_features:
            front_dist = distance_features['ball_to_front_distance']
            back_dist = distance_features['ball_to_back_distance']
            distance_features['ball_closer_to_front'] = (front_dist < back_dist).astype(int)
        else:
            distance_features['ball_closer_to_front'] = np.zeros(data_length, dtype=int)
        
        return distance_features
    
    def calculate_position_features_vectorized(self, numeric_data: Dict[str, np.ndarray], 
                                             available_fields: set, data_length: int) -> Dict[str, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸä½ç½®ç‰¹å¾´é‡è¨ˆç®—"""
        position_features = {}
        
        if all(col in available_fields for col in ['ball_x_normalized', 'ball_y_normalized']):
            ball_x_norm = np.nan_to_num(numeric_data['ball_x_normalized'], nan=0.5)
            ball_y_norm = np.nan_to_num(numeric_data['ball_y_normalized'], nan=0.5)
            
            position_features['ball_in_upper_half'] = (ball_x_norm < 0.5).astype(int)
            position_features['ball_in_left_half'] = (ball_y_norm < 0.5).astype(int)
            
            in_center = ((ball_x_norm > 0.3) & (ball_x_norm < 0.7) & (ball_y_norm > 0.3) & (ball_y_norm < 0.7))
            position_features['ball_in_center'] = in_center.astype(int)
        else:
            position_features.update({
                'ball_in_upper_half': np.zeros(data_length, dtype=int),
                'ball_in_left_half': np.zeros(data_length, dtype=int),
                'ball_in_center': np.zeros(data_length, dtype=int)
            })
        
        return position_features
    
    def calculate_tracking_quality_vectorized(self, numeric_data: Dict[str, np.ndarray], 
                                            available_fields: set, data_length: int) -> np.ndarray:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°å“è³ªè¨ˆç®—"""
        quality_components, weights = [], []
        if 'ball_detected' in available_fields: quality_components.append(numeric_data['ball_detected']); weights.append(0.4)
        if 'ball_tracking_confidence' in available_fields: quality_components.append((numeric_data['ball_tracking_confidence'] > 0.5).astype(int)); weights.append(0.3)
        if 'candidate_balls_count' in available_fields: quality_components.append((numeric_data['candidate_balls_count'] > 0).astype(int)); weights.append(0.2)
        if 'disappeared_count' in available_fields: quality_components.append((numeric_data['disappeared_count'] == 0).astype(int)); weights.append(0.1)
        
        if quality_components:
            quality_array = np.array(quality_components)
            weights_array = np.array(weights).reshape(-1, 1)
            weighted_sum = np.sum(quality_array * weights_array, axis=0)
            total_weight = np.sum(weights_array)
            return weighted_sum / total_weight if total_weight > 0 else np.zeros(data_length)
        else:
            return np.zeros(data_length)
    
    def calculate_temporal_context_vectorized(self, numeric_data: Dict[str, np.ndarray], 
                                            available_fields: set, data_length: int) -> Dict[str, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸæ™‚ç³»åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡è¨ˆç®—"""
        print("    æ™‚ç³»åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆä¸­... (çœŸã®NumPyé«˜é€ŸåŒ–)")
        temporal_features = {}
        
        if 'ball_detected' in available_fields:
            ball_detected = numeric_data['ball_detected']
            for window in [3, 5, 10]:
                kernel = np.ones(window) / window
                temporal_features[f'ball_detection_stability_{window}'] = np.convolve(ball_detected, kernel, mode='same')
        
        if all(col in available_fields for col in ['ball_x', 'ball_y']):
            x_diff = np.diff(numeric_data['ball_x'], prepend=numeric_data['ball_x'][0])
            y_diff = np.diff(numeric_data['ball_y'], prepend=numeric_data['ball_y'][0])
            movement_distance = np.sqrt(x_diff**2 + y_diff**2)
            temporal_features['ball_movement_distance'] = movement_distance
            for window in [3, 5]:
                temporal_features[f'ball_movement_stability_{window}'] = self.fast_rolling_std_vectorized(movement_distance, window)
        
        for player in ['front', 'back']:
            if all(f'player_{player}_{coord}' in available_fields for coord in ['x', 'y']):
                x_diff = np.diff(numeric_data[f'player_{player}_x'], prepend=numeric_data[f'player_{player}_x'][0])
                y_diff = np.diff(numeric_data[f'player_{player}_y'], prepend=numeric_data[f'player_{player}_y'][0])
                movement_dist = np.sqrt(x_diff**2 + y_diff**2)
                temporal_features[f'player_{player}_movement_distance'] = movement_dist
                for window in [5, 10]:
                    kernel = np.ones(window) / window
                    temporal_features[f'player_{player}_activity_{window}'] = np.convolve(movement_dist, kernel, mode='same')
        
        movement_cols = [k for k in temporal_features if 'movement_distance' in k]
        if movement_cols:
            movement_matrix = np.array([temporal_features[col] for col in movement_cols])
            scene_dynamics = np.mean(movement_matrix, axis=0)
            temporal_features['scene_dynamics'] = scene_dynamics
            for window in [5, 10]:
                kernel = np.ones(window) / window
                temporal_features[f'scene_dynamics_ma_{window}'] = np.convolve(scene_dynamics, kernel, mode='same')
                temporal_features[f'scene_dynamics_std_{window}'] = self.fast_rolling_std_vectorized(scene_dynamics, window)
        
        if 'ball_movement_distance' in temporal_features:
            movement_dist = temporal_features['ball_movement_distance']
            kernel = np.ones(5) / 5
            movement_ma = np.convolve(movement_dist, kernel, mode='same')
            spike_mask = movement_dist > movement_ma * 2
            temporal_features['ball_movement_spike'] = spike_mask.astype(int)
            for window in [10, 20]:
                kernel = np.ones(window)
                temporal_features[f'ball_events_frequency_{window}'] = np.convolve(spike_mask.astype(float), kernel, mode='same')

        return temporal_features
    
    def fast_rolling_std_vectorized(self, values: np.ndarray, window: int) -> np.ndarray:
        """å®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸé«˜é€Ÿç§»å‹•æ¨™æº–åå·®è¨ˆç®—"""
        n= len(values)

        padded_values = np.pad(values, window//2, mode='edge')
        kernel = np.ones(window)
        moving_sum = np.convolve(padded_values, kernel, mode='valid')
        moving_mean = moving_sum / window
        moving_sum_sq = np.convolve(padded_values**2, kernel, mode='valid')
        moving_mean_sq = moving_sum_sq / window
        variance = np.clip(moving_mean_sq - moving_mean**2, 0, None)

        if len(variance) > n:
            variance = variance[:n]
        return np.sqrt(variance)

    def handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¬ æå€¤ã‚’å‡¦ç†ï¼ˆå®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰"""
        df_cleaned = df.copy()
        position_columns = ['ball_x', 'ball_y', 'player_front_x', 'player_front_y', 'player_back_x', 'player_back_y']
        
        for col in position_columns:
            if col in df_cleaned.columns:
                values = df_cleaned[col].values
                mask = pd.isna(values)
                if np.any(mask):
                    valid_indices = np.where(~mask)[0]
                    if len(valid_indices) > 0:
                        first_valid = values[valid_indices[0]]
                        values[:valid_indices[0]] = first_valid
                        for i in range(1, len(values)):
                            if mask[i]: values[i] = values[i-1]
                    else:
                        values[:] = 0
                    df_cleaned[col] = values
        
        numeric_columns = df_cleaned.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if col not in position_columns:
                df_cleaned[col] = np.nan_to_num(df_cleaned[col].values, nan=0)
        
        return df_cleaned

    def extract_features_from_video(self, video_name: str, tracking_data_dict: Dict, court_coords: Dict = None) -> pd.DataFrame:
        """å˜ä¸€å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        print(f"\n--- æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡º: {video_name} ---")
        
        print("  ã‚¹ãƒ†ãƒƒãƒ—1/4: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ä¸­...")
        validation_result = self.validate_tracking_data_consistency(tracking_data_dict)
        for key, value in validation_result.items():
            if key == 'warnings' and value:
                for warning in value: print(f"  ğŸ“‹ {warning}")
            elif key in ['missing_frames', 'duplicate_frames']:
                if value:
                    print(f"  {key}: {len(value)}å€‹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡º")
            elif key != 'warnings':
                print(f"  {key}: {value}")

        if validation_result['frame_count'] <= 10:
            print(f"âš ï¸  ç•°å¸¸ã«ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒå°‘ãªã„ã§ã™: {validation_result['frame_count']}")
            self.diagnose_tracking_data_structure(tracking_data_dict, video_name)
            alternative_data = self.attempt_alternative_data_loading(video_name)
            if alternative_data and len(alternative_data) > validation_result['frame_count']:
                print(f"âœ… ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(alternative_data)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                current_metadata = tracking_data_dict.get('metadata', {'frame_skip': 1, 'legacy_format': True})
                tracking_data_dict = {'metadata': current_metadata, 'frames': alternative_data}
        
        print("  ã‚¹ãƒ†ãƒƒãƒ—2/4: ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–ä¸­...")
        normalized_tracking_data = self.normalize_frame_numbers(tracking_data_dict)
        
        if not normalized_tracking_data:
            print("âš ï¸  æ­£è¦åŒ–å¾Œã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return pd.DataFrame()
        
        print("  ã‚¹ãƒ†ãƒƒãƒ—3/4: DataFrameä½œæˆä¸­...")
        features_df = self.safe_create_dataframe_from_tracking_data(normalized_tracking_data, video_name)
        
        if features_df.empty:
            print("âŒ DataFrameä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame()
        if 'frame_number' in features_df.columns:
            features_df['original_frame_number'] = features_df['frame_number']

        features_df['frame_number'] = range(len(features_df))
        features_df['video_name'] = video_name
        if 'interpolated' not in features_df.columns:
            features_df['interpolated'] = False
        
        print("  ã‚¹ãƒ†ãƒƒãƒ—4/4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ä¸­...")
        features_df = self.handle_missing_values(features_df)
        features_df = self.create_court_features(features_df, court_coords)
        features_df = self.create_temporal_features(features_df)
        features_df = self.create_contextual_features(features_df)
        
        print(f"æœ€çµ‚ç‰¹å¾´é‡æ•°: {len(features_df.columns)}")
        return features_df
    
    def safe_create_dataframe_from_tracking_data(self, tracking_data: List[Dict], video_name: str) -> pd.DataFrame:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®‰å…¨ã«DataFrameã‚’ä½œæˆ"""
        if not tracking_data:
            return pd.DataFrame()
        try:
            return pd.DataFrame(tracking_data)
        except Exception as e:
            print(f"âŒ DataFrameä½œæˆã§ä¾‹å¤–ç™ºç”Ÿ: {e}")
            return self.handle_mixed_data_types_error_fast(tracking_data, video_name)
    
    def handle_mixed_data_types_error_fast(self, tracking_data: List[Dict], video_name: str) -> pd.DataFrame:
        """æ··åˆãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†ï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        print("=== æ··åˆãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼å¯¾å‡¦ä¸­ (NumPyé«˜é€ŸåŒ–) ===")
        all_keys = set()
        valid_frames = [frame for frame in tracking_data if isinstance(frame, dict)]
        if not valid_frames: return pd.DataFrame()
        for frame in valid_frames: all_keys.update(frame.keys())
        
        normalized_data = {}
        for key in all_keys:
            values = []
            for frame in valid_frames:
                value = frame.get(key)
                if value is None: values.append(0.0)
                elif isinstance(value, (int, float, bool)): values.append(float(value))
                elif isinstance(value, str):
                    try: values.append(float(value))
                    except ValueError: values.append(0.0)
                elif isinstance(value, (list, tuple)): values.append(float(value[0]) if len(value) > 0 and isinstance(value[0], (int, float)) else float(len(value)))
                elif isinstance(value, dict): values.append(np.sqrt(float(value.get('x',0))**2 + float(value.get('y',0))**2) if 'x' in value and 'y' in value else float(len(value)))
                else: values.append(0.0)
            normalized_data[key] = np.array(values, dtype=float)
        
        if 'frame_number' not in normalized_data:
            normalized_data['frame_number'] = np.arange(len(valid_frames), dtype=float)
        
        return pd.DataFrame(normalized_data)

    def create_court_features(self, features_df: pd.DataFrame, court_coords: Dict) -> pd.DataFrame:
            """ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ä½¿ç”¨ã—ãŸç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
            if not court_coords:
                print("ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return features_df
            
            court_df = features_df.copy()
            print("ã‚³ãƒ¼ãƒˆåº§æ¨™ç‰¹å¾´é‡ã‚’ä½œæˆä¸­... (NumPyé«˜é€ŸåŒ–)")
            
            # --- ãƒœãƒ¼ãƒ«ä½ç½®ã®ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»å¤‰æ› ---
            if all(col in court_df.columns for col in ['ball_x', 'ball_y']):
                ball_court_coords = self.transform_to_court_coordinates(
                    court_df['ball_x'].values, 
                    court_df['ball_y'].values, 
                    court_coords
                )
                
                court_df['ball_court_x'] = ball_court_coords['x']
                court_df['ball_court_y'] = ball_court_coords['y']
                
                ball_court_x = ball_court_coords['x']
                ball_court_y = ball_court_coords['y']
                
                # --- â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒå¾©å…ƒã™ã‚‹ç‰¹å¾´é‡è¨ˆç®— â˜…â˜…â˜… ---
                
                # ã‚³ãƒ¼ãƒˆä¸Šã®ä½ç½®ã«åŸºã¥ãç‰¹å¾´é‡ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
                court_df['ball_in_court'] = ((ball_court_x >= 0) & (ball_court_x <= 1) &
                                            (ball_court_y >= 0) & (ball_court_y <= 1)).astype(int)
                
                # ã‚³ãƒ¼ãƒˆä¸Šã®é ˜åŸŸç‰¹å¾´é‡ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
                court_df['ball_in_front_court'] = (ball_court_y > 0.5).astype(int)
                court_df['ball_in_back_court'] = (ball_court_y <= 0.5).astype(int)
                court_df['ball_in_left_court'] = (ball_court_x <= 0.5).astype(int)
                court_df['ball_in_right_court'] = (ball_court_x > 0.5).astype(int)
                
                # å„ç¨®è·é›¢ã®è¨ˆç®—ï¼ˆNumPyé…åˆ—ã§ä¸€æ‹¬è¨ˆç®—ï¼‰
                net_y = 0.5
                court_df['ball_distance_to_net'] = np.abs(ball_court_y - net_y)
                court_df['ball_distance_to_left_line'] = ball_court_x
                court_df['ball_distance_to_right_line'] = 1 - ball_court_x
                court_df['ball_distance_to_sideline'] = np.minimum(
                    court_df['ball_distance_to_left_line'],
                    court_df['ball_distance_to_right_line']
                )
                court_df['ball_distance_to_front_baseline'] = 1 - ball_court_y
                court_df['ball_distance_to_back_baseline'] = ball_court_y
                court_df['ball_distance_to_baseline'] = np.minimum(
                    court_df['ball_distance_to_front_baseline'],
                    court_df['ball_distance_to_back_baseline']
                )
            
            # --- ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½ç½®ã®ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»å¤‰æ› ---
            for player in ['front', 'back']:
                x_col, y_col = f'player_{player}_x', f'player_{player}_y'
                if x_col in court_df.columns and y_col in court_df.columns:
                    player_court_coords = self.transform_to_court_coordinates(
                        court_df[x_col].values, court_df[y_col].values, court_coords
                    )
                    court_df[f'player_{player}_court_x'] = player_court_coords['x']
                    court_df[f'player_{player}_court_y'] = player_court_coords['y']
                    
                    player_court_x, player_court_y = player_court_coords['x'], player_court_coords['y']
                    
                    court_df[f'player_{player}_in_court'] = ((player_court_x >= 0) & (player_court_x <= 1) &
                                                            (player_court_y >= 0) & (player_court_y <= 1)).astype(int)
                    court_df[f'player_{player}_distance_to_net'] = np.abs(player_court_y - 0.5)
            
            # --- ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“ã®é–¢ä¿‚ç‰¹å¾´é‡ï¼ˆã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ï¼‰ ---
            if all(col in court_df.columns for col in ['player_front_court_x', 'player_back_court_x']):
                front_x, front_y = court_df['player_front_court_x'].values, court_df['player_front_court_y'].values
                back_x, back_y = court_df['player_back_court_x'].values, court_df['player_back_court_y'].values
                
                court_df['players_court_distance'] = np.sqrt((front_x - back_x)**2 + (front_y - back_y)**2)
                court_df['players_correct_sides'] = (front_y > back_y).astype(int)
            
            # --- ãƒœãƒ¼ãƒ«ã¨ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é–¢ä¿‚ç‰¹å¾´é‡ï¼ˆã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ï¼‰ ---
            if 'ball_court_x' in court_df.columns:
                ball_court_x, ball_court_y = court_df['ball_court_x'].values, court_df['ball_court_y'].values
                for player in ['front', 'back']:
                    if f'player_{player}_court_x' in court_df.columns:
                        player_x, player_y = court_df[f'player_{player}_court_x'].values, court_df[f'player_{player}_court_y'].values
                        court_df[f'ball_to_{player}_court_distance'] = np.sqrt((ball_court_x - player_x)**2 + (ball_court_y - player_y)**2)
            
            print(f"ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(court_df.columns) - len(features_df.columns)}ç‰¹å¾´é‡è¿½åŠ ")
            return court_df
    
    def calculate_court_geometry(self, court_coords: Dict) -> Dict:
        """ã‚³ãƒ¼ãƒˆåº§æ¨™ã‹ã‚‰å¹¾ä½•å­¦çš„æƒ…å ±ã‚’è¨ˆç®—"""
        corners = {k: np.array(v) for k, v in court_coords.items() if 'corner' in k}
        return {
            'avg_width': (np.linalg.norm(corners['top_right'] - corners['top_left']) + np.linalg.norm(corners['bottom_right'] - corners['bottom_left'])) / 2,
            'avg_height': (np.linalg.norm(corners['bottom_left'] - corners['top_left']) + np.linalg.norm(corners['bottom_right'] - corners['top_right'])) / 2,
        }

    def transform_to_court_coordinates(self, x_coords: np.ndarray, y_coords: np.ndarray, 
                                     court_coords: Dict) -> Dict[str, np.ndarray]:
        """ç”»åƒåº§æ¨™ã‚’ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ã«å¤‰æ›ï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        tl, tr, bl, br = (np.array(court_coords[k]) for k in ['top_left_corner', 'top_right_corner', 'bottom_left_corner', 'bottom_right_corner'])
        
        court_x = np.full_like(x_coords, -1.0, dtype=float)
        court_y = np.full_like(y_coords, -1.0, dtype=float)
        valid_mask = ~(np.isnan(x_coords) | np.isnan(y_coords))
        if not np.any(valid_mask): return {'x': court_x, 'y': court_y}

        valid_x, valid_y = x_coords[valid_mask], y_coords[valid_mask]
        
        try:
            top_ratio = (valid_x - tl[0]) / (tr[0] - tl[0]) if (tr[0] - tl[0]) != 0 else np.full_like(valid_x, 0.5)
            bottom_ratio = (valid_x - bl[0]) / (br[0] - bl[0]) if (br[0] - bl[0]) != 0 else np.full_like(valid_x, 0.5)
            y_ratio = (valid_y - (top_ratio * tr[1] + (1 - top_ratio) * tl[1])) / \
                      ((bottom_ratio * br[1] + (1 - bottom_ratio) * bl[1]) - (top_ratio * tr[1] + (1 - top_ratio) * tl[1]))

            valid_court_x = y_ratio * bottom_ratio + (1 - y_ratio) * top_ratio
            valid_court_y = y_ratio
            
            court_x[valid_mask] = np.clip(valid_court_x, -0.5, 1.5)
            court_y[valid_mask] = np.clip(valid_court_y, -0.5, 1.5)
        except (ZeroDivisionError, ValueError):
            pass
        
        return {'x': court_x, 'y': court_y}
    
    def extract_all_features(self, video_name: str = None) -> pd.DataFrame:
        """ã™ã¹ã¦ã®å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦DataFrameã‚’çµ±åˆ"""
        print("=== æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºé–‹å§‹ ===")
        
        print("1. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        tracking_features = self.load_tracking_features(video_name)
        court_coordinates = self.load_court_coordinates(video_name)
        
        if not tracking_features:
            print("âŒ ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        print("\n2. ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚°ä¸­...")
        matched_data = self.match_video_data(tracking_features, court_coordinates)
        
        if not matched_data:
            print("âŒ ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        print("\n3. ç‰¹å¾´é‡æŠ½å‡ºä¸­...")
        all_features_list = []
        total_videos = len(matched_data)
        print(f"å‡¦ç†å¯¾è±¡å‹•ç”»æ•°: {total_videos}")
        
        for i, (vid_name, track_data, court_data) in enumerate(matched_data, 1):
            print(f"\n--- å‹•ç”»å‡¦ç†é€²æ—: [{i}/{total_videos}] - {vid_name} ---")
            try:
                features_df = self.extract_features_from_video(
                    vid_name, track_data, court_data
                )
                
                if not features_df.empty:
                    all_features_list.append(features_df)
                    print(f"âœ… ç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {len(features_df)}è¡Œ")
                else:
                    print(f"âš ï¸  ç‰¹å¾´é‡ãŒç©ºã§ã™: {vid_name}")
            except Exception as e:
                print(f"âŒ ç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼ ({vid_name}): {e}")
                import traceback
                traceback.print_exc()
                continue
        
        if all_features_list:
            print(f"\n4. ç‰¹å¾´é‡çµ±åˆä¸­... ({len(all_features_list)}å‹•ç”»)")
            combined_features = pd.concat(all_features_list, ignore_index=True)
            print("âœ… çµ±åˆå®Œäº†:")
            print(f"   ç·è¡Œæ•°: {len(combined_features)}")
            print(f"   ç·ç‰¹å¾´é‡æ•°: {len(combined_features.columns)}")
            if 'video_name' in combined_features.columns:
                print(f"   å‹•ç”»æ•°: {combined_features['video_name'].nunique()}")
            return combined_features
        else:
            print("âŒ æŠ½å‡ºã§ããŸç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
    
    def save_features(self, features_df: pd.DataFrame, filename: str = None) -> str:
        """ç‰¹å¾´é‡ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if features_df.empty:
            print("âš ï¸  ä¿å­˜ã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"tennis_inference_features_{timestamp}.csv"
        
        output_path = self.features_dir / filename
        
        try:
            features_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"âœ… ç‰¹å¾´é‡ä¿å­˜å®Œäº†: {output_path}")
            return str(output_path)
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def save_feature_info(self, features_df: pd.DataFrame, filename: str = None) -> str:
        """ç‰¹å¾´é‡ã®è©³ç´°æƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if features_df.empty:
            print("âš ï¸  ä¿å­˜ã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"tennis_inference_features_info_{timestamp}.json"
        
        output_path = self.features_dir / filename
        
        try:
            info = {
                'creation_time': datetime.now().isoformat(),
                'total_frames': len(features_df),
                'total_features': len(features_df.columns),
                'videos': features_df['video_name'].nunique() if 'video_name' in features_df.columns else 0,
                'video_list': features_df['video_name'].unique().tolist() if 'video_name' in features_df.columns else [],
                'feature_columns': features_df.columns.tolist(),
                'data_quality': {
                    'interpolated_frames': int(features_df.get('interpolated', pd.Series([False])).sum()),
                    'interpolation_rate': float(features_df.get('interpolated', pd.Series([False])).mean()),
                    'missing_values_summary': features_df.isnull().sum()[features_df.isnull().sum() > 0].to_dict()
                }
            }
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(info, f, indent=2, ensure_ascii=False)
            print(f"âœ… æ¨è«–ç”¨ç‰¹å¾´é‡æƒ…å ±ä¿å­˜å®Œäº†: {output_path}")
            return str(output_path)
        except Exception as e:
            print(f"âŒ æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def run_feature_extraction(self, video_name: str = None, save_results: bool = True) -> Tuple[pd.DataFrame, str, str]:
        """ç‰¹å¾´é‡æŠ½å‡ºã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ"""
        print("ğŸ¾ ãƒ†ãƒ‹ã‚¹å‹•ç”» æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹")
        print("=" * 50)
        
        features_df = self.extract_all_features(video_name)
        
        if features_df.empty:
            print("âŒ æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame(), "", ""
        
        feature_file, info_file = "", ""
        if save_results:
            print("\n5. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
            feature_file = self.save_features(features_df)
            info_file = self.save_feature_info(features_df)
        
        print("\nğŸ‰ æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹å®Œäº†!")
        print("=" * 50)
        
        return features_df, feature_file, info_file
    
    def analyze_features(self, features_df: pd.DataFrame):
        """ç‰¹å¾´é‡ã®çµ±è¨ˆåˆ†æã‚’è¡¨ç¤º"""
        if features_df.empty:
            print("âš ï¸  åˆ†æã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return
        
        print("\nğŸ“ˆ æ¨è«–ç”¨ç‰¹å¾´é‡åˆ†æçµæœ")
        print("=" * 30)
        
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(features_df):,}")
        print(f"   ç‰¹å¾´é‡æ•°: {len(features_df.columns)}")
        if 'video_name' in features_df.columns:
            print(f"   å‹•ç”»æ•°: {features_df['video_name'].nunique()}")
        
            print(f"\nğŸ¬ å‹•ç”»åˆ¥ãƒ•ãƒ¬ãƒ¼ãƒ æ•°:")
            video_counts = features_df['video_name'].value_counts()
            for video, count in video_counts.items():
                print(f"   {video}: {count:,}ãƒ•ãƒ¬ãƒ¼ãƒ ")

        if 'interpolated' in features_df.columns:
            interpolated_count = features_df['interpolated'].sum()
            interpolation_rate = interpolated_count / len(features_df) * 100 if len(features_df) > 0 else 0
            print(f"\nğŸ”§ ãƒ‡ãƒ¼ã‚¿å“è³ª:")
            print(f"   è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {interpolated_count:,}")
            print(f"   è£œé–“ç‡: {interpolation_rate:.1f}%")
        
        missing_counts = features_df.isnull().sum()
        missing_cols = missing_counts[missing_counts > 0]
        if not missing_cols.empty:
            print(f"\nâš ï¸  æ¬ æå€¤:")
            for col, count in missing_cols.items():
                print(f"   {col}: {count:,} ({count / len(features_df) * 100:.1f}%)")
        else:
            print(f"\nâœ… æ¬ æå€¤: ãªã—")


if __name__ == "__main__":
    default_input_dir = "./training_data" 
    
    if not Path(default_input_dir).exists():
        print(f"âš ï¸  ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{default_input_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        # Example of how to handle this case, e.g., by exiting or asking for input
        # exit()
        
    extractor = TennisInferenceFeatureExtractor(inference_data_dir=default_input_dir)
    video_to_process = None 

    features_dataframe, saved_feature_path, saved_info_path = extractor.run_feature_extraction(
        video_name=video_to_process,
        save_results=True
    )

    if not features_dataframe.empty:
        print(f"\n--- æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºæˆåŠŸ ---")
        if saved_feature_path:
            print(f"æ¨è«–ç”¨ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {saved_feature_path}")
        if saved_info_path:
            print(f"æ¨è«–ç”¨ç‰¹å¾´é‡æƒ…å ±ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {saved_info_path}")

        print("\n--- ç‰¹å¾´é‡åˆ†æé–‹å§‹ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ---")
        extractor.analyze_features(features_dataframe)
        print("--- ç‰¹å¾´é‡åˆ†æå®Œäº† ---")
    else:
        print("\n--- æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºå¤±æ•— ---")
        print("å‡¦ç†ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒãªã‹ã£ãŸã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    print("\nãƒ¡ã‚¤ãƒ³å‡¦ç†å®Œäº†")