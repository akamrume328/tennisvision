import json
import pandas as pd
import numpy as np
import os
import glob
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import warnings
from tqdm import tqdm # tqdmã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

warnings.filterwarnings('ignore')

class TennisInferenceFeatureExtractor: # ã‚¯ãƒ©ã‚¹åã‚’å¤‰æ›´
    """
    ãƒ†ãƒ‹ã‚¹å‹•ç”»ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ã‹ã‚‰ã€æ¨è«–ç”¨ã®ç‰¹å¾´é‡ã‚’ä½œæˆã™ã‚‹ã‚¯ãƒ©ã‚¹
    ï¼ˆå±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã¯ä½¿ç”¨ã—ãªã„ï¼‰
    """
    
    def __init__(self, inference_data_dir: str = "inference_data", court_data_dir: Optional[str] = None): # court_data_dir å¼•æ•°ã‚’è¿½åŠ 
        self.inference_data_dir = Path(inference_data_dir)
        self.court_data_dir = Path(court_data_dir) if court_data_dir else None # court_data_dir ã‚’åˆæœŸåŒ–
        self.features_dir = Path("./training_data/predict_features") # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’æŒ‡å®šã®ãƒ‘ã‚¹ã«å¤‰æ›´
        self.features_dir.mkdir(parents=True, exist_ok=True) # parents=True ã‚’è¿½åŠ ã—ã¦è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚ä½œæˆ
        
        # phase_labels ã¨ label_to_id ã¯æ¨è«–æ™‚ã«ã¯ä¸è¦ãªãŸã‚å‰Šé™¤
        
        print(f"æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ") # printæ–‡ã‚’å¤‰æ›´
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°): {self.inference_data_dir}") # printæ–‡ã‚’å¤‰æ›´
        if self.court_data_dir:
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ã‚³ãƒ¼ãƒˆåº§æ¨™): {self.court_data_dir}")
        else:
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ã‚³ãƒ¼ãƒˆåº§æ¨™): æŒ‡å®šãªã— (ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.inference_data_dir}' å†…ã‚’æ¢ç´¢)")
        print(f"ç‰¹å¾´é‡ä¿å­˜å…ˆ: {self.features_dir}") # printæ–‡ã‚’å¤‰æ›´
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    # load_phase_annotations ãƒ¡ã‚½ãƒƒãƒ‰ã¯æ¨è«–æ™‚ã«ã¯ä¸è¦ãªãŸã‚å‰Šé™¤
    
    def load_tracking_features(self, video_name: str = None) -> Dict[str, Dict]:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰"""
        pattern = "tracking_features_*.json"
        if video_name:
            pattern = f"tracking_features_{video_name}_*.json"
        
        tracking_files = list(self.inference_data_dir.glob(pattern)) # å‚ç…§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¤‰æ›´
        
        if not tracking_files:
            print(f"âš ï¸  ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern} in {self.inference_data_dir}") # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹è¿½åŠ 
            return {}
        
        all_tracking = {}
        for file_path in tracking_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å‹•ç”»åã‚’æ¨å®š
                filename_parts = file_path.stem.split('_')
                if len(filename_parts) >= 3:
                    # tracking_features_video_name_timestamp ã®å½¢å¼ã‚’æƒ³å®š
                    video_key = '_'.join(filename_parts[2:-1])  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’é™¤å»
                else:
                    video_key = file_path.stem
                
                # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ–°å½¢å¼ã‹æ—§å½¢å¼ã‹ï¼‰
                if isinstance(data, dict) and 'metadata' in data and 'frames' in data:
                    # æ–°å½¢å¼ï¼šãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãŒåˆ†é›¢ã•ã‚Œã¦ã„ã‚‹
                    all_tracking[video_key] = data
                    print(f"âœ… ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆæ–°å½¢å¼ï¼‰: {file_path.name}")
                    print(f"   å‹•ç”»: {video_key}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(data['frames'])}")
                    if 'frame_skip' in data['metadata']:
                        print(f"   ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {data['metadata']['frame_skip']}")
                elif isinstance(data, list):
                    # æ—§å½¢å¼ï¼šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®ã¿ã®ãƒªã‚¹ãƒˆ
                    all_tracking[video_key] = {
                        'metadata': {'frame_skip': 1, 'legacy_format': True},
                        'frames': data
                    }
                    print(f"âœ… ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆæ—§å½¢å¼ï¼‰: {file_path.name}")
                    print(f"   å‹•ç”»: {video_key}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(data)}")
                    print(f"   æ³¨æ„: æ—§å½¢å¼ã®ãŸã‚ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãªã—")
                else:
                    print(f"âš ï¸  ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿å½¢å¼: {file_path.name}")
                    print(f"   ãƒ‡ãƒ¼ã‚¿å‹: {type(data)}")
                    if isinstance(data, dict):
                        print(f"   ã‚­ãƒ¼: {list(data.keys())[:10]}")
                    continue
                
            except Exception as e:
                print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
        
        return all_tracking
    
    def load_court_coordinates(self, video_name: str = None) -> Dict[str, Dict]:
        """ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        pattern = "court_coords_*.json"
        if video_name:
            pattern = f"court_coords_{video_name}_*.json"
        
        # èª­ã¿è¾¼ã¿å…ƒã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±ºå®š
        data_source_dir = self.court_data_dir if self.court_data_dir else self.inference_data_dir
        
        court_files = list(data_source_dir.glob(pattern))
        
        if not court_files:
            print(f"âš ï¸  ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern} in {data_source_dir}") # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹è¿½åŠ 
            return {}
        
        all_court_coords = {}
        for file_path in court_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å‹•ç”»åã‚’æ¨å®š
                filename_parts = file_path.stem.split('_')
                if len(filename_parts) >= 3:
                    video_key = '_'.join(filename_parts[2:])  # court_coords_ã‚’é™¤ã
                else:
                    video_key = file_path.stem
                
                all_court_coords[video_key] = data
                print(f"âœ… ã‚³ãƒ¼ãƒˆåº§æ¨™èª­ã¿è¾¼ã¿: {file_path.name}")
                print(f"   å‹•ç”»: {video_key}")
                
            except Exception as e:
                print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
        
        return all_court_coords
    
    # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚°ãƒ»æ¤œè¨¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def match_video_data(self, tracking_features: Dict, court_coordinates: Dict = None) -> List[Tuple[str, Dict, Dict]]: # phase_annotations ã‚’å‰Šé™¤
        """å‹•ç”»åã§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ æ›´æ–°ãƒ»è¨ºæ–­å¼·åŒ–ï¼‰"""
        matched_data = []
        
        print("\n=== ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚° (æ¨è«–ç”¨) ===") # printæ–‡ã‚’å¤‰æ›´
        # print(f"å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»æ•°: {len(phase_annotations)}") # å‰Šé™¤
        print(f"ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡å‹•ç”»æ•°: {len(tracking_features)}")
        print(f"ã‚³ãƒ¼ãƒˆåº§æ¨™å‹•ç”»æ•°: {len(court_coordinates) if court_coordinates else 0}")
        
        print("\n--- åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ« ---")
        # print("å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³:") # å‰Šé™¤
        # for key in phase_annotations.keys(): # å‰Šé™¤
        #     print(f"  - {key}") # å‰Šé™¤
        print("ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡:")
        for key in tracking_features.keys():
            print(f"  - {key}")
        if court_coordinates:
            print("ã‚³ãƒ¼ãƒˆåº§æ¨™:")
            for key in court_coordinates.keys():
                print(f"  - {key}")
        
        print("\n--- ãƒãƒƒãƒãƒ³ã‚°å‡¦ç† ---")
        
        for video_name in tracking_features.keys(): # tracking_features ã‚’åŸºæº–ã«å¤‰æ›´
            tracking_data = tracking_features[video_name] # tracking_data ã‚’ç›´æ¥ä½¿ç”¨
            court_data = None
            # tracking_match_type = "ãªã—" # å‰Šé™¤
            court_match_type = "ãªã—"
            # tracking_matched_key = "" # å‰Šé™¤
            court_matched_key = ""
            
            print(f"\nğŸ¯ å‡¦ç†ä¸­: {video_name}")
            
            # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ã¯ä¸è¦ (tracking_features ã‚’åŸºæº–ã¨ã™ã‚‹ãŸã‚)
            
            # ã‚³ãƒ¼ãƒˆåº§æ¨™ã®ãƒãƒƒãƒãƒ³ã‚°
            if court_coordinates:
                if video_name in court_coordinates:
                    court_data = court_coordinates[video_name]
                    court_match_type = "å®Œå…¨ä¸€è‡´"
                    court_matched_key = video_name
                    print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… å®Œå…¨ä¸€è‡´ - {video_name}")
                else:
                    # éƒ¨åˆ†ãƒãƒƒãƒã‚’è©¦è¡Œ
                    for court_key in court_coordinates.keys():
                        if video_name in court_key: # video_name ãŒ court_key ã«å«ã¾ã‚Œã‚‹å ´åˆ
                            court_data = court_coordinates[court_key]
                            court_match_type = "éƒ¨åˆ†ä¸€è‡´(å‹•ç”»åãŒã‚­ãƒ¼ã«å«ã¾ã‚Œã‚‹)"
                            court_matched_key = court_key
                            print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… éƒ¨åˆ†ä¸€è‡´ - {video_name} âŠ† {court_key}")
                            break
                        elif court_key in video_name: # court_key ãŒ video_name ã«å«ã¾ã‚Œã‚‹å ´åˆ
                            court_data = court_coordinates[court_key]
                            court_match_type = "éƒ¨åˆ†ä¸€è‡´(ã‚­ãƒ¼ãŒå‹•ç”»åã«å«ã¾ã‚Œã‚‹)"
                            court_matched_key = court_key
                            print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… éƒ¨åˆ†ä¸€è‡´ - {court_key} âŠ† {video_name}")
                            break
                    if not court_data:
                        print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âŒ ãƒãƒƒãƒãªã—")
            else:
                print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âŒ ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            # çµæœã®åˆ¤å®š (tracking_data ã¯å¸¸ã«å­˜åœ¨ã™ã‚‹ã¨ä»®å®š)
            matched_data.append((
                video_name,
                # phase_annotations[video_name], # å‰Šé™¤
                tracking_data,
                court_data
            ))
            
            frame_count = self.get_actual_frame_count(tracking_data)
            print(f"  âœ… ãƒãƒƒãƒãƒ³ã‚°æˆåŠŸ:")
            # print(f"     å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {video_name}") # å‰Šé™¤
            print(f"     ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°: {video_name}") # tracking_matched_key ã¨ tracking_match_type ã‚’å‰Šé™¤
            print(f"     å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
            if isinstance(tracking_data, dict) and 'metadata' in tracking_data:
                frame_skip = tracking_data['metadata'].get('frame_skip', 1)
                print(f"     ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {frame_skip}")
            if court_data:
                print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: {court_matched_key} ({court_match_type})")
            else:
                print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: ãªã—")
            # else: # å‰Šé™¤ (tracking_data ã¯å¸¸ã«å­˜åœ¨)
            #     print(f"  âŒ ãƒãƒƒãƒãƒ³ã‚°å¤±æ•—: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“") # å‰Šé™¤
        
        print(f"\n=== ãƒãƒƒãƒãƒ³ã‚°çµæœã‚µãƒãƒªãƒ¼ ===")
        print(f"âœ… ãƒãƒƒãƒãƒ³ã‚°æ•°: {len(matched_data)}") # è¡¨ç¾ã‚’å¤‰æ›´
        # print(f"âŒ å¤±æ•—ã—ãŸãƒãƒƒãƒãƒ³ã‚°: {len(phase_annotations) - len(matched_data)}") # å‰Šé™¤
        
        if matched_data:
            print("\nğŸ“‹ ãƒãƒƒãƒãƒ³ã‚°ä¸€è¦§:")
            for i, (video_name, tracking_data, court_data) in enumerate(matched_data, 1): # phase_data ã‚’å‰Šé™¤
                frame_count = self.get_actual_frame_count(tracking_data)
                court_status = "ã‚ã‚Š" if court_data else "ãªã—"
                print(f"  {i}. {video_name}")
                print(f"     ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
                print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: {court_status}")
        
        print(f"æœ€çµ‚ãƒãƒƒãƒãƒ³ã‚°æ•°: {len(matched_data)}")
        return matched_data
    
    def get_actual_frame_count(self, tracking_data) -> int:
        """å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«é–¢ä¿‚ãªãï¼‰"""
        if isinstance(tracking_data, list):
            return len(tracking_data)
        elif isinstance(tracking_data, dict):
            if 'frames' in tracking_data:
                frames = tracking_data['frames']
                return len(frames) if hasattr(frames, '__len__') else 0
            elif 'frame_data' in tracking_data:
                frame_data = tracking_data['frame_data']
                return len(frame_data) if hasattr(frame_data, '__len__') else 0
            else:
                # æ•°å€¤ã‚­ãƒ¼ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                numeric_keys = [k for k in tracking_data.keys() if str(k).isdigit()]
                return len(numeric_keys)
        else:
            return 0

    def validate_tracking_data_consistency(self, tracking_data_dict: Dict) -> Dict:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã‚’æ¤œè¨¼ï¼ˆè¨˜éŒ²ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
        validation_result = {
            'is_valid': True,
            'warnings': [],
            'frame_count': 0,
            'frame_skip_detected': False,
            'recorded_frame_skip': 1,
            'actual_frame_skip_interval': 1,
            'missing_frames': [],
            'duplicate_frames': [],
            'interpolated_count': 0,
            'metadata_available': False,
            'processing_mode': 'unknown'
        }
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯
        if isinstance(tracking_data_dict, list):
            # æ—§å½¢å¼
            tracking_data = tracking_data_dict
            validation_result['warnings'].append("æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        elif isinstance(tracking_data_dict, dict) and 'frames' in tracking_data_dict:
            # æ–°å½¢å¼
            tracking_data = tracking_data_dict['frames']
            metadata = tracking_data_dict.get('metadata', {})
            validation_result['metadata_available'] = True
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ã‚’å–å¾—
            recorded_skip = metadata.get('frame_skip', 1)
            processing_mode = metadata.get('processing_mode', 'unknown')
            
            validation_result['recorded_frame_skip'] = recorded_skip
            validation_result['processing_mode'] = processing_mode
            
            if recorded_skip > 1:
                validation_result['frame_skip_detected'] = True
                validation_result['warnings'].append(
                    f"è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {recorded_skip} (ãƒ¢ãƒ¼ãƒ‰: {processing_mode})"
                )
            
            # ä»–ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚‚æ¤œè¨¼
            if 'original_fps' in metadata:
                validation_result['original_fps'] = metadata['original_fps']
            if 'processing_fps' in metadata:
                validation_result['processing_fps'] = metadata['processing_fps']
            if 'total_original_frames' in metadata:
                validation_result['total_original_frames'] = metadata['total_original_frames']
        else:
            validation_result['is_valid'] = False
            validation_result['warnings'].append("ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã™")
            return validation_result
        
        validation_result['frame_count'] = len(tracking_data)
        
        if not tracking_data:
            validation_result['is_valid'] = False
            validation_result['warnings'].append("ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return validation_result
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        frame_numbers = [data.get('frame_number', 0) for data in tracking_data]
        frame_numbers.sort()
        
        # é‡è¤‡ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒã‚§ãƒƒã‚¯
        from collections import Counter
        frame_counts = Counter(frame_numbers)
        duplicates = [frame for frame, count in frame_counts.items() if count > 1]
        if duplicates:
            validation_result['duplicate_frames'] = duplicates
            validation_result['warnings'].append(f"é‡è¤‡ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {duplicates}")
        
        # å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã®æ¤œå‡ºã¨è¨˜éŒ²å€¤ã¨ã®æ¯”è¼ƒ
        intervals = []
        missing_frames = []
        
        for i in range(1, len(frame_numbers)):
            interval = frame_numbers[i] - frame_numbers[i-1]
            if interval > 1:
                intervals.append(interval)
                # æ¬ æãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¨˜éŒ²
                for missing in range(frame_numbers[i-1] + 1, frame_numbers[i]):
                    missing_frames.append(missing)
            elif interval == 1:
                intervals.append(1)
        
        if intervals:
            # æœ€ã‚‚é »ç¹ãªé–“éš”ã‚’ã‚¹ã‚­ãƒƒãƒ—é–“éš”ã¨ã—ã¦åˆ¤å®š
            interval_counts = Counter(intervals)
            most_common_interval = interval_counts.most_common(1)[0][0]
            
            validation_result['actual_frame_skip_interval'] = most_common_interval
            
            # è¨˜éŒ²ã•ã‚ŒãŸå€¤ã¨å®Ÿéš›ã®å€¤ã‚’æ¯”è¼ƒ
            recorded_skip = validation_result['recorded_frame_skip']
            if recorded_skip > 1:
                if most_common_interval == recorded_skip:
                    validation_result['warnings'].append(
                        f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æ•´åˆæ€§ç¢ºèª: è¨˜éŒ²å€¤({recorded_skip}) = å®Ÿæ¸¬å€¤({most_common_interval})"
                    )
                else:
                    validation_result['warnings'].append(
                        f"âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ä¸æ•´åˆ: è¨˜éŒ²å€¤({recorded_skip}) â‰  å®Ÿæ¸¬å€¤({most_common_interval})"
                    )
            elif most_common_interval > 1:
                validation_result['warnings'].append(
                    f"âš ï¸  è¨˜éŒ²ãªã—ã‚¹ã‚­ãƒƒãƒ—æ¤œå‡º: å®Ÿæ¸¬é–“éš”({most_common_interval})"
                )
        
        validation_result['missing_frames'] = missing_frames
        
        # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚«ã‚¦ãƒ³ãƒˆ
        interpolated_count = sum(1 for data in tracking_data if data.get('interpolated', False))
        validation_result['interpolated_count'] = interpolated_count
        
        if interpolated_count > 0:
            validation_result['warnings'].append(f"è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {interpolated_count}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªã®è©•ä¾¡
        ball_detection_rate = sum(1 for data in tracking_data if data.get('ball_detected', 0)) / len(tracking_data)
        validation_result['ball_detection_rate'] = ball_detection_rate
        
        if ball_detection_rate < 0.3:
            validation_result['warnings'].append(f"ãƒœãƒ¼ãƒ«æ¤œå‡ºç‡ãŒä½ã„ã§ã™: {ball_detection_rate:.1%}")
        
        return validation_result
    
    # ãƒ‡ãƒ¼ã‚¿è¨ºæ–­ãƒ»ä»£æ›¿èª­ã¿è¾¼ã¿ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def diagnose_tracking_data_structure(self, tracking_data_dict: Dict, video_name: str):
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®è©³ç´°è¨ºæ–­"""
        print(f"\n=== {video_name} ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨ºæ–­ ===")
        
        if isinstance(tracking_data_dict, dict):
            print("ãƒ‡ãƒ¼ã‚¿æ§‹é€ : è¾æ›¸å‹")
            print(f"ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚­ãƒ¼: {list(tracking_data_dict.keys())}")
            
            if 'frames' in tracking_data_dict:
                frames_data = tracking_data_dict['frames']
                print(f"framesè¦ç´ å‹: {type(frames_data)}")
                print(f"framesè¦ç´ æ•°: {len(frames_data) if hasattr(frames_data, '__len__') else 'N/A'}")
                
                if isinstance(frames_data, list) and len(frames_data) > 0:
                    sample_frame = frames_data[0]
                    print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ å‹: {type(sample_frame)}")
                    if isinstance(sample_frame, dict):
                        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚­ãƒ¼æ•°: {len(sample_frame.keys())}")
                        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚­ãƒ¼ä¾‹: {list(sample_frame.keys())[:10]}")
                
            if 'metadata' in tracking_data_dict:
                metadata = tracking_data_dict['metadata']
                print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata}")
        
        elif isinstance(tracking_data_dict, list):
            print("ãƒ‡ãƒ¼ã‚¿æ§‹é€ : ãƒªã‚¹ãƒˆå‹")
            print(f"è¦ç´ æ•°: {len(tracking_data_dict)}")
            if len(tracking_data_dict) > 0:
                sample = tracking_data_dict[0]
                print(f"ã‚µãƒ³ãƒ—ãƒ«è¦ç´ å‹: {type(sample)}")
        
        else:
            print(f"ãƒ‡ãƒ¼ã‚¿æ§‹é€ : ä¸æ˜ãªå‹ - {type(tracking_data_dict)}")
    
    def attempt_alternative_data_loading(self, video_name: str) -> List[Dict]:
        """ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è©¦è¡Œ"""
        print(f"=== {video_name} ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è©¦è¡Œ ===")
        
        # tracking_features_*.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥å†èª­ã¿è¾¼ã¿
        pattern = f"tracking_features_{video_name}_*.json"
        tracking_files = list(self.inference_data_dir.glob(pattern))
        
        if not tracking_files:
            print(f"å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
            return []
        
        for file_path in tracking_files:
            try:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«å†èª­ã¿è¾¼ã¿è©¦è¡Œ: {file_path.name}")
                
                with open(file_path, 'r', encoding='utf-8') as f:
                    raw_data = json.load(f)
                
                print(f"ç”Ÿãƒ‡ãƒ¼ã‚¿å‹: {type(raw_data)}")
                
                # æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¯¾å¿œ
                if isinstance(raw_data, list):
                    print(f"ãƒªã‚¹ãƒˆå½¢å¼: {len(raw_data)}è¦ç´ ")
                    return raw_data
                elif isinstance(raw_data, dict):
                    print(f"è¾æ›¸å½¢å¼ã‚­ãƒ¼: {list(raw_data.keys())}")
                    
                    # 'frames'ã‚­ãƒ¼ã‚’å„ªå…ˆ
                    if 'frames' in raw_data:
                        frames = raw_data['frames']
                        print(f"framesã‚­ãƒ¼: {type(frames)}, è¦ç´ æ•°: {len(frames) if hasattr(frames, '__len__') else 'N/A'}")
                        if isinstance(frames, list):
                            return frames
                    
                    # 'frame_data'ã‚­ãƒ¼ã‚’è©¦è¡Œ
                    if 'frame_data' in raw_data:
                        frame_data = raw_data['frame_data']
                        print(f"frame_dataã‚­ãƒ¼: {type(frame_data)}, è¦ç´ æ•°: {len(frame_data) if hasattr(frame_data, '__len__') else 'N/A'}")
                        if isinstance(frame_data, list):
                            return frame_data
                    
                    # æ•°å€¤ã‚­ãƒ¼ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ï¼‰ã‚’æ¢ç´¢
                    numeric_keys = [k for k in raw_data.keys() if str(k).isdigit()]
                    if numeric_keys:
                        print(f"æ•°å€¤ã‚­ãƒ¼æ¤œå‡º: {len(numeric_keys)}å€‹")
                        # æ•°å€¤ã‚­ãƒ¼ã‹ã‚‰è¾æ›¸ã‚’æ§‹ç¯‰
                        frame_list = []
                        for key in sorted(numeric_keys, key=int):
                            frame_data = raw_data[key]
                            if isinstance(frame_data, dict):
                                frame_data['frame_number'] = int(key)
                                frame_list.append(frame_data)
                        
                        if frame_list:
                            print(f"æ•°å€¤ã‚­ãƒ¼ã‹ã‚‰æ§‹ç¯‰: {len(frame_list)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                            return frame_list
                
                print("âš ï¸  èªè­˜å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
                
            except Exception as e:
                print(f"ä»£æ›¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return []
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ æ­£è¦åŒ–ãƒ»è£œé–“ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def normalize_frame_numbers(self, tracking_data_dict: Dict) -> List[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’æ­£è¦åŒ–ã—ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚’è€ƒæ…®ã—ãŸå±•é–‹ã‚’è¡Œã†"""
        print("=== ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–ãƒ»å±•é–‹å‡¦ç† ===")
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯
        if isinstance(tracking_data_dict, list):
            # æ—§å½¢å¼ã®å ´åˆã¯å¾“æ¥ã®å‡¦ç†
            print("âš ï¸  æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return self.legacy_normalize_frame_numbers(tracking_data_dict)
        
        # æ–°å½¢å¼ã®å‡¦ç†ï¼šãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚’è€ƒæ…®ã—ãŸå±•é–‹
        metadata = tracking_data_dict.get('metadata', {})
        frame_skip = metadata.get('frame_skip', 1)
        
        print(f"âœ… è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±: {frame_skip}")
        
        if frame_skip == 1:
            # ã‚¹ã‚­ãƒƒãƒ—ãªã—ã®å ´åˆã¯é€šå¸¸ã®æ­£è¦åŒ–ã®ã¿
            frames_data = tracking_data_dict.get('frames', [])
            print("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ãªã— - é€šå¸¸ã®æ­£è¦åŒ–ã‚’å®Ÿè¡Œ")
            return frames_data
        else:
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚ã‚Šã®å ´åˆã¯å±•é–‹å‡¦ç†
            print(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—({frame_skip})ã‚’æ¤œå‡º - å…ƒã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¸ã®å±•é–‹ã‚’å®Ÿè¡Œ")
            expanded_frames = self.expand_frames_to_original_sequence(tracking_data_dict)
            return expanded_frames
    
    def legacy_normalize_frame_numbers(self, tracking_data: List[Dict]) -> List[Dict]:
        """æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–"""
        if not tracking_data:
            return []
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã§ã‚½ãƒ¼ãƒˆ
        sorted_data = sorted(tracking_data, key=lambda x: x.get('frame_number', 0))
        
        # é€£ç¶šã—ãŸç•ªå·ã«æ­£è¦åŒ–
        for i, frame_data in enumerate(tqdm(sorted_data, desc="æ—§å½¢å¼ãƒ•ãƒ¬ãƒ¼ãƒ æ­£è¦åŒ–", leave=False)):
            frame_data['original_frame_number'] = frame_data.get('frame_number', 0)
            frame_data['frame_number'] = i
            frame_data['interpolated'] = False
        
        return sorted_data
    
    def expand_frames_to_original_sequence(self, tracking_data_dict: Dict) -> List[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã®å‹•ç”»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å±•é–‹"""
        print("=== ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å±•é–‹å‡¦ç† ===")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata = tracking_data_dict['metadata']
        frames_data = tracking_data_dict['frames']
        frame_skip = metadata.get('frame_skip', 1)
        total_original_frames = metadata.get('total_original_frames')
        
        print(f"è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {frame_skip}")
        print(f"å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(frames_data)}")
        if total_original_frames:
            print(f"å…ƒå‹•ç”»ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_original_frames}")
        
        # å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã§ã‚½ãƒ¼ãƒˆ
        sorted_frames = sorted(frames_data, key=lambda x: x.get('frame_number', 0))
        
        if not sorted_frames:
            print("å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return []
        
        # æœ€åˆã¨æœ€å¾Œã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’å–å¾—
        first_processed_frame = sorted_frames[0].get('frame_number', 0)
        last_processed_frame = sorted_frames[-1].get('frame_number', 0)
        
        print(f"æœ€åˆã®å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ : {first_processed_frame}")
        print(f"æœ€å¾Œã®å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ : {last_processed_frame}")
        
        # å…ƒå‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’æ¨å®šï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆï¼‰
        if total_original_frames is None:
            estimated_total = last_processed_frame + frame_skip
            total_original_frames = estimated_total
            print(f"æ¨å®šç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {estimated_total}")
        
        # å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        processed_frame_map = {}
        for frame_data in sorted_frames:
            original_frame_num = frame_data.get('frame_number', 0)
            processed_frame_map[original_frame_num] = frame_data
        
        # å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å†æ§‹ç¯‰
        expanded_frames = []
        interpolated_count = 0
        
        for original_frame_num in tqdm(range(total_original_frames), desc="ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å±•é–‹", leave=False):
            if original_frame_num in processed_frame_map:
                # å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã®ã¾ã¾ä½¿ç”¨
                frame_data = processed_frame_map[original_frame_num].copy()
                frame_data['original_frame_number'] = original_frame_num
                frame_data['interpolated'] = False
                expanded_frames.append(frame_data)
            else:
                # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                interpolated_frame = self.create_interpolated_frame_from_skip(
                    original_frame_num, processed_frame_map, frame_skip
                )
                expanded_frames.append(interpolated_frame)
                interpolated_count += 1
        
        print(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ å±•é–‹å®Œäº†:")
        print(f"   å±•é–‹å¾Œç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(expanded_frames)}")
        print(f"   å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(sorted_frames)}")
        print(f"   è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {interpolated_count}")
        print(f"   è£œé–“ç‡: {interpolated_count/len(expanded_frames)*100:.1f}%")
        
        return expanded_frames
    
    def create_interpolated_frame_from_skip(self, target_frame_num: int, 
                                          processed_frame_map: Dict, frame_skip: int) -> Dict:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã«ã‚ˆã‚‹æ¬ æã‚’è£œé–“ã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        # å‰å¾Œã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã™
        prev_frame_data = None
        next_frame_data = None
        
        # å‰ã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã™
        for i in range(target_frame_num - 1, -1, -1):
            if i in processed_frame_map:
                prev_frame_data = processed_frame_map[i]
                break
        
        # æ¬¡ã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã™
        max_search_range = target_frame_num + frame_skip * 2
        for i in range(target_frame_num + 1, max_search_range):
            if i in processed_frame_map:
                next_frame_data = processed_frame_map[i]
                break
        
        # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        interpolated_frame = {
            'frame_number': target_frame_num,
            'original_frame_number': target_frame_num,
            'interpolated': True,
            'timestamp': '',
            'ball_detected': 0,
            'ball_x': None,
            'ball_y': None,
            'ball_x_normalized': 0,
            'ball_y_normalized': 0,
            'ball_movement_score': 0,
            'ball_tracking_confidence': 0,
            'ball_velocity_x': 0,
            'ball_velocity_y': 0,
            'ball_speed': 0,
            'player_front_count': 0,
            'player_back_count': 0,
            'total_players': 0,
            'candidate_balls_count': 0,
            'disappeared_count': 0,
            'trajectory_length': 0,
            'prediction_active': 0
        }
        
        # å‰å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã¯è£œé–“
        if prev_frame_data and next_frame_data:
            prev_frame_num = prev_frame_data.get('frame_number', 0)
            next_frame_num = next_frame_data.get('frame_number', 0)
            
            if next_frame_num > prev_frame_num:
                # ç·šå½¢è£œé–“ã®æ¯”ç‡ã‚’è¨ˆç®—
                ratio = (target_frame_num - prev_frame_num) / (next_frame_num - prev_frame_num)
                ratio = max(0, min(1, ratio))
                
                # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ç·šå½¢è£œé–“
                numeric_keys = [
                    'ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized',
                    'ball_velocity_x', 'ball_velocity_y', 'ball_speed',
                    'ball_movement_score', 'ball_tracking_confidence',
                    'player_front_x', 'player_front_y', 'player_front_x_normalized', 'player_front_y_normalized',
                    'player_back_x', 'player_back_y', 'player_back_x_normalized', 'player_back_y_normalized',
                    'player_front_confidence', 'player_back_confidence',
                    'player_distance', 'player_distance_normalized'
                ]
                
                for key in numeric_keys:
                    prev_val = prev_frame_data.get(key)
                    next_val = next_frame_data.get(key)
                    
                    if prev_val is not None and next_val is not None:
                        interpolated_val = prev_val + (next_val - prev_val) * ratio
                        interpolated_frame[key] = interpolated_val
                    elif prev_val is not None:
                        interpolated_frame[key] = prev_val
                    elif next_val is not None:
                        interpolated_frame[key] = next_val
        
        elif prev_frame_data:
            # å‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚ã‚‹å ´åˆã€å€¤ã‚’ç¶™æ‰¿
            for key in ['ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized',
                       'player_front_x', 'player_front_y', 'player_back_x', 'player_back_y']:
                if key in prev_frame_data:
                    interpolated_frame[key] = prev_frame_data[key]
        
        elif next_frame_data:
            # æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚ã‚‹å ´åˆã€å€¤ã‚’ç¶™æ‰¿
            for key in ['ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized',
                       'player_front_x', 'player_front_y', 'player_back_x', 'player_back_y']:
                if key in next_frame_data:
                    interpolated_frame[key] = next_frame_data[key]
        
        return interpolated_frame
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def safe_create_dataframe_from_tracking_data(self, tracking_data: List[Dict], video_name: str) -> pd.DataFrame:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®‰å…¨ã«DataFrameã‚’ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼å¯¾ç­–å¼·åŒ–ï¼‰"""
        if not tracking_data:
            print("âš ï¸  ç©ºã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿")
            return pd.DataFrame()
        
        try:
            # æ–¹æ³•1: æ¨™æº–çš„ãªDataFrameä½œæˆã‚’è©¦è¡Œ
            if all(isinstance(frame, dict) for frame in tracking_data):
                return pd.DataFrame(tracking_data)
            else:
                print("âš ï¸  éè¾æ›¸å½¢å¼ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                # è¾æ›¸å½¢å¼ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
                valid_frames = [frame for frame in tracking_data if isinstance(frame, dict)]
                if valid_frames:
                    return pd.DataFrame(valid_frames)
                else:
                    print("âŒ æœ‰åŠ¹ãªè¾æ›¸å½¢å¼ãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return pd.DataFrame()
                
        except ValueError as e:
            if "Mixing dicts with non-Series" in str(e):
                print(f"âš ï¸  DataFrameä½œæˆã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º: {e}")
                return self.handle_mixed_data_types_error(tracking_data, video_name)
            else:
                print(f"âŒ äºˆæœŸã—ãªã„DataFrameä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
                return pd.DataFrame()
        except Exception as e:
            print(f"âŒ DataFrameä½œæˆã§ä¾‹å¤–ç™ºç”Ÿ: {e}")
            return self.handle_mixed_data_types_error(tracking_data, video_name)
    
    def handle_mixed_data_types_error(self, tracking_data: List[Dict], video_name: str) -> pd.DataFrame:
        """æ··åˆãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        print("=== æ··åˆãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼å¯¾å‡¦ä¸­ ===")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è©³ç´°åˆ†æ
            print(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(tracking_data)}")
            if tracking_data:
                sample_frame = tracking_data[0]
                print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ å‹: {type(sample_frame)}")
                if isinstance(sample_frame, dict):
                    print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ¼æ•°: {len(sample_frame.keys())}")
                    print(f"ã‚­ãƒ¼ä¾‹: {list(sample_frame.keys())[:10]}")
            
            # æ”¹å–„ã•ã‚ŒãŸæ­£è¦åŒ–å‡¦ç†
            normalized_frames = []
            for i, frame in enumerate(tracking_data):
                if isinstance(frame, dict):
                    normalized_frame = {'frame_number': i}  # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’è¨­å®š
                    
                    for key, value in frame.items():
                        try:
                            # å€¤ã®å‹ã«å¿œã˜ã¦é©åˆ‡ã«å‡¦ç†
                            if value is None:
                                normalized_frame[key] = 0
                            elif isinstance(value, (int, float)):
                                normalized_frame[key] = float(value)
                            elif isinstance(value, bool):
                                normalized_frame[key] = int(value)
                            elif isinstance(value, str):
                                # æ•°å€¤ã«å¤‰æ›å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                                try:
                                    normalized_frame[key] = float(value)
                                except ValueError:
                                    normalized_frame[key] = 0
                            elif isinstance(value, (list, tuple)):
                                # ãƒªã‚¹ãƒˆã®å ´åˆã¯é•·ã•ã¾ãŸã¯æœ€åˆã®å€¤ã‚’ä½¿ç”¨
                                if len(value) > 0:
                                    first_val = value[0]
                                    if isinstance(first_val, (int, float)):
                                        normalized_frame[key] = float(first_val)
                                    else:
                                        normalized_frame[key] = len(value)
                                else:
                                    normalized_frame[key] = 0
                            elif isinstance(value, dict):
                                # è¾æ›¸ã®å ´åˆã¯å±•é–‹ã¾ãŸã¯è¦ç´„
                                if 'x' in value and 'y' in value:
                                    normalized_frame[f'{key}_x'] = float(value.get('x', 0))
                                    normalized_frame[f'{key}_y'] = float(value.get('y', 0))
                                elif len(value) == 1:
                                    # å˜ä¸€ã‚­ãƒ¼ã®å ´åˆã¯ãã®å€¤ã‚’ä½¿ç”¨
                                    single_key = list(value.keys())[0]
                                    single_val = value[single_key]
                                    if isinstance(single_val, (int, float)):
                                        normalized_frame[key] = float(single_val)
                                    else:
                                        normalized_frame[key] = 1
                                else:
                                    normalized_frame[key] = len(value)
                            else:
                                # ãã®ä»–ã®å‹ã¯0ã«è¨­å®š
                                normalized_frame[key] = 0
                        except Exception as e:
                            print(f"ã‚­ãƒ¼ '{key}' ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                            normalized_frame[key] = 0
                    
                    normalized_frames.append(normalized_frame)
                else:
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {i} ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(frame)}")
            
            if normalized_frames:
                print(f"âœ… ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–å®Œäº†: {len(normalized_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                
                # DataFrameã®å®‰å…¨ãªä½œæˆ
                try:
                    # å…¨ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§å…±é€šã®ã‚­ãƒ¼ã‚»ãƒƒãƒˆã‚’ä½œæˆ
                    all_keys = set()
                    for frame in normalized_frames:
                        all_keys.update(frame.keys())
                    
                    # æ¬ æã‚­ãƒ¼ã‚’è£œå®Œ
                    for frame in normalized_frames:
                        for key in all_keys:
                            if key not in frame:
                                frame[key] = 0
                    
                    df = pd.DataFrame(normalized_frames)
                    print(f"DataFrameä½œæˆæˆåŠŸ: {df.shape}")
                    return df
                    
                except Exception as df_error:
                    print(f"DataFrameä½œæˆã§ã‚¨ãƒ©ãƒ¼: {df_error}")
                    # æœ€å°é™ã®DataFrameã‚’ä½œæˆ
                    basic_df = pd.DataFrame({
                        'frame_number': range(len(normalized_frames)),
                        'ball_detected': [frame.get('ball_detected', 0) for frame in normalized_frames],
                        'ball_x': [frame.get('ball_x', 0) for frame in normalized_frames],
                        'ball_y': [frame.get('ball_y', 0) for frame in normalized_frames]
                    })
                    print(f"åŸºæœ¬DataFrameä½œæˆ: {basic_df.shape}")
                    return basic_df
            else:
                print("âŒ æ­£è¦åŒ–å¯èƒ½ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
                return pd.DataFrame()
                
        except Exception as e2:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã§ã‚‚ã‚¨ãƒ©ãƒ¼: {e2}")
            # ç©ºã®DataFrameã‚’è¿”ã™
            return pd.DataFrame()
    
    # ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰
    def extract_features_from_video(self, video_name: str, tracking_data_dict: Dict, court_coords: Dict = None) -> pd.DataFrame: # phase_data ã‚’å‰Šé™¤
        """å˜ä¸€å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆè¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±å¯¾å¿œï¼‰"""
        print(f"\n--- æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡º: {video_name} ---") # printæ–‡ã‚’å¤‰æ›´
        
        # ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã‚’æ¤œè¨¼
        print("  ã‚¹ãƒ†ãƒƒãƒ—1/4: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ä¸­...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        validation_result = self.validate_tracking_data_consistency(tracking_data_dict)
        
        print("  === ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµæœ ===")
        print(f"ãƒ‡ãƒ¼ã‚¿å“è³ª: {'è‰¯å¥½' if validation_result['is_valid'] else 'å•é¡Œã‚ã‚Š'}")
        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {validation_result['frame_count']}")
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {'ã‚ã‚Š' if validation_result['metadata_available'] else 'ãªã—ï¼ˆæ—§å½¢å¼ï¼‰'}")
        
        if validation_result['metadata_available']:
            print(f"å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {validation_result['processing_mode']}")
            print(f"è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {validation_result['recorded_frame_skip']}")
            print(f"å®Ÿæ¸¬ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {validation_result['actual_frame_skip_interval']}")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°æƒ…å ±
            if isinstance(tracking_data_dict, dict) and 'metadata' in tracking_data_dict:
                metadata = tracking_data_dict['metadata']
                if 'original_fps' in metadata and metadata['original_fps']:
                    print(f"å…ƒFPS: {metadata['original_fps']}")
                if 'processing_fps' in metadata and metadata['processing_fps']:
                    print(f"å‡¦ç†FPS: {metadata['processing_fps']}")
                if 'total_original_frames' in metadata and metadata['total_original_frames']:
                    print(f"å…ƒå‹•ç”»ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {metadata['total_original_frames']}")
                if 'processing_efficiency' in metadata:
                    print(f"å‡¦ç†åŠ¹ç‡: {metadata['processing_efficiency']}")
        
        if validation_result['interpolated_count'] > 0:
            print(f"æ—¢å­˜è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {validation_result['interpolated_count']}")
        
        if validation_result['warnings']:
            for warning in validation_result['warnings']:
                print(f"ğŸ“‹ {warning}")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒç•°å¸¸ã«å°‘ãªã„å ´åˆã®è¨ºæ–­
        if validation_result['frame_count'] <= 10:
            print(f"âš ï¸  ç•°å¸¸ã«ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒå°‘ãªã„ã§ã™: {validation_result['frame_count']}")
            self.diagnose_tracking_data_structure(tracking_data_dict, video_name)
            
            # ç·Šæ€¥å¯¾å‡¦ï¼šå…ƒã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿è©¦è¡Œ
            alternative_data = self.attempt_alternative_data_loading(video_name)
            if alternative_data and len(alternative_data) > validation_result['frame_count']:
                print(f"âœ… ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(alternative_data)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¤ã¤ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
                current_metadata = tracking_data_dict.get('metadata', {'frame_skip': 1, 'legacy_format': True})
                tracking_data_dict = {
                    'metadata': current_metadata,
                    'frames': alternative_data
                }
                validation_result['frame_count'] = len(alternative_data) # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’æ›´æ–°
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’æ­£è¦åŒ–ï¼ˆè¨˜éŒ²ã•ã‚ŒãŸã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ã‚’ä½¿ç”¨ï¼‰
        print("  ã‚¹ãƒ†ãƒƒãƒ—2/4: ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–ä¸­...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        normalized_tracking_data = self.normalize_frame_numbers(tracking_data_dict)
        
        # åŸºæœ¬æƒ…å ±
        total_frames = len(normalized_tracking_data)
        # fps = phase_data.get('fps', 30.0) # phase_data ã‹ã‚‰ã§ã¯ãªã metadata ã‹ã‚‰å–å¾—
        metadata = tracking_data_dict.get('metadata', {})
        fps = metadata.get('original_fps', metadata.get('processing_fps', 30.0)) # original_fpså„ªå…ˆã€ãªã‘ã‚Œã°processing_fpsã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30
        # phase_changes = phase_data.get('phase_changes', []) # å‰Šé™¤
        
        print(f"æ­£è¦åŒ–å¾Œãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}, FPS (æ¨å®š): {fps}") # printæ–‡ã‚’å¤‰æ›´
        # print(f"å±€é¢å¤‰æ›´æ•°: {len(phase_changes)}") # å‰Šé™¤
        print(f"ã‚³ãƒ¼ãƒˆåº§æ¨™: {'ã‚ã‚Š' if court_coords else 'ãªã—'}")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã®ãƒã‚§ãƒƒã‚¯
        if not normalized_tracking_data:
            print("âš ï¸  æ­£è¦åŒ–å¾Œã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return pd.DataFrame()
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®å±€é¢ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹å‡¦ç†ã¯å‰Šé™¤
        # print("  ã‚¹ãƒ†ãƒƒãƒ—3/5: å±€é¢ãƒ©ãƒ™ãƒ«ç”Ÿæˆä¸­...") # å‰Šé™¤
        # frame_labels = self.interpolate_phase_labels(phase_changes, total_frames, fps) # å‰Šé™¤
        
        # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾ç­–å¼·åŒ–ï¼‰
        print("  ã‚¹ãƒ†ãƒƒãƒ—3/4: DataFrameä½œæˆä¸­...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        features_df = self.safe_create_dataframe_from_tracking_data(normalized_tracking_data, video_name)
        
        if features_df.empty:
            print("âŒ DataFrameä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame()
        
        print(f"DataFrameä½œæˆæˆåŠŸ: {len(features_df)}è¡Œ, {len(features_df.columns)}åˆ—")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã®æ•´åˆæ€§ã‚’ç¢ºä¿
        if 'frame_number' in features_df.columns:
            # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’é€£ç¶šç•ªå·ã«æ­£è¦åŒ–
            features_df['original_frame_number'] = features_df['frame_number']
            features_df['frame_number'] = range(len(features_df))
        else: # ã‚‚ã— frame_number ãŒãªã‘ã‚Œã°ä½œæˆ
            features_df['frame_number'] = range(len(features_df))
            features_df['original_frame_number'] = range(len(features_df))


        # ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ ã™ã‚‹å‡¦ç†ã¯å‰Šé™¤
        # label_length = min(len(frame_labels), len(features_df)) # å‰Šé™¤
        # features_df = features_df.iloc[:label_length].copy() # å‰Šé™¤
        # features_df['label'] = frame_labels[:label_length] # å‰Šé™¤
        features_df['video_name'] = video_name
        
        # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã®æƒ…å ±ã‚’ä¿æŒ
        if 'interpolated' not in features_df.columns:
            features_df['interpolated'] = False
        
        # ãƒ©ãƒ™ãƒ«æœªè¨­å®šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å¤–ã™ã‚‹å‡¦ç†ã¯å‰Šé™¤
        # labeled_frames = features_df['label'] != -1 # å‰Šé™¤
        # features_df = features_df[labeled_frames].copy() # å‰Šé™¤
        
        # print(f"ãƒ©ãƒ™ãƒ«ä»˜ããƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(features_df)}") # å‰Šé™¤
        
        if len(features_df) == 0: # ãƒ©ãƒ™ãƒ«ã§ã¯ãªãDFè‡ªä½“ã®è¡Œæ•°ã§åˆ¤å®š
            print("âš ï¸  å‡¦ç†å¯èƒ½ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“") # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›´
            return pd.DataFrame()
        
        # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã‚’è¡¨ç¤ºã™ã‚‹å‡¦ç†ã¯å‰Šé™¤
        interpolated_count = features_df['interpolated'].sum() if 'interpolated' in features_df.columns else 0
        if interpolated_count > 0:
            print(f"è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ å«æœ‰ç‡: {interpolated_count}/{len(features_df)} ({interpolated_count/len(features_df)*100:.1f}%)")
        
        # æ¬ æå€¤å‡¦ç†
        print("  ã‚¹ãƒ†ãƒƒãƒ—4/4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ä¸­...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.1/4.4: æ¬ æå€¤å‡¦ç†...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        features_df = self.handle_missing_values(features_df)
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.1/4.4: æ¬ æå€¤å‡¦ç†å®Œäº†") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        
        # ã‚³ãƒ¼ãƒˆåº§æ¨™ç‰¹å¾´é‡ã‚’ä½œæˆ
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.2/4.4: ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ä½œæˆ...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        features_df = self.create_court_features(features_df, court_coords)
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.2/4.4: ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        
        # æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆè£œé–“ãƒ‡ãƒ¼ã‚¿ã‚’è€ƒæ…®)
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.3/4.4: æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆ...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        features_df = self.create_temporal_features(features_df)
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.3/4.4: æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆå®Œäº†") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆ
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.4/4.4: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ä½œæˆ...") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        features_df = self.create_contextual_features(features_df)
        print("    ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—4.4/4.4: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        
        print(f"  ã‚¹ãƒ†ãƒƒãƒ—4/4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†") # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰æ›´
        print(f"æœ€çµ‚ç‰¹å¾´é‡æ•°: {len(features_df.columns)}")
        
        return features_df
    
    # ç‰¹å¾´é‡ä½œæˆãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def create_temporal_features(self, features_df: pd.DataFrame, window_sizes: List[int] = [3, 5, 10, 15]) -> pd.DataFrame:
        """æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆè£œé–“ãƒ‡ãƒ¼ã‚¿ã‚’è€ƒæ…®ï¼‰"""
        temporal_df = features_df.copy()
        
        # æ•°å€¤åˆ—ã®ã¿ã‚’å¯¾è±¡
        numeric_columns = features_df.select_dtypes(include=[np.number]).columns
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã¨ãƒ©ãƒ™ãƒ«ã¯é™¤å¤– (ãƒ©ãƒ™ãƒ«ã¯æ¨è«–æ™‚ãªã„ã®ã§å‰Šé™¤)
        target_columns = [col for col in numeric_columns if col not in ['frame_number', 'original_frame_number']] # 'label' ã‚’å‰Šé™¤
        
        print(f"æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆå¯¾è±¡: {len(target_columns)}ç‰¹å¾´é‡")
        
        # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‡¦ç†
        is_interpolated = features_df.get('interpolated', pd.Series([False] * len(features_df)))
        
        for window in tqdm(window_sizes, desc="æ™‚ç³»åˆ—ç‰¹å¾´é‡(ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ¥)", leave=False):
            print(f"  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º {window} ã®ç‰¹å¾´é‡ä½œæˆä¸­...")
            
            for col in tqdm(target_columns, desc=f"ç‰¹å¾´é‡ (win={window})", leave=False):
                base_values = features_df[col]
                
                # è£œé–“ãƒ‡ãƒ¼ã‚¿ã‚’è€ƒæ…®ã—ãŸé‡ã¿ä»˜ãç§»å‹•å¹³å‡
                if is_interpolated.any():
                    # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã«ä½ã„é‡ã¿ã‚’ä¸ãˆã‚‹
                    weights = (~is_interpolated).astype(float) * 0.8 + is_interpolated.astype(float) * 0.3
                    
                    # é‡ã¿ä»˜ãç§»å‹•å¹³å‡ã‚’è¨ˆç®—
                    weighted_values = base_values * weights
                    temporal_df[f'{col}_ma_{window}'] = weighted_values.rolling(
                        window=window, center=True, min_periods=1
                    ).sum() / weights.rolling(window=window, center=True, min_periods=1).sum()
                else:
                    # é€šå¸¸ã®ç§»å‹•å¹³å‡
                    temporal_df[f'{col}_ma_{window}'] = base_values.rolling(
                        window=window, center=True, min_periods=1
                    ).mean()
                
                # ç§»å‹•æ¨™æº–åå·®ï¼ˆè£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã®å½±éŸ¿ã‚’è»½æ¸›ï¼‰
                temporal_df[f'{col}_std_{window}'] = base_values.rolling(
                    window=window, center=True, min_periods=1
                ).std().fillna(0)
                
                # ç§»å‹•æœ€å¤§å€¤ãƒ»æœ€å°å€¤
                temporal_df[f'{col}_max_{window}'] = base_values.rolling(
                    window=window, center=True, min_periods=1
                ).max()
                
                temporal_df[f'{col}_min_{window}'] = base_values.rolling(
                    window=window, center=True, min_periods=1
                ).min()
                
                # å°ã•ãªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®ã¿ä½œæˆã™ã‚‹ç‰¹å¾´é‡
                if window <= 5:
                    # 1æ¬¡å·®åˆ†ï¼ˆå¤‰åŒ–ç‡ï¼‰- è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è€ƒæ…®
                    diff = base_values.diff().fillna(0)
                    
                    # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å·®åˆ†ã¯é‡ã¿ã‚’ä¸‹ã’ã‚‹
                    if is_interpolated.any():
                        diff_weights = (~is_interpolated).astype(float) * 1.0 + is_interpolated.astype(float) * 0.5
                        diff = diff * diff_weights
                    
                    temporal_df[f'{col}_diff'] = diff
                    temporal_df[f'{col}_diff_abs'] = np.abs(diff)
                    
                    # 2æ¬¡å·®åˆ†ï¼ˆåŠ é€Ÿåº¦ï¼‰
                    temporal_df[f'{col}_diff2'] = temporal_df[f'{col}_diff'].diff().fillna(0)
                    temporal_df[f'{col}_diff2_abs'] = np.abs(temporal_df[f'{col}_diff2'])
                
                # ä¸­ã‚µã‚¤ã‚ºã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®ã¿ä½œæˆ
                if window == 5:
                    # ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆç·šå½¢å›å¸°ã®å‚¾ãè¿‘ä¼¼ï¼‰
                    temporal_df[f'{col}_trend_{window}'] = base_values.rolling(
                        window=window, center=True, min_periods=1
                    ).apply(lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0, raw=True)
                    
                    # å¤‰å‹•ä¿‚æ•°ï¼ˆCV: Coefficient of Variationï¼‰
                    mean_vals = temporal_df[f'{col}_ma_{window}']
                    std_vals = temporal_df[f'{col}_std_{window}']
                    temporal_df[f'{col}_cv_{window}'] = np.where(
                        mean_vals != 0, std_vals / np.abs(mean_vals), 0
                    )
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ•ãƒ©ã‚°ã®è¿½åŠ 
        temporal_df['data_quality'] = (~is_interpolated).astype(float)
        temporal_df['interpolation_ratio'] = is_interpolated.rolling(
            window=10, center=True, min_periods=1
        ).mean()
        
        print(f"æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(temporal_df.columns) - len(features_df.columns)}ç‰¹å¾´é‡è¿½åŠ ")
        return temporal_df
    
    def create_contextual_features(self, features_df: pd.DataFrame) -> pd.DataFrame:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆæ™‚ç³»åˆ—å¯¾å¿œå¼·åŒ–ãƒ»ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å­˜åœ¨ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""
        context_df = features_df.copy()
        
        print("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        available_fields = set(context_df.columns)
        
        # ãƒœãƒ¼ãƒ«é–¢é€£ã®è¤‡åˆç‰¹å¾´é‡ï¼ˆå­˜åœ¨ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ä½¿ç”¨ï¼‰
        ball_activity_components = []
        
        if 'ball_detected' in available_fields:
            ball_activity_components.append(context_df['ball_detected'])
        
        if 'ball_movement_score' in available_fields:
            ball_activity_components.append(context_df['ball_movement_score'])
        elif 'ball_speed' in available_fields:
            # ball_movement_scoreãŒãªã„å ´åˆã¯ball_speedã§ä»£ç”¨
            ball_activity_components.append(context_df['ball_speed'] / 100.0)  # æ­£è¦åŒ–
        
        if 'ball_tracking_confidence' in available_fields:
            ball_activity_components.append(context_df['ball_tracking_confidence'])
        
        # ãƒœãƒ¼ãƒ«æ´»å‹•åº¦ã‚’è¨ˆç®—ï¼ˆåˆ©ç”¨å¯èƒ½ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰ï¼‰
        if ball_activity_components:
            if len(ball_activity_components) == 1:
                context_df['ball_activity'] = ball_activity_components[0]
            else:
                # è¤‡æ•°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ç©
                ball_activity = ball_activity_components[0]
                for component in ball_activity_components[1:]:
                    ball_activity = ball_activity * component
                context_df['ball_activity'] = ball_activity
        else:
            context_df['ball_activity'] = 0
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼é–¢é€£ã®è¤‡åˆç‰¹å¾´é‡
        player_interaction_components = []
        
        if 'player_front_count' in available_fields:
            player_interaction_components.append(context_df['player_front_count'])
        
        if 'player_back_count' in available_fields:
            player_interaction_components.append(context_df['player_back_count'])
        
        if player_interaction_components:
            context_df['players_interaction'] = sum(player_interaction_components) / len(player_interaction_components)
        else:
            context_df['players_interaction'] = 0
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä¿¡é ¼åº¦å¹³å‡
        confidence_components = []
        if 'player_front_confidence' in available_fields:
            confidence_components.append(context_df['player_front_confidence'].fillna(0))
        if 'player_back_confidence' in available_fields:
            confidence_components.append(context_df['player_back_confidence'].fillna(0))
        
        if confidence_components:
            context_df['players_confidence_avg'] = sum(confidence_components) / len(confidence_components)
        else:
            context_df['players_confidence_avg'] = 0
        
        # ãƒœãƒ¼ãƒ«ã¨ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä½ç½®é–¢ä¿‚ï¼ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å­˜åœ¨ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        ball_pos_available = all(col in available_fields for col in ['ball_x', 'ball_y'])
        front_pos_available = all(col in available_fields for col in ['player_front_x', 'player_front_y'])
        back_pos_available = all(col in available_fields for col in ['player_back_x', 'player_back_y'])
        
        if ball_pos_available and front_pos_available:
            # ãƒœãƒ¼ãƒ«-æ‰‹å‰ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è·é›¢
            context_df['ball_to_front_distance'] = np.sqrt(
                (context_df['ball_x'].fillna(0) - context_df['player_front_x'].fillna(0))**2 + 
                (context_df['ball_y'].fillna(0) - context_df['player_front_y'].fillna(0))**2
            )
            # NaNã‚„ç„¡åŠ¹å€¤ã‚’å¤§ããªå€¤ã§ç½®æ›
            context_df['ball_to_front_distance'] = context_df['ball_to_front_distance'].fillna(1000)
        else:
            context_df['ball_to_front_distance'] = 1000
        
        if ball_pos_available and back_pos_available:
            # ãƒœãƒ¼ãƒ«-å¥¥ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è·é›¢
            context_df['ball_to_back_distance'] = np.sqrt(
                (context_df['ball_x'].fillna(0) - context_df['player_back_x'].fillna(0))**2 + 
                (context_df['ball_y'].fillna(0) - context_df['player_back_y'].fillna(0))**2
            )
            context_df['ball_to_back_distance'] = context_df['ball_to_back_distance'].fillna(1000)
        else:
            context_df['ball_to_back_distance'] = 1000
        
        # ã©ã¡ã‚‰ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ãƒœãƒ¼ãƒ«ãŒè¿‘ã„ã‹
        if 'ball_to_front_distance' in context_df.columns and 'ball_to_back_distance' in context_df.columns:
            context_df['ball_closer_to_front'] = (
                context_df['ball_to_front_distance'] < context_df['ball_to_back_distance']
            ).astype(int)
        else:
            context_df['ball_closer_to_front'] = 0
        
        # ãƒœãƒ¼ãƒ«ã®ç”»é¢ä¸Šã®ä½ç½®ï¼ˆæ­£è¦åŒ–åº§æ¨™ã‚’ä½¿ç”¨ï¼‰
        if all(col in available_fields for col in ['ball_x_normalized', 'ball_y_normalized']):
            context_df['ball_in_upper_half'] = (context_df['ball_x_normalized'].fillna(0.5) < 0.5).astype(int)
            context_df['ball_in_left_half'] = (context_df['ball_y_normalized'].fillna(0.5) < 0.5).astype(int)
            context_df['ball_in_center'] = (
                (context_df['ball_x_normalized'].fillna(0) > 0.3) & 
                (context_df['ball_x_normalized'].fillna(0) < 0.7) &
                (context_df['ball_y_normalized'].fillna(0) > 0.3) & 
                (context_df['ball_y_normalized'].fillna(0) < 0.7)
            ).astype(int)
        else:
            context_df['ball_in_upper_half'] = 0
            context_df['ball_in_left_half'] = 0
            context_df['ball_in_center'] = 0
        
        # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°å“è³ªæŒ‡æ¨™ï¼ˆå­˜åœ¨ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ä½¿ç”¨ï¼‰
        quality_components = []
        weights = []
        
        if 'ball_detected' in available_fields:
            quality_components.append(context_df['ball_detected'])
            weights.append(0.4)
        
        if 'ball_tracking_confidence' in available_fields:
            quality_components.append((context_df['ball_tracking_confidence'].fillna(0) > 0.5).astype(int))
            weights.append(0.3)
        
        if 'candidate_balls_count' in available_fields:
            quality_components.append((context_df['candidate_balls_count'].fillna(0) > 0).astype(int))
            weights.append(0.2)
        
        if 'disappeared_count' in available_fields:
            quality_components.append((context_df['disappeared_count'].fillna(1) == 0).astype(int))
            weights.append(0.1)
        
        if quality_components:
            # é‡ã¿ä»˜ãå¹³å‡ã§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°å“è³ªã‚’è¨ˆç®—
            weighted_sum = sum(comp * weight for comp, weight in zip(quality_components, weights))
            total_weight = sum(weights)
            context_df['tracking_quality'] = weighted_sum / total_weight if total_weight > 0 else 0
        else:
            context_df['tracking_quality'] = 0
        
        # æ™‚ç³»åˆ—å¯¾å¿œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’è¿½åŠ 
        print("  æ™‚ç³»åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")
        
        # ãƒœãƒ¼ãƒ«æ¤œå‡ºã®å®‰å®šæ€§ï¼ˆé€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã§ã®æ¤œå‡ºç‡ï¼‰
        if 'ball_detected' in available_fields:
            for window in [3, 5, 10]:
                context_df[f'ball_detection_stability_{window}'] = context_df['ball_detected'].rolling(
                    window=window, center=True, min_periods=1
                ).mean()
        
        # ãƒœãƒ¼ãƒ«ä½ç½®ã®å¤‰å‹•ï¼ˆå®‰å®šæ€§ã®æŒ‡æ¨™ï¼‰
        if all(col in available_fields for col in ['ball_x', 'ball_y']):
            # ãƒœãƒ¼ãƒ«ä½ç½®ã®ç§»å‹•è·é›¢
            ball_x_diff = context_df['ball_x'].fillna(method='ffill').diff().fillna(0)
            ball_y_diff = context_df['ball_y'].fillna(method='ffill').diff().fillna(0)
            context_df['ball_movement_distance'] = np.sqrt(ball_x_diff**2 + ball_y_diff**2)
            
            # ãƒœãƒ¼ãƒ«ç§»å‹•ã®å®‰å®šæ€§
            for window in [3, 5]:
                context_df[f'ball_movement_stability_{window}'] = context_df['ball_movement_distance'].rolling(
                    window=window, center=True, min_periods=1
                ).std().fillna(0)
        else:
            context_df['ball_movement_distance'] = 0
            for window in [3, 5]:
                context_df[f'ball_movement_stability_{window}'] = 0
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½ç½®ã®å¤‰å‹•
        for player in ['front', 'back']:
            x_col = f'player_{player}_x'
            y_col = f'player_{player}_y'
            
            if x_col in available_fields and y_col in available_fields:
                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ç§»å‹•è·é›¢
                x_diff = context_df[x_col].fillna(method='ffill').diff().fillna(0)
                y_diff = context_df[y_col].fillna(method='ffill').diff().fillna(0)
                context_df[f'player_{player}_movement_distance'] = np.sqrt(x_diff**2 + y_diff**2)
                
                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼æ´»å‹•ãƒ¬ãƒ™ãƒ«ï¼ˆç§»å‹•ã®æ¿€ã—ã•ï¼‰
                for window in [5, 10]:
                    context_df[f'player_{player}_activity_{window}'] = context_df[f'player_{player}_movement_distance'].rolling(
                        window=window, center=True, min_periods=1
                    ).mean()
            else:
                context_df[f'player_{player}_movement_distance'] = 0
                for window in [5, 10]:
                    context_df[f'player_{player}_activity_{window}'] = 0
        
        # å…¨ä½“çš„ãªå‹•ãã®æ¿€ã—ã•ï¼ˆã‚·ãƒ¼ãƒ³ã®å‹•çš„ãƒ¬ãƒ™ãƒ«ï¼‰
        movement_cols = [col for col in context_df.columns if 'movement_distance' in col and col in context_df.columns]
        if movement_cols:
            context_df['scene_dynamics'] = context_df[movement_cols].mean(axis=1)
            
            # ã‚·ãƒ¼ãƒ³å‹•çš„ãƒ¬ãƒ™ãƒ«ã®æ™‚ç³»åˆ—ç‰¹å¾´é‡
            for window in [5, 10]:
                context_df[f'scene_dynamics_ma_{window}'] = context_df['scene_dynamics'].rolling(
                    window=window, center=True, min_periods=1
                ).mean()
                
                context_df[f'scene_dynamics_std_{window}'] = context_df['scene_dynamics'].rolling(
                    window=window, center=True, min_periods=1
                ).std().fillna(0)
        else:
            context_df['scene_dynamics'] = 0
            for window in [5, 10]:
                context_df[f'scene_dynamics_ma_{window}'] = 0
                context_df[f'scene_dynamics_std_{window}'] = 0
        
        # ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºï¼ˆæ€¥æ¿€ãªå¤‰åŒ–ã®æ¤œå‡ºï¼‰
        if 'ball_movement_distance' in context_df.columns:
            # ãƒœãƒ¼ãƒ«ç§»å‹•ã®æ€¥æ¿€ãªå¤‰åŒ–ï¼ˆãƒ’ãƒƒãƒˆã€ãƒã‚¦ãƒ³ãƒ‰ãªã©ã®ã‚¤ãƒ™ãƒ³ãƒˆï¼‰
            ball_movement_ma = context_df['ball_movement_distance'].rolling(
                window=5, center=True, min_periods=1
            ).mean()
            
            context_df['ball_movement_spike'] = (
                context_df['ball_movement_distance'] > ball_movement_ma * 2
            ).astype(int)
            
            # ã‚¤ãƒ™ãƒ³ãƒˆé »åº¦
            for window in [10, 20]:
                context_df[f'ball_events_frequency_{window}'] = context_df['ball_movement_spike'].rolling(
                    window=window, center=True, min_periods=1
                ).sum()
        else:
            context_df['ball_movement_spike'] = 0
            for window in [10, 20]:
                context_df[f'ball_events_frequency_{window}'] = 0
        
        print(f"  ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(context_df.columns) - len(features_df.columns)}ç‰¹å¾´é‡è¿½åŠ ")
        return context_df
    
    def create_court_features(self, features_df: pd.DataFrame, court_coords: Dict) -> pd.DataFrame:
        """ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ä½¿ç”¨ã—ãŸç‰¹å¾´é‡ã‚’ä½œæˆ"""
        if not court_coords:
            print("ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return features_df
        
        court_df = features_df.copy()
        print("ã‚³ãƒ¼ãƒˆåº§æ¨™ç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")
        
        # ã‚³ãƒ¼ãƒˆåº§æ¨™ã‹ã‚‰åŸºæœ¬æƒ…å ±ã‚’è¨ˆç®—
        court_info = self.calculate_court_geometry(court_coords)
        
        # ãƒœãƒ¼ãƒ«ä½ç½®ã®ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»å¤‰æ›
        if all(col in court_df.columns for col in ['ball_x', 'ball_y']):
            ball_court_coords = self.transform_to_court_coordinates(
                court_df['ball_x'].values, 
                court_df['ball_y'].values, 
                court_coords
            )
            
            court_df['ball_court_x'] = ball_court_coords['x']
            court_df['ball_court_y'] = ball_court_coords['y']
            
            # ã‚³ãƒ¼ãƒˆä¸Šã®ä½ç½®ã«åŸºã¥ãç‰¹å¾´é‡
            court_df['ball_in_court'] = (
                (court_df['ball_court_x'] >= 0) & 
                (court_df['ball_court_x'] <= 1) &
                (court_df['ball_court_y'] >= 0) & 
                (court_df['ball_court_y'] <= 1)
            ).astype(int)
            
            # ã‚³ãƒ¼ãƒˆä¸Šã®é ˜åŸŸç‰¹å¾´é‡
            court_df['ball_in_front_court'] = (court_df['ball_court_y'] > 0.5).astype(int)
            court_df['ball_in_back_court'] = (court_df['ball_court_y'] <= 0.5).astype(int)
            court_df['ball_in_left_court'] = (court_df['ball_court_x'] <= 0.5).astype(int)
            court_df['ball_in_right_court'] = (court_df['ball_court_x'] > 0.5).astype(int)
            
            # ãƒãƒƒãƒˆã‹ã‚‰ã®è·é›¢
            net_y = 0.5  # ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ã§ã¯ãƒãƒƒãƒˆã¯y=0.5
            court_df['ball_distance_to_net'] = np.abs(court_df['ball_court_y'] - net_y)
            
            # ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®è·é›¢
            court_df['ball_distance_to_left_line'] = court_df['ball_court_x']
            court_df['ball_distance_to_right_line'] = 1 - court_df['ball_court_x']
            court_df['ball_distance_to_sideline'] = np.minimum(
                court_df['ball_distance_to_left_line'],
                court_df['ball_distance_to_right_line']
            )
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®è·é›¢
            court_df['ball_distance_to_front_baseline'] = 1 - court_df['ball_court_y']
            court_df['ball_distance_to_back_baseline'] = court_df['ball_court_y']
            court_df['ball_distance_to_baseline'] = np.minimum(
                court_df['ball_distance_to_front_baseline'],
                court_df['ball_distance_to_back_baseline']
            )
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½ç½®ã®ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»å¤‰æ›
        for player in ['front', 'back']:
            x_col = f'player_{player}_x'
            y_col = f'player_{player}_y'
            
            if x_col in court_df.columns and y_col in court_df.columns:
                player_court_coords = self.transform_to_court_coordinates(
                    court_df[x_col].values,
                    court_df[y_col].values,
                    court_coords
                )
                
                court_df[f'player_{player}_court_x'] = player_court_coords['x']
                court_df[f'player_{player}_court_y'] = player_court_coords['y']
                
                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚³ãƒ¼ãƒˆä¸Šä½ç½®ç‰¹å¾´é‡
                court_df[f'player_{player}_in_court'] = (
                    (court_df[f'player_{player}_court_x'] >= 0) & 
                    (court_df[f'player_{player}_court_x'] <= 1) &

                    (court_df[f'player_{player}_court_y'] >= 0) & 
                    (court_df[f'player_{player}_court_y'] <= 1)
                ).astype(int)
                
                # ãƒãƒƒãƒˆã‹ã‚‰ã®è·é›¢
                court_df[f'player_{player}_distance_to_net'] = np.abs(
                    court_df[f'player_{player}_court_y'] - net_y
                )
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“ã®é–¢ä¿‚ç‰¹å¾´é‡ï¼ˆã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ï¼‰
        if all(col in court_df.columns for col in ['player_front_court_x', 'player_front_court_y', 
                                                  'player_back_court_x', 'player_back_court_y']):
            # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“è·é›¢ï¼ˆã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ï¼‰
            court_df['players_court_distance'] = np.sqrt(
                (court_df['player_front_court_x'] - court_df['player_back_court_x'])**2 +
                (court_df['player_front_court_y'] - court_df['player_back_court_y'])**2
            )
            
            # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒæ­£ã—ã„å´ã«ã„ã‚‹ã‹ã®åˆ¤å®š
            court_df['players_correct_sides'] = (
                court_df['player_front_court_y'] > court_df['player_back_court_y']
            ).astype(int)
        
        # ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ã§ã®ãƒœãƒ¼ãƒ«-ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼é–¢ä¿‚
        if all(col in court_df.columns for col in ['ball_court_x', 'ball_court_y']):
            for player in ['front', 'back']:
                if all(col in court_df.columns for col in [f'player_{player}_court_x', f'player_{player}_court_y']):
                    # ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ã§ã®ãƒœãƒ¼ãƒ«-ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è·é›¢
                    court_df[f'ball_to_{player}_court_distance'] = np.sqrt(
                        (court_df['ball_court_x'] - court_df[f'player_{player}_court_x'])**2 +
                        (court_df['ball_court_y'] - court_df[f'player_{player}_court_y'])**2
                    )
        
        print(f"ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(court_df.columns) - len(features_df.columns)}ç‰¹å¾´é‡è¿½åŠ ")
        return court_df
    
    # ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»è¨ˆç®—ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def calculate_court_geometry(self, court_coords: Dict) -> Dict:
        """ã‚³ãƒ¼ãƒˆåº§æ¨™ã‹ã‚‰å¹¾ä½•å­¦çš„æƒ…å ±ã‚’è¨ˆç®—"""
        # åŸºæœ¬çš„ãªã‚³ãƒ¼ãƒˆæƒ…å ±ã‚’è¨ˆç®—
        top_left = np.array(court_coords['top_left_corner'])
        top_right = np.array(court_coords['top_right_corner'])
        bottom_left = np.array(court_coords['bottom_left_corner'])
        bottom_right = np.array(court_coords['bottom_right_corner'])
        
        # ã‚³ãƒ¼ãƒˆã®å¹…ã¨é«˜ã•
        court_width_top = np.linalg.norm(top_right - top_left)
        court_width_bottom = np.linalg.norm(bottom_right - bottom_left)
        court_height_left = np.linalg.norm(bottom_left - top_left)
        court_height_right = np.linalg.norm(bottom_right - top_right)
        
        court_info = {
            'width_top': court_width_top,
            'width_bottom': court_width_bottom,
            'height_left': court_height_left,
            'height_right': court_height_right,
            'avg_width': (court_width_top + court_width_bottom) / 2,
            'avg_height': (court_height_left + court_height_right) /  2
        }
        
        return court_info
    
    def transform_to_court_coordinates(self, x_coords: np.ndarray, y_coords: np.ndarray, 
                                     court_coords: Dict) -> Dict[str, np.ndarray]:
        """ç”»åƒåº§æ¨™ã‚’ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ï¼ˆ0-1ã®æ­£è¦åŒ–åº§æ¨™ï¼‰ã«å¤‰æ›"""
        # ã‚³ãƒ¼ãƒˆå››éš…ã®åº§æ¨™
        top_left = np.array(court_coords['top_left_corner'])
        top_right = np.array(court_coords['top_right_corner'])
        bottom_left = np.array(court_coords['bottom_left_corner'])
        bottom_right = np.array(court_coords['bottom_right_corner'])
        
        # ãƒã‚¤ãƒªãƒ‹ã‚¢è£œé–“ã«ã‚ˆã‚‹åº§æ¨™å¤‰æ›
        court_x = np.zeros_like(x_coords, dtype=float)
        court_y = np.zeros_like(y_coords, dtype=float)
        
        for i in range(len(x_coords)):
            x, y = x_coords[i], y_coords[i]
            
            # Noneå€¤ã®å‡¦ç†
            if pd.isna(x) or pd.isna(y) or x == 0 or y == 0:
                court_x[i] = -1  # ã‚³ãƒ¼ãƒˆå¤–ã‚’ç¤ºã™å€¤
                court_y[i] = -1
                continue
            
            # ã‚³ãƒ¼ãƒˆå››éš…ã‚’åŸºæº–ã«ã—ãŸæ­£è¦åŒ–åº§æ¨™ã‚’è¨ˆç®—
            # ç°¡æ˜“çš„ãªé€è¦–å¤‰æ›è¿‘ä¼¼
            try:
                # ä¸Šè¾ºã¨ä¸‹è¾ºã§ã®ä½ç½®ã‚’è¨ˆç®—
                if top_right[0] != top_left[0]:
                    top_ratio = (x - top_left[0]) / (top_right[0] - top_left[0])
                else:
                    top_ratio = 0.5
                
                if bottom_right[0] != bottom_left[0]:
                    bottom_ratio = (x - bottom_left[0]) / (bottom_right[0] - bottom_left[0])
                else:
                    bottom_ratio = 0.5
                
                # yæ–¹å‘ã®æ¯”ç‡ã‚’è¨ˆç®—
                total_height = max(bottom_left[1] - top_left[1], bottom_right[1] - top_right[1], 1)
                y_ratio = (y - top_left[1]) / total_height if total_height > 0 else 0
                
                # ãƒã‚¤ãƒªãƒ‹ã‚¢è£œé–“ã§xåº§æ¨™ã‚’è¨ˆç®—
                court_x[i] = np.clip(top_ratio * (1 - y_ratio) + bottom_ratio * y_ratio, -0.5, 1.5)
                court_y[i] = np.clip(y_ratio, -0.5, 1.5)
                
            except (ZeroDivisionError, ValueError):
                court_x[i] = -1
                court_y[i] = -1
        
        return {'x': court_x, 'y': court_y}
    
    def handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¬ æå€¤ã‚’å‡¦ç†"""
        df_cleaned = df.copy()
        
        # Noneå€¤ã‚’é©åˆ‡ãªå€¤ã«ç½®æ›
        none_columns = ['ball_x', 'ball_y', 'player_front_x', 'player_front_y', 
                       'player_back_x', 'player_back_y']
        
        for col in none_columns:
            if col in df_cleaned.columns:
                # None/NaNã‚’å‰ã®å€¤ã§åŸ‹ã‚ã‚‹ï¼ˆå‰å‘ãè£œé–“ï¼‰
                df_cleaned[col] = df_cleaned[col].fillna(method='ffill')
                # ãã‚Œã§ã‚‚æ®‹ã‚‹NaNã‚’0ã§åŸ‹ã‚ã‚‹
                df_cleaned[col] = df_cleaned[col].fillna(0)
        
        # æ•°å€¤åˆ—ã®æ®‹ã‚Šã®NaNã‚’0ã§åŸ‹ã‚ã‚‹
        numeric_columns = df_cleaned.select_dtypes(include=[np.number]).columns
        df_cleaned[numeric_columns] = df_cleaned[numeric_columns].fillna(0)
        
        return df_cleaned
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ»çµ±åˆãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def extract_all_features(self, video_name: str = None) -> pd.DataFrame:
        """ã™ã¹ã¦ã®å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦DataFrameã‚’çµ±åˆ"""
        print("=== æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºé–‹å§‹ ===") # printæ–‡ã‚’å¤‰æ›´
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        print("1. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        # phase_annotations = self.load_phase_annotations(video_name) # å‰Šé™¤
        tracking_features = self.load_tracking_features(video_name)
        court_coordinates = self.load_court_coordinates(video_name)
        
        # if not phase_annotations: # å‰Šé™¤
        #     print("âŒ å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“") # å‰Šé™¤
        #     return pd.DataFrame() # å‰Šé™¤
        
        if not tracking_features:
            print("âŒ ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒãƒ³ã‚°
        print("\n2. ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚°ä¸­...")
        matched_data = self.match_video_data(tracking_features, court_coordinates) # phase_annotations ã‚’å‰Šé™¤
        
        if not matched_data:
            print("âŒ ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        # å„å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        print("\n3. ç‰¹å¾´é‡æŠ½å‡ºä¸­...")
        all_features_list = [] # å¤‰æ•°åã‚’å¤‰æ›´ (all_features -> all_features_list)
        total_videos = len(matched_data)
        print(f"å‡¦ç†å¯¾è±¡å‹•ç”»æ•°: {total_videos}")
        
        for i, (vid_name, track_data, court_data) in enumerate(tqdm(matched_data, desc="å‹•ç”»åˆ¥ç‰¹å¾´é‡æŠ½å‡º"), 1): # å¤‰æ•°åã‚’å¤‰æ›´
            print(f"\n--- å‹•ç”»å‡¦ç†é€²æ—: [{i}/{total_videos}] - {vid_name} ---") # å¤‰æ•°åã‚’å¤‰æ›´
            
            try:
                features_df = self.extract_features_from_video(
                    vid_name, track_data, court_data # phase_data ã‚’å‰Šé™¤ã€å¤‰æ•°åã‚’å¤‰æ›´
                )
                
                if not features_df.empty:
                    all_features_list.append(features_df) # å¤‰æ•°åã‚’å¤‰æ›´
                    print(f"âœ… ç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {len(features_df)}è¡Œ")
                else:
                    print(f"âš ï¸  ç‰¹å¾´é‡ãŒç©ºã§ã™: {vid_name}") # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å‹•ç”»åè¿½åŠ 
                    
            except Exception as e:
                print(f"âŒ ç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼ ({vid_name}): {e}") # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å‹•ç”»åè¿½åŠ 
                import traceback # traceback ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                traceback.print_exc() # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å‡ºåŠ›
                continue
        
        # ç‰¹å¾´é‡ã‚’çµ±åˆ
        if all_features_list: # å¤‰æ•°åã‚’å¤‰æ›´
            print(f"\n4. ç‰¹å¾´é‡çµ±åˆä¸­... ({len(all_features_list)}å‹•ç”»)") # å¤‰æ•°åã‚’å¤‰æ›´
            combined_features = pd.concat(all_features_list, ignore_index=True) # å¤‰æ•°åã‚’å¤‰æ›´
            
            print(f"âœ… çµ±åˆå®Œäº†:")
            print(f"   ç·è¡Œæ•°: {len(combined_features)}")
            print(f"   ç·ç‰¹å¾´é‡æ•°: {len(combined_features.columns)}")
            if 'video_name' in combined_features.columns: # video_name ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                print(f"   å‹•ç”»æ•°: {combined_features['video_name'].nunique()}")
            
            # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã‚’è¡¨ç¤ºã™ã‚‹å‡¦ç†ã¯å‰Šé™¤
            
            return combined_features
        else:
            print("âŒ æŠ½å‡ºã§ããŸç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
    
    def save_features(self, features_df: pd.DataFrame, filename: str = None) -> str:
        """ç‰¹å¾´é‡ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if features_df.empty:
            print("âš ï¸  ä¿å­˜ã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"tennis_inference_features_{timestamp}.csv" # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´
        
        output_path = self.features_dir / filename
        
        try:
            features_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"âœ… ç‰¹å¾´é‡ä¿å­˜å®Œäº†: {output_path}")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_path.stat().st_size / (1024*1024):.2f} MB")
            return str(output_path)
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def save_feature_info(self, features_df: pd.DataFrame, filename: str = None) -> str:
        """ç‰¹å¾´é‡ã®è©³ç´°æƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if features_df.empty:
            print("âš ï¸  ä¿å­˜ã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"tennis_inference_features_info_{timestamp}.json" # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´
        
        output_path = self.features_dir / filename
        
        try:
            # ç‰¹å¾´é‡æƒ…å ±ã‚’ä½œæˆ
            feature_info = {
                'creation_time': datetime.now().isoformat(),
                'total_frames': len(features_df),
                'total_features': len(features_df.columns),
                'videos': features_df['video_name'].nunique() if 'video_name' in features_df.columns else 0, # video_name ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                'video_list': features_df['video_name'].unique().tolist() if 'video_name' in features_df.columns else [], # video_name ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                # 'phase_labels': self.phase_labels, # å‰Šé™¤
                # 'label_distribution': features_df['label'].value_counts().sort_index().to_dict(), # å‰Šé™¤
                'feature_columns': features_df.columns.tolist(),
                'feature_types': { # æ¨è«–æ™‚ã«ã¯ç°¡ç•¥åŒ–ã‚‚æ¤œè¨å¯èƒ½ã ãŒã€ä¸€æ—¦ç¶­æŒ
                    'temporal': [col for col in features_df.columns if any(suffix in col for suffix in ['_ma_', '_std_', '_max_', '_min_', '_diff', '_trend_', '_cv_'])],
                    'contextual': [col for col in features_df.columns if any(keyword in col for keyword in ['activity', 'interaction', 'confidence', 'distance', 'movement', 'stability', 'dynamics', 'quality'])],
                    'court': [col for col in features_df.columns if 'court' in col],
                    'basic': [col for col in features_df.columns if col.startswith(('ball_', 'player_')) and not any(suffix in col for suffix in ['_ma_', '_std_', '_max_', '_min_', '_diff', '_trend_', '_cv_', '_court'])]
                },
                'data_quality': {
                    'interpolated_frames': int(features_df.get('interpolated', pd.Series([False] * len(features_df))).sum()), # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä¿®æ­£
                    'interpolation_rate': float(features_df.get('interpolated', pd.Series([False] * len(features_df))).mean()), # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä¿®æ­£
                    'missing_values_summary': features_df.isnull().sum()[features_df.isnull().sum() > 0].to_dict() # missing_values ã‚’ missing_values_summary ã«å¤‰æ›´ã—ã€å†…å®¹ã‚’èª¿æ•´
                }
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(feature_info, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… æ¨è«–ç”¨ç‰¹å¾´é‡æƒ…å ±ä¿å­˜å®Œäº†: {output_path}") # printæ–‡ã‚’å¤‰æ›´
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def run_feature_extraction(self, video_name: str = None, save_results: bool = True) -> Tuple[pd.DataFrame, str, str]:
        """ç‰¹å¾´é‡æŠ½å‡ºã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ"""
        print("ğŸ¾ ãƒ†ãƒ‹ã‚¹å‹•ç”» æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹") # printæ–‡ã‚’å¤‰æ›´
        print("=" * 50)
        
        # ç‰¹å¾´é‡æŠ½å‡º
        features_df = self.extract_all_features(video_name)
        
        if features_df.empty:
            print("âŒ æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ") # printæ–‡ã‚’å¤‰æ›´
            return pd.DataFrame(), "", ""
        
        feature_file = ""
        info_file = ""
        
        if save_results:
            print("\n5. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
            feature_file = self.save_features(features_df)
            info_file = self.save_feature_info(features_df)
        
        print("\nğŸ‰ æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹å®Œäº†!") # printæ–‡ã‚’å¤‰æ›´
        print("=" * 50)
        
        return features_df, feature_file, info_file
    
    def analyze_features(self, features_df: pd.DataFrame):
        """ç‰¹å¾´é‡ã®çµ±è¨ˆåˆ†æã‚’è¡¨ç¤º"""
        if features_df.empty:
            print("âš ï¸  åˆ†æã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return
        
        print("\nğŸ“ˆ æ¨è«–ç”¨ç‰¹å¾´é‡åˆ†æçµæœ") # printæ–‡ã‚’å¤‰æ›´
        print("=" * 30)
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(features_df):,}")
        print(f"   ç‰¹å¾´é‡æ•°: {len(features_df.columns)}")
        if 'video_name' in features_df.columns: # video_name ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            print(f"   å‹•ç”»æ•°: {features_df['video_name'].nunique()}")
        
        # å‹•ç”»åˆ¥çµ±è¨ˆ
        if 'video_name' in features_df.columns: # video_name ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            print(f"\nğŸ¬ å‹•ç”»åˆ¥ãƒ•ãƒ¬ãƒ¼ãƒ æ•°:")
            video_counts = features_df['video_name'].value_counts()
            for video, count in video_counts.items():
                print(f"   {video}: {count:,}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        
        # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã®è¡¨ç¤ºã¯å‰Šé™¤
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ª
        if 'interpolated' in features_df.columns:
            interpolated_count = features_df['interpolated'].sum()
            interpolation_rate = interpolated_count / len(features_df) * 100 if len(features_df) > 0 else 0 # ã‚¼ãƒ­é™¤ç®—ã‚’å›é¿
            print(f"\nğŸ”§ ãƒ‡ãƒ¼ã‚¿å“è³ª:")
            print(f"   è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {interpolated_count:,}")
            print(f"   è£œé–“ç‡: {interpolation_rate:.1f}%")
        
        # æ¬ æå€¤
        missing_counts = features_df.isnull().sum()
        missing_cols = missing_counts[missing_counts > 0]
        if len(missing_cols) > 0:
            print(f"\nâš ï¸  æ¬ æå€¤:")
            for col, count in missing_cols.items():
                rate = count / len(features_df) * 100
                print(f"   {col}: {count:,} ({rate:.1f}%)")
        else:
            print(f"\nâœ… æ¬ æå€¤: ãªã—")


if __name__ == "__main__":
    # ç‰¹å¾´é‡æŠ½å‡ºå™¨ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    # inference_data_dir ã¯ã€æ¨è«–å¯¾è±¡ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã—ã¾ã™ã€‚
    # ä¾‹: extractor = TennisInferenceFeatureExtractor(inference_data_dir="path/to/your/inference_data")
    # ã“ã“ã§ã¯ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜éšå±¤ã«ã‚ã‚‹ "inference_data_example" ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦ã„ã¾ã™ã€‚
    # ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€é©å®œä½œæˆã¾ãŸã¯ãƒ‘ã‚¹ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚
    
    # ä¾‹: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã« 'my_inference_input' ã¨ã„ã†åå‰ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹å ´åˆ
    # extractor = TennisInferenceFeatureExtractor(inference_data_dir="my_inference_input")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜éšå±¤ã‚’æƒ³å®š)
    default_input_dir = "./training_data" 
    
    # ã‚‚ã—ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒ‘ã‚¹å…¥åŠ›ã‚’ä¿ƒã™ã“ã¨ã‚‚æ¤œè¨ã§ãã¾ã™
    if not Path(default_input_dir).exists():
        print(f"âš ï¸  ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{default_input_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print(f"    ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”¨ã« '{default_input_dir}' ã‚’ä½œæˆã™ã‚‹ã‹ã€")
        print(f"    é©åˆ‡ãª inference_data_dir ã‚’æŒ‡å®šã—ã¦ TennisInferenceFeatureExtractor ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
        # ã“ã“ã§å‡¦ç†ã‚’çµ‚äº†ã™ã‚‹ã‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å…¥åŠ›ã‚’æ±‚ã‚ã‚‹ãªã©ã®å‡¦ç†ã‚’è¿½åŠ ã§ãã¾ã™ã€‚
        # ä¾‹: exit() ã¾ãŸã¯ input_dir = input("æ¨è«–ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
        
    extractor = TennisInferenceFeatureExtractor(inference_data_dir=default_input_dir)

    # ç‰¹å®šã®å‹•ç”»ã®ã¿ã‚’å‡¦ç†ã™ã‚‹å ´åˆ (ä¾‹: "your_video_name_without_extension")
    # video_to_process = "your_inference_video_name_here" 
    # video_to_process ã«å‹•ç”»åã‚’æŒ‡å®šã™ã‚‹ã¨ã€ãã®å‹•ç”»ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒå‡¦ç†ã•ã‚Œã¾ã™ã€‚
    # None ã®å ´åˆã€inference_data_dir å†…ã®ã™ã¹ã¦ã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ãŒå‡¦ç†å¯¾è±¡ã¨ãªã‚Šã¾ã™ã€‚
    video_to_process = None 

    # ç‰¹å¾´é‡æŠ½å‡ºã‚’å®Ÿè¡Œ
    # save_results=True ã«ã™ã‚‹ã¨ã€æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡ãŒCSVãƒ•ã‚¡ã‚¤ãƒ«ãŠã‚ˆã³æƒ…å ±JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã™ã€‚
    # False ã«ã™ã‚‹ã¨ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚
    features_dataframe, saved_feature_path, saved_info_path = extractor.run_feature_extraction(
        video_name=video_to_process,
        save_results=True
    )

    if not features_dataframe.empty:
        print(f"\n--- æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºæˆåŠŸ ---")
        if saved_feature_path:
            print(f"æ¨è«–ç”¨ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {saved_feature_path}")
        if saved_info_path:
            print(f"æ¨è«–ç”¨ç‰¹å¾´é‡æƒ…å ±ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {saved_info_path}")

        # æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡ã®åˆ†æ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        # å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€åˆ†æã«æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
        print("\n--- ç‰¹å¾´é‡åˆ†æé–‹å§‹ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ---")
        extractor.analyze_features(features_dataframe)
        print("--- ç‰¹å¾´é‡åˆ†æå®Œäº† ---")
    else:
        print("\n--- æ¨è«–ç”¨ç‰¹å¾´é‡æŠ½å‡ºå¤±æ•— ---")
        print("å‡¦ç†ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒãªã‹ã£ãŸã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print(f"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {extractor.inference_data_dir}")
        print(f"ç‰¹å¾´é‡ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {extractor.features_dir}")


    print("\nãƒ¡ã‚¤ãƒ³å‡¦ç†å®Œäº†")
