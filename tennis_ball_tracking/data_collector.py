import cv2
import json
import os
import numpy as np
from datetime import datetime
from court_calibrator import CourtCalibrator
import tkinter as tk
import time

class PhaseAnnotator:
    """
    ãƒ†ãƒ‹ã‚¹å±€é¢ãƒ©ãƒ™ãƒªãƒ³ã‚°å°‚ç”¨ã‚¯ãƒ©ã‚¹
    
    ç”¨é€”:
    - å‹•ç”»ã®å±€é¢åˆ†æã¨é«˜é€Ÿãªãƒ©ãƒ™ãƒªãƒ³ã‚°ä½œæ¥­
    - train_phase_model.pyç”¨ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    - ã‚³ãƒ¼ãƒˆåº§æ¨™è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    - æ—¢å­˜ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ç·¨é›†
    """
    def __init__(self):
        # --- çŠ¶æ…‹ç®¡ç† ---
        self.video_cap = None
        self.video_path = None
        self.current_frame_number = 0
        self.total_frames = 0
        self.fps = 30.0
        self.is_playing = False
        self.playback_speed = 1.0
        
        # --- å±€é¢ãƒ‡ãƒ¼ã‚¿ ---
        self.phases = [
            "point_interval", "rally", "serve_front_deuce", "serve_front_ad",
            "serve_back_deuce", "serve_back_ad", "changeover"
        ]
        self.current_phase = None
        self.phase_changes = []
        
        # --- ã‚³ãƒ¼ãƒˆåº§æ¨™ ---
        self.court_coordinates = {}
        self.show_court_overlay = False
        
        # --- UIè¨­å®š ---
        self.display_scale = 1.0
        self.window_width = 1280
        self.window_height = 720
        self.ui_font_scale = 0.6

        # --- ç·¨é›†ãƒ¢ãƒ¼ãƒ‰ç”¨ ---
        self.editing_file_path = None

    def annotate_video(self, video_path: str, existing_annotation_path: str = None):
        """
        å‹•ç”»ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚
        æ—¢å­˜ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ç·¨é›†ãƒ¢ãƒ¼ãƒ‰ã§é–‹å§‹ã—ã¾ã™ã€‚
        """
        self.video_path = video_path
        self.editing_file_path = existing_annotation_path
        if not self._setup(video_path):
            return False

        self._annotation_loop()
        
        return self._cleanup_and_save(video_path)

    # --- åˆæœŸåŒ–ãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
    
    def _setup(self, video_path: str):
        """ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹å‰ã®æº–å‚™ã‚’è¡Œã„ã¾ã™ã€‚"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"Error: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")
            return False
        
        self.set_video_source(cap)
        self._detect_display_size()
        
        print(f"å‹•ç”»ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {os.path.basename(video_path)}")
        
        # æ—¢å­˜ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®èª­ã¿è¾¼ã¿ã€ã¾ãŸã¯æ–°è¦ä½œæˆã®æº–å‚™
        if self.editing_file_path and os.path.exists(self.editing_file_path):
            print(f"\nğŸ“ æ—¢å­˜ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç·¨é›†ä¸­: {os.path.basename(self.editing_file_path)}")
            self._load_phase_data(self.editing_file_path)
        else:
            print("\nğŸ“ æ–°è¦ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚")
            # æ–°è¦ä½œæˆã®å ´åˆã®ã¿ã€ç‹¬ç«‹ã—ãŸã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’è©¦ã¿ã‚‹
            if self.setup_court_coordinates(video_path):
                self.show_court_overlay = True

        self._update_current_phase()
        print(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.total_frames}, FPS: {self.fps:.2f}")
        print(f"è¡¨ç¤ºè¨­å®š: {self.window_width}x{self.window_height} (ã‚¹ã‚±ãƒ¼ãƒ«: {self.display_scale})")

        cv2.namedWindow('Phase Annotation', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Phase Annotation', self.window_width, self.window_height)
        
        self._print_usage_instructions()
        return True

    def _load_phase_data(self, file_path: str):
        """æ—¢å­˜ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ã‚¯ãƒ©ã‚¹ã®çŠ¶æ…‹ã‚’å¾©å…ƒã—ã¾ã™ã€‚"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.phase_changes = data.get('phase_changes', [])
            
            if 'court_coordinates' in data and data['court_coordinates']:
                self.court_coordinates = data['court_coordinates']
                self.show_court_overlay = True
            
            if 'fps' in data: # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã®FPSã‚’å„ªå…ˆ
                self.fps = data['fps']
            
            print(f"âœ… {len(self.phase_changes)}ä»¶ã®å±€é¢å¤‰æ›´ã¨ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            return True
        except Exception as e:
            print(f"âŒ ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            self.editing_file_path = None # å¤±æ•—ã—ãŸå ´åˆã¯æ–°è¦ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return False
    
    def set_video_source(self, video_cap):
        """å‹•ç”»ã‚½ãƒ¼ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚"""
        self.video_cap = video_cap
        if video_cap:
            self.total_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.fps = video_cap.get(cv2.CAP_PROP_FPS)

    def _detect_display_size(self):
        """ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚µã‚¤ã‚ºã‚’æ¤œå‡ºã—ã€é©åˆ‡ãªè¡¨ç¤ºè¨­å®šã‚’æ±ºå®šã—ã¾ã™ã€‚"""
        try:
            root = tk.Tk()
            screen_width = root.winfo_screenwidth()
            screen_height = root.winfo_screenheight()
            root.destroy()
            
            if screen_width >= 2560:
                self.display_scale, self.window_width, self.window_height, self.ui_font_scale = 1.5, 1920, 1080, 0.8
            elif screen_width >= 1920:
                self.display_scale, self.window_width, self.window_height, self.ui_font_scale = 1.2, 1600, 900, 0.7
            elif screen_width >= 1366:
                self.display_scale, self.window_width, self.window_height, self.ui_font_scale = 1.0, 1280, 720, 0.6
            elif screen_width >= 1024:
                self.display_scale, self.window_width, self.window_height, self.ui_font_scale = 0.8, 1000, 600, 0.45
            else:
                self.display_scale, self.window_width, self.window_height, self.ui_font_scale = 0.6, min(800, screen_width - 50), min(500, screen_height - 100), 0.35

        except Exception as e:
            print(f"ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚µã‚¤ã‚ºæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            self.display_scale, self.window_width, self.window_height, self.ui_font_scale = 0.7, 900, 600, 0.4

    # --- (ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã¨ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã¯å¤‰æ›´ãªã—) ---
    def _annotation_loop(self):
            # --- â–¼â–¼â–¼ ä¿®æ­£ç®‡æ‰€ï¼ˆå…¨ä½“ã‚’ç½®ãæ›ãˆï¼‰â–¼â–¼â–¼ ---
            
            # é«˜ç²¾åº¦ã‚¿ã‚¤ãƒãƒ¼ã§ã€ãƒ«ãƒ¼ãƒ—é–‹å§‹å‰ã®æ™‚åˆ»ã‚’è¨˜éŒ²
            loop_start_time = time.perf_counter()

            while True:
                # --- ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã¨UIæç”» ---
                frame = self._get_current_frame()
                if frame is None:
                    break
                self._draw_ui(frame)

                # --- å¾…æ©Ÿæ™‚é–“ã®å‹•çš„è¨ˆç®— ---
                wait_time_ms = 0  # åœæ­¢ä¸­ (is_playing=False) ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¾…æ©Ÿæ™‚é–“ (ã‚­ãƒ¼å…¥åŠ›ã¾ã§ç„¡åˆ¶é™ã«å¾…ã¤)
                
                if self.is_playing:
                    # FPSãŒæ­£å¸¸ã«å–å¾—ã§ãã¦ã„ã‚‹ã‹ç¢ºèª
                    effective_fps = self.fps if self.fps and self.fps > 1 else 30.0
                    # 1ãƒ•ãƒ¬ãƒ¼ãƒ ã‚ãŸã‚Šã«ã‹ã‘ãŸã„ç›®æ¨™æ™‚é–“ï¼ˆç§’ï¼‰
                    target_duration_sec = 1.0 / (effective_fps * self.playback_speed)

                    # å‰å›ã®ãƒ«ãƒ¼ãƒ—é–‹å§‹ã‹ã‚‰ç¾åœ¨ã¾ã§ã®çµŒéæ™‚é–“ï¼ˆå®Ÿéš›ã®å‡¦ç†æ™‚é–“ï¼‰ã‚’è¨ˆç®—
                    processing_time_sec = time.perf_counter() - loop_start_time

                    # å¾…æ©Ÿã™ã¹ãæ™‚é–“ = ç›®æ¨™æ™‚é–“ - å®Ÿéš›ã®å‡¦ç†æ™‚é–“
                    wait_duration_sec = target_duration_sec - processing_time_sec
                    
                    # è¨ˆç®—çµæœã‚’ãƒŸãƒªç§’ã«å¤‰æ›ã€‚è² ã®å€¤ï¼ˆå‡¦ç†é…å»¶ï¼‰ã®å ´åˆã¯æœ€ä½ã§ã‚‚1msã¨ã™ã‚‹
                    wait_time_ms = max(1, int(wait_duration_sec * 1000))

                # --- ã‚­ãƒ¼å…¥åŠ›ã®å—ä»˜ ---
                key = cv2.waitKey(wait_time_ms) & 0xFF

                # æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã®ãŸã‚ã«ã€ç¾åœ¨ã®æ™‚åˆ»ã‚’è¨˜éŒ²ã™ã‚‹
                loop_start_time = time.perf_counter()

                # --- ã‚­ãƒ¼å…¥åŠ›ã®å‡¦ç† ---
                if key != 255 and self._handle_key_input(key):
                    break
            # --- â–²â–²â–² ä¿®æ­£å®Œäº† â–²â–²â–² ---

    def _get_current_frame(self):
            if self.is_playing:
                # --- 60fpså¯¾ç­–: 1ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿é£›ã°ã—ã¦å‡¦ç†è² è·ã‚’åŠåˆ†ã«ã™ã‚‹ ---
                self.video_cap.grab()  # 1ãƒ•ãƒ¬ãƒ¼ãƒ ç›®ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã ã‘ã—ã¦èª­ã¿é£›ã°ã™ï¼ˆæç”»ã—ãªã„ã®ã§é«˜é€Ÿï¼‰
                ret, frame = self.video_cap.read() # 2ãƒ•ãƒ¬ãƒ¼ãƒ ç›®ã‚’èª­ã¿è¾¼ã‚“ã§ã€ã“ã‚Œã‚’è¡¨ç¤ºå¯¾è±¡ã¨ã™ã‚‹
                
                if not ret:
                    print("å‹•ç”»ã®çµ‚ç«¯ã«é”ã—ã¾ã—ãŸ")
                    self.is_playing = False
                    self._seek_frame(self.total_frames - 1)
                    # çµ‚ç«¯ã§ã‚‚ã†ä¸€åº¦èª­ã¿è¾¼ã¿ã‚’è©¦ã¿ã‚‹
                    self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, self.current_frame_number)
                    ret, frame = self.video_cap.read()
                else:
                    self.current_frame_number = int(self.video_cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1
            else:
                # åœæ­¢ä¸­ã¯ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„
                self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, self.current_frame_number)
                ret, frame = self.video_cap.read()
                
            return frame if ret else None
    def _handle_key_input(self, key):
        if ord('1') <= key <= ord('7'): self._record_phase_change(self.phases[key - ord('1')])
        elif key == ord(' '): self.is_playing = not self.is_playing
        elif key in [ord('d'), 83]: self._seek_frame(self.current_frame_number + 1, stop_playback=True)
        elif key in [ord('a'), 81]: self._seek_frame(self.current_frame_number - 1, stop_playback=True)
        elif key in [ord('w'), 82]: self._seek_frame(self.current_frame_number + 10, stop_playback=True)
        elif key in [ord('s'), 84]: self._seek_frame(self.current_frame_number - 10, stop_playback=True)
        elif key == ord('z'): self._seek_frame(self.current_frame_number - 100, stop_playback=True)
        elif key == ord('x'): self._seek_frame(self.current_frame_number + 100, stop_playback=True)
        elif key == 2: self._seek_frame(0, stop_playback=True)
        elif key == 3: self._seek_frame(self.total_frames - 1, stop_playback=True)
        elif key in [ord('-'), ord('_')]: self._change_playback_speed(direction='down')
        elif key in [ord('+'), ord('=')]: self._change_playback_speed(direction='up')
        elif key == ord('0'): self.playback_speed = 1.0
        elif key == ord('c'): self._run_court_calibration()
        elif key == ord('o'): self.show_court_overlay = not self.show_court_overlay
        elif key == ord('r'): self._reset_annotations()
        elif key == ord('u'): self._undo_last_phase_change()
        elif key == ord('q'): return self._confirm_exit()
        return False
    def _seek_frame(self, target_frame, stop_playback=False):
        self.current_frame_number = max(0, min(target_frame, self.total_frames - 1))
        if stop_playback: self.is_playing = False
        self._update_current_phase()
    def _change_playback_speed(self, direction='up'):
        speed_levels = [0.25, 0.5, 1.0, 2.0, 4.0]
        try:
            current_index = speed_levels.index(self.playback_speed)
            if direction == 'up' and current_index < len(speed_levels) - 1: self.playback_speed = speed_levels[current_index + 1]
            elif direction == 'down' and current_index > 0: self.playback_speed = speed_levels[current_index - 1]
            print(f"å†ç”Ÿé€Ÿåº¦: {self.playback_speed}x")
        except ValueError: self.playback_speed = 1.0
    def _run_court_calibration(self):
            print("\nã‚³ãƒ¼ãƒˆåº§æ¨™è¨­å®šã‚’é–‹å§‹ã—ã¾ã™...")
            
            # 1. ç¾åœ¨ã®å†ç”ŸçŠ¶æ…‹ã¨ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’ä¿å­˜
            original_is_playing = self.is_playing
            original_frame_number = self.current_frame_number
            self.is_playing = False  # å®‰å…¨ã®ãŸã‚å†ç”Ÿã‚’åœæ­¢
            
            # 2. ç¾åœ¨è¡¨ç¤ºã—ã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ­£ç¢ºã«å–å¾—ã—ã¦ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ä½¿ã†
            self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, original_frame_number)
            ret, frame_for_calib = self.video_cap.read()
            if not ret:
                print("âŒ ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                self.is_playing = original_is_playing # å…ƒã®çŠ¶æ…‹ã«æˆ»ã™
                return

            # 3. CourtCalibratorã‚’æº–å‚™ã—ã€æ—¢å­˜ã®åº§æ¨™ãŒã‚ã‚Œã°æ¸¡ã™
            calibrator = CourtCalibrator()
            if self.court_coordinates:
                print("æ—¢å­˜ã®åº§æ¨™ã‚’èª­ã¿è¾¼ã‚“ã§ç·¨é›†ãƒ¢ãƒ¼ãƒ‰ã§é–‹å§‹ã—ã¾ã™ã€‚")
                calibrator.set_coordinates(self.court_coordinates)

            # 4. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            # calibrateãƒ¡ã‚½ãƒƒãƒ‰ãŒTrueã‚’è¿”ã›ã°ã€åº§æ¨™ãŒè¨­å®šã¾ãŸã¯æ›´æ–°ã•ã‚ŒãŸ
            if calibrator.calibrate(frame_for_calib, self.video_cap):
                self.court_coordinates = calibrator.get_coordinates()
                self.show_court_overlay = True
                print("âœ… ã‚³ãƒ¼ãƒˆåº§æ¨™ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚")
                if self.video_path:
                    try:
                        video_name = os.path.splitext(os.path.basename(self.video_path))[0]
                        output_dir = "training_data"
                        os.makedirs(output_dir, exist_ok=True)
                        coord_file = os.path.join(output_dir, f"court_coords_{video_name}.json")

                        with open(coord_file, 'w', encoding='utf-8') as f:
                            json.dump(self.court_coordinates, f, indent=2, ensure_ascii=False)
                            print(f"âœ… ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {coord_file}")
                    except Exception as e:
                        print(f"âŒ ã‚³ãƒ¼ãƒˆåº§æ¨™ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

            else:
                print("ğŸŸ¡ ã‚³ãƒ¼ãƒˆåº§æ¨™è¨­å®šãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã¾ãŸã¯ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")

            # 5. ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å†ç”Ÿæˆ
            # CourtCalibratorã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‰ã˜ã‚‹ãŸã‚ã€ã“ã¡ã‚‰ã‚‚å†æº–å‚™ãŒå¿…è¦
            cv2.destroyAllWindows() 
            cv2.namedWindow('Phase Annotation', cv2.WINDOW_NORMAL)
            cv2.resizeWindow('Phase Annotation', self.window_width, self.window_height)

            # 6. å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¨å†ç”ŸçŠ¶æ…‹ã«æˆ»ã™
            # ã“ã‚Œã«ã‚ˆã‚Šã€ä½œæ¥­ã‚’ä¸­æ–­ã—ãŸã¨ã“ã‚ã‹ã‚‰ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«å†é–‹ã§ãã‚‹
            self._seek_frame(original_frame_number, stop_playback=(not original_is_playing))

    # --- (UIæç”»ã¯å¤‰æ›´ãªã—) ---
    def _draw_ui(self, frame):
        # --- â–¼â–¼â–¼ ã€ãƒ†ã‚¹ãƒˆç”¨ã€‘UIæç”»ã‚’æ¥µé™ã¾ã§è»½é‡åŒ– â–¼â–¼â–¼ ---
        if self.is_playing:
            # ã€ãƒ†ã‚¹ãƒˆã€‘å†ç”Ÿä¸­ã¯ãƒªã‚µã‚¤ã‚ºã—ã¦è¡¨ç¤ºã™ã‚‹ã ã‘ã€‚UIã¯ä¸€åˆ‡æç”»ã—ãªã„ã€‚
            # ã“ã‚Œã§é€Ÿåº¦ãŒæ”¹å–„ã™ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚
            display_frame, _ = self._resize_frame_for_display(frame)
            cv2.imshow('Phase Annotation', display_frame)
        else:
            # åœæ­¢ä¸­ã¯å…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿è­·ã™ã‚‹ãŸã‚ã«ã‚³ãƒ”ãƒ¼ã—ã¦ã‹ã‚‰UIã‚’æç”»ã—ã¾ã™
            display_frame, scale_factors = self._resize_frame_for_display(frame.copy())
            if self.show_court_overlay and self.court_coordinates:
                display_frame = self.draw_court_overlay(display_frame, scale_factors)
            
            # _draw_annotation_uiã¯å‰å›ä¿®æ­£ã—ãŸè»½é‡ç‰ˆã‚’å‘¼ã³å‡ºã—ã¾ã™
            self._draw_annotation_ui(display_frame)
            cv2.imshow('Phase Annotation', display_frame)
        # --- â–²â–²â–² ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰çµ‚äº† â–²â–²â–² ---
    def _resize_frame_for_display(self, frame):
        h, w = frame.shape[:2]
        target_w, target_h = int(self.window_width * 0.7), int(self.window_height * 0.9)
        aspect_ratio = w / h if h > 0 else 1.0
        if target_w / aspect_ratio <= target_h: new_w, new_h = target_w, int(target_w / aspect_ratio)
        else: new_h, new_w = target_h, int(target_h * aspect_ratio)
        resized_frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
        scale_x, scale_y = (new_w / w if w > 0 else 0), (new_h / h if h > 0 else 0)
        return resized_frame, (scale_x, scale_y)
    def _draw_annotation_ui(self, frame):
            # --- â–¼â–¼â–¼ ä¿®æ­£ç®‡æ‰€ï¼ˆå…¨ä½“ã‚’ç½®ãæ›ãˆï¼‰â–¼â–¼â–¼ ---
            h, w = frame.shape[:2]
            font_scale, thickness = max(0.3, self.ui_font_scale * self.display_scale), max(1, int(1.5 * self.display_scale))
            y, dy, left_x, right_x = int(20 * self.display_scale), int(18 * self.display_scale), 10, w // 2 + 10

            # --- UIè¦ç´ ã®åº§æ¨™ãªã©ã‚’äº‹å‰ã«è¨ˆç®— ---
            info_y, status_y, phase_y = y, y + dy, y + dy * 2
            ph_dy = int(dy * 0.7)
            phases_list_y_start = phase_y + int(dy * 1.3)
            phases_per_column = (len(self.phases) + 1) // 2
            phases_list_y_end = phases_list_y_start + (phases_per_column -1) * ph_dy
            help_texts = ["1-7:Phase SPACE:Play/Pause A/D:Frame W/S:10f Z/X:100f", "+/-:Speed 0:1x C:Court O:Overlay U:Undo Q:Save&Quit"]
            help_y_start = phases_list_y_end + int(dy * 1.5)
            help_y_end = help_y_start + (len(help_texts) - 1) * int(dy * 0.6)

            # --- ã‚¹ãƒ†ãƒƒãƒ—1: UIèƒŒæ™¯ã®æç”»ã‚’è»½é‡åŒ– ---
            # å†ç”Ÿä¸­ã¯æœ€å°é™ã®èƒŒæ™¯ã€åœæ­¢ä¸­ã¯å…¨ã¦ã®UIãŒå…¥ã‚‹é«˜ã•ã®èƒŒæ™¯ã‚’æç”»
            if self.is_playing:
                ui_background_height = phase_y + int(dy * 0.5)
            else:
                ui_background_height = help_y_end + int(20 * self.display_scale)

            # â˜…â˜…â˜… æœ€ã‚‚é‡è¦ãªè»½é‡åŒ–: addWeightedã‚’å»ƒæ­¢ã—ã€å˜ç´”ãªçŸ©å½¢æç”»ã«å¤‰æ›´ â˜…â˜…â˜…
            cv2.rectangle(frame, (5, 5), (w - 5, min(h - 5, ui_background_height)), (0, 0, 0), -1)

            # --- å¸¸ã«è¡¨ç¤ºã™ã‚‹æƒ…å ±ï¼ˆå†ç”Ÿä¸­/åœæ­¢ä¸­å…±é€šï¼‰ ---
            progress = self.current_frame_number / self.total_frames if self.total_frames > 0 else 0
            # Frameã¨Progressã‚’1è¡Œã«ã¾ã¨ã‚ã¦æç”»å‘½ä»¤ã‚’å‰Šæ¸›
            cv2.putText(frame, f"Frame: {self.current_frame_number}/{self.total_frames} ({progress:.1%})", (left_x, info_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255,255,255), thickness)

            status, s_color = ("PLAY", (0,255,0)) if self.is_playing else ("PAUSE", (0,0,255))
            cv2.putText(frame, f"Status: {status}", (left_x, status_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, s_color, thickness)
            cv2.putText(frame, f"Speed: {self.playback_speed}x", (right_x, status_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,255), thickness)
            cv2.putText(frame, f"Phase: {self.current_phase or 'None'}", (left_x, phase_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,255,0), thickness)

            # --- ã‚¹ãƒ†ãƒƒãƒ—2: åœæ­¢ä¸­ (is_playing=False) ã®ã¿è©³ç´°æƒ…å ±ã‚’æç”» ---
            if not self.is_playing:
                court_info = f"ON ({len(self.court_coordinates)} pts)" if self.court_coordinates else "OFF"
                court_status = f"Court: {court_info} | Ovl: {'ON' if self.show_court_overlay else 'OFF'}"
                cv2.putText(frame, court_status, (right_x, phase_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255,255,0), thickness)

                # å±€é¢ãƒªã‚¹ãƒˆã®æç”»
                ph_font_scale = font_scale * 0.85
                for i, p in enumerate(self.phases):
                    col, row = i // phases_per_column, i % phases_per_column
                    x_pos, y_pos = (left_x if col == 0 else right_x), phases_list_y_start + row * ph_dy
                    color = (0, 255, 0) if p == self.current_phase else (255, 255, 255)
                    short_phase = p.replace("serve_", "").replace("_", " ")[:12]
                    cv2.putText(frame, f"{i+1}: {short_phase}", (x_pos, y_pos), cv2.FONT_HERSHEY_SIMPLEX, ph_font_scale, color, max(1, thickness-1))

                # ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã®æç”»
                for i, text in enumerate(help_texts):
                    y_pos = help_y_start + i * int(dy * 0.6)
                    if y_pos < h - 10: cv2.putText(frame, text, (left_x, y_pos), cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.6, (255,255,0), max(1, thickness-1))
            # --- â–²â–²â–² ä¿®æ­£å®Œäº† â–²â–²â–² ---
    def draw_court_overlay(self, frame, scale_factors):
        overlay_frame, thickness, (scale_x, scale_y) = frame.copy(), max(1, int(1.5 * self.display_scale)), scale_factors
        scaled_coords = {name: (int(p[0] * scale_x), int(p[1] * scale_y)) for name, p in self.court_coordinates.items() if p and len(p) == 2}
        corner_keys = ["top_left_corner", "top_right_corner", "bottom_right_corner", "bottom_left_corner"]
        points = [scaled_coords.get(key) for key in corner_keys]
        if all(p is not None for p in points): cv2.polylines(overlay_frame, [np.array(points, dtype=np.int32)], isClosed=True, color=(255, 255, 0), thickness=thickness)
        net_l, net_r = scaled_coords.get("net_left_ground"), scaled_coords.get("net_right_ground")
        if net_l and net_r: cv2.line(overlay_frame, net_l, net_r, (0, 255, 255), thickness + 1)
        for point in scaled_coords.values(): cv2.circle(overlay_frame, point, max(2, int(4 * self.display_scale)), (0, 255, 0), -1)
        return overlay_frame

    # --- (ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã¯å¤‰æ›´ãªã—) ---
    def _record_phase_change(self, new_phase):
        frame_num = self.current_frame_number
        self.phase_changes = [c for c in self.phase_changes if c['frame_number'] <= frame_num]
        if self.phase_changes and self.phase_changes[-1]['frame_number'] == frame_num:
            if self.phase_changes[-1]['phase'] != new_phase:
                old_phase = self.phase_changes[-1]['phase']
                self.phase_changes[-1]['phase'] = new_phase
                print(f"Frame {frame_num}: å±€é¢ã‚’ä¸Šæ›¸ã -> {new_phase} (æ—§: {old_phase})")
        else:
            if self.phase_changes and self.phase_changes[-1]['phase'] == new_phase: return
            self.phase_changes.append({'frame_number': frame_num, 'phase': new_phase, 'timestamp': frame_num / self.fps})
            print(f"Frame {frame_num}: æ–°ã—ã„å±€é¢ -> {new_phase}")
        self.phase_changes.sort(key=lambda x: x['frame_number'])
        self.current_phase = new_phase
    def _update_current_phase(self):
        updated_phase = None
        for change in reversed(self.phase_changes):
            if change['frame_number'] <= self.current_frame_number:
                updated_phase = change['phase']; break
        self.current_phase = updated_phase
    def _undo_last_phase_change(self):
        if self.phase_changes:
            removed = self.phase_changes.pop()
            print(f"å–ã‚Šæ¶ˆã—: Frame {removed['frame_number']} - {removed['phase']}")
            self._update_current_phase()
        else: print("å–ã‚Šæ¶ˆã™å¤‰æ›´ãŒã‚ã‚Šã¾ã›ã‚“")
    def _reset_annotations(self):
        if self.phase_changes and input("å…¨ã¦ã®å±€é¢å¤‰æ›´ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower() == 'y':
            self.phase_changes, self.current_phase = [], None
            print("å…¨ã¦ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

    # --- çµ‚äº†ã¨ä¿å­˜ ---

    def _cleanup_and_save(self, video_path):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™ã€‚ç·¨é›†ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ä¸Šæ›¸ãç¢ºèªã‚’è¡Œã„ã¾ã™ã€‚"""
        self.video_cap.release()
        cv2.destroyAllWindows()
        
        if not self.phase_changes:
            print("å¤‰æ›´ãŒãªã‹ã£ãŸãŸã‚ã€ä¿å­˜ã›ãšã«çµ‚äº†ã—ã¾ã™ã€‚")
            return False

        if self.editing_file_path:
            overwrite = input(f"æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¸Šæ›¸ãä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower()
            if overwrite == 'y':
                return self._save_phase_data(video_path, output_path=self.editing_file_path)

        return self._save_phase_data(video_path)
    
    def _confirm_exit(self):
        """çµ‚äº†æ™‚ã®ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
        if not self.phase_changes:
            return True
        save = input("å¤‰æ›´ã‚’ä¿å­˜ã—ã¦çµ‚äº†ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower()
        if save == 'y': return True
        else: return input("ä¿å­˜ã›ãšã«çµ‚äº†ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower() == 'y'

    def _save_phase_data(self, video_path: str, output_path: str = None):
        """å±€é¢ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚output_pathãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ä¸Šæ›¸ãã—ã¾ã™ã€‚"""
        if output_path:
            phase_file = output_path
        else:
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            output_dir = "training_data"
            os.makedirs(output_dir, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            phase_file = os.path.join(output_dir, f"phase_annotations_{video_name}_{timestamp}.json")
        
        annotation_data = {
            'video_path': os.path.abspath(video_path),
            'video_name': os.path.splitext(os.path.basename(video_path))[0],
            'total_frames': self.total_frames, 'fps': self.fps,
            'duration_seconds': self.total_frames / self.fps,
            'phase_changes': self.phase_changes,
            'annotation_timestamp': datetime.now().strftime("%Y%m%d_%H%M%S"),
            'phase_statistics': self._calculate_phase_statistics(),
            'court_coordinates': self.court_coordinates or None,
            'court_coordinates_available': bool(self.court_coordinates)
        }
        
        try:
            with open(phase_file, 'w', encoding='utf-8') as f:
                json.dump(annotation_data, f, indent=2, ensure_ascii=False)
            
            save_type = "ä¸Šæ›¸ãä¿å­˜" if output_path else "æ–°è¦ä¿å­˜"
            print(f"\nâœ… å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’{save_type}ã—ã¾ã—ãŸ: {phase_file}")
            self._print_statistics(annotation_data)
            return True
        except Exception as e:
            print(f"âŒ å±€é¢ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def setup_court_coordinates(self, video_path):
        """ï¼ˆæ–°è¦ä½œæˆæ™‚ç”¨ï¼‰ç‹¬ç«‹ã—ãŸã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚"""
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        coord_file = os.path.join("training_data", f"court_coords_{video_name}.json")
        if os.path.exists(coord_file):
            try:
                with open(coord_file, 'r') as f: self.court_coordinates = json.load(f)
                print(f"âœ… æ—¢å­˜ã®ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {coord_file}")
                for name, point in self.court_coordinates.items(): print(f"   - {name}: {point}")
                return True
            except Exception as e:
                print(f"âŒ ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    # (save_court_coordinates, çµ±è¨ˆã€ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã¯å¤‰æ›´ãªã—)
    def save_court_coordinates(self, video_path):
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        output_dir = "training_data"; os.makedirs(output_dir, exist_ok=True)
        coord_file = os.path.join(output_dir, f"court_coords_{video_name}.json")
        try:
            with open(coord_file, 'w') as f: json.dump(self.court_coordinates, f, indent=2)
            print(f"âœ… ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {coord_file}"); return True
        except Exception as e:
            print(f"âŒ ã‚³ãƒ¼ãƒˆåº§æ¨™ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"); return False
    def _calculate_phase_statistics(self):
        if not self.phase_changes: return {}
        durations = {phase: 0 for phase in self.phases}
        for i, change in enumerate(self.phase_changes):
            start_frame, end_frame = change['frame_number'], self.phase_changes[i+1]['frame_number'] if i + 1 < len(self.phase_changes) else self.total_frames
            durations[change['phase']] += (end_frame - start_frame)
        total_duration_sec = self.total_frames / self.fps
        stats = {}
        for phase, frame_count in durations.items():
            if frame_count > 0:
                duration_sec = frame_count / self.fps
                stats[phase] = {'duration': duration_sec, 'percentage': (duration_sec / total_duration_sec) * 100 if total_duration_sec > 0 else 0}
        return stats
    def _print_statistics(self, data):
        print(f"è¨˜éŒ²ã•ã‚ŒãŸå±€é¢å¤‰æ›´æ•°: {len(data['phase_changes'])}")
        if data['court_coordinates_available']: print("ğŸŸï¸  ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™")
        print("\n=== å±€é¢çµ±è¨ˆ ===")
        stats = data.get('phase_statistics', {})
        for phase, info in stats.items(): print(f"{phase:<20}: {info['duration']:.1f}ç§’ ({info['percentage']:.1f}%)")
    def _print_usage_instructions(self):
        print("\n=== å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ ===")
        print("å±€é¢é¸æŠ: 1-7ã‚­ãƒ¼ | å†ç”Ÿåˆ¶å¾¡: SPACE, a/d, w/s, z/x | å†ç”Ÿé€Ÿåº¦: +/-, 0")
        print("ã‚³ãƒ¼ãƒˆåº§æ¨™: c (è¨­å®š), o (ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ON/OFF) | ãã®ä»–: u (å…ƒã«æˆ»ã™), r (ãƒªã‚»ãƒƒãƒˆ), q (çµ‚äº†)")

# --- CLIãƒ¡ãƒ‹ãƒ¥ãƒ¼ã¨ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†é–¢æ•° ---

def select_annotation_file(video_path: str):
    """æŒ‡å®šã•ã‚ŒãŸå‹•ç”»ã«å¯¾å¿œã™ã‚‹æ—¢å­˜ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã•ã›ã¾ã™ã€‚"""
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    output_dir = "training_data"
    
    existing_files = []
    if os.path.exists(output_dir):
        for f in os.listdir(output_dir):
            if f.startswith(f"phase_annotations_{video_name}_") and f.endswith(".json"):
                existing_files.append(os.path.join(output_dir, f))

    if not existing_files:
        print("\næ—¢å­˜ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    print("\n=== æ—¢å­˜ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ ===")
    existing_files.sort(key=os.path.getmtime, reverse=True)
    for i, f_path in enumerate(existing_files, 1):
        print(f"{i}: {os.path.basename(f_path)}")
    print(f"{len(existing_files) + 1}: ğŸ“ æ–°è¦ä½œæˆ")
    
    try:
        choice = int(input(f"\nç·¨é›†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ (1-{len(existing_files) + 1}): "))
        if 1 <= choice <= len(existing_files):
            return existing_files[choice - 1]
    except (ValueError, IndexError):
        pass
    
    print("æ–°è¦ä½œæˆã‚’é¸æŠã—ã¾ã—ãŸã€‚")
    return None

def get_video_files(data_dir="../data/raw"):
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']
    search_paths = [data_dir, "data/raw", "./data/raw"]
    for path in search_paths:
        abs_path = os.path.abspath(path)
        if os.path.exists(abs_path):
            try:
                files = [os.path.join(abs_path, f) for f in os.listdir(abs_path) if any(f.lower().endswith(ext) for ext in video_extensions)]
                if files:
                    print(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {abs_path} ã§ç™ºè¦‹ã—ã¾ã—ãŸã€‚")
                    return files
            except Exception as e: print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")
    return []

def select_video_file():
    video_files = get_video_files()
    if not video_files:
        print("\nå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        if input("æ‰‹å‹•ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower() == 'y':
            path = input("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
            return path if os.path.exists(path) else None
        return None
    print("\n=== å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ===")
    for i, video_path in enumerate(video_files, 1): print(f"{i}: {os.path.basename(video_path)}")
    try:
        choice = int(input(f"\nå‹•ç”»ã‚’é¸æŠã—ã¦ãã ã•ã„ (1-{len(video_files)}): "))
        return video_files[choice - 1] if 1 <= choice <= len(video_files) else None
    except ValueError: return None

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã‚’èµ·å‹•ã—ã¾ã™ã€‚"""
    print("=== ãƒ†ãƒ‹ã‚¹å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ« (ç·¨é›†æ©Ÿèƒ½ä»˜ã) ===")
    print("1: å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹")
    print("2: çµ‚äº†")
    
    choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1-2): ").strip()
    
    if choice == '1':
        video_path = select_video_file()
        if video_path:
            annotation_path = select_annotation_file(video_path)
            annotator = PhaseAnnotator()
            annotator.annotate_video(video_path, existing_annotation_path=annotation_path)
    
    print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\næ“ä½œãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    except Exception as e:
        print(f"\näºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")