import json
import pandas as pd
import numpy as np
import os
import glob
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import warnings
from tqdm import tqdm # tqdmã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import numba
import cv2

warnings.filterwarnings('ignore')

@numba.jit(nopython=True, parallel=True)
def vectorized_rolling_stats(data_matrix: np.ndarray, window: int, 
                            is_interpolated: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸç§»å‹•çµ±è¨ˆè¨ˆç®— (Numba JITã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¯¾å¿œã€axiså¼•æ•°å•é¡Œã‚’å®Œå…¨ä¿®æ­£)"""
    n_rows, n_cols = data_matrix.shape
    
    ma_results = np.zeros_like(data_matrix)
    std_results = np.zeros_like(data_matrix)
    max_results = np.zeros_like(data_matrix)
    min_results = np.zeros_like(data_matrix)
    
    half_window = window // 2
    
    # --- ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç† (æ‰‹å‹•å®Ÿè£…) ---
    padded_data = np.empty((n_rows + 2 * half_window, n_cols), dtype=np.float64)
    padded_data[half_window:half_window + n_rows] = data_matrix
    for i in range(half_window):
        padded_data[i] = data_matrix[0]
        padded_data[n_rows + half_window + i] = data_matrix[-1]

    weights = np.where(is_interpolated, 0.3, 0.8)
    
    padded_weights = np.empty(n_rows + 2 * half_window, dtype=np.float64)
    padded_weights[half_window:half_window + n_rows] = weights
    for i in range(half_window):
        padded_weights[i] = weights[0]
        padded_weights[n_rows + half_window + i] = weights[-1]

    # --- ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®è¨ˆç®— (ä¸¦åˆ—åŒ–) ---
    for i in numba.prange(n_rows):
        window_start = i
        window_end = i + window
        
        window_data = padded_data[window_start:window_end]
        window_weights = padded_weights[window_start:window_end]
        
        # --- å¹³å‡å€¤ (mean) ã®è¨ˆç®— ---
        weight_sum = np.sum(window_weights)
        if weight_sum > 0:
            weighted_data = window_data * window_weights.reshape(-1, 1)
            ma_results[i, :] = np.sum(weighted_data, axis=0) / weight_sum
        else:
            ma_results[i, :] = np.sum(window_data, axis=0) / window_data.shape[0]

        # â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒä»Šå›ã®ä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜…

        # --- æ¨™æº–åå·® (std) ã®è¨ˆç®— (æ‰‹å‹•å®Ÿè£…) ---
        # E[X^2] - (E[X])^2 ã‚’åˆ©ç”¨
        mean_val = np.sum(window_data, axis=0) / window_data.shape[0]
        mean_sq_val = np.sum(window_data**2, axis=0) / window_data.shape[0]
        variance = mean_sq_val - mean_val**2
        # æµ®å‹•å°æ•°ç‚¹èª¤å·®ã§è² ã«ãªã‚‹ã®ã‚’é˜²ã
        for j in range(n_cols):
            if variance[j] < 0:
                variance[j] = 0
        std_results[i, :] = np.sqrt(variance)

        # --- æœ€å¤§å€¤ (max) ã®è¨ˆç®— (æ‰‹å‹•å®Ÿè£…) ---
        # å„åˆ—ã”ã¨ã«æœ€å¤§å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ«ãƒ¼ãƒ—
        for j in range(n_cols):
            max_results[i, j] = np.max(window_data[:, j])

        # --- æœ€å°å€¤ (min) ã®è¨ˆç®— (æ‰‹å‹•å®Ÿè£…) ---
        # å„åˆ—ã”ã¨ã«æœ€å°å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ«ãƒ¼ãƒ—
        for j in range(n_cols):
            min_results[i, j] = np.min(window_data[:, j])
    
    return ma_results, std_results, max_results, min_results



class TennisFeatureExtractor:
    """
    ãƒ†ãƒ‹ã‚¹å‹•ç”»ã®å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ã‚’çµ±åˆã—ã€
    æ©Ÿæ¢°å­¦ç¿’ç”¨ã®ç‰¹å¾´é‡ã‚’ä½œæˆã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, training_data_dir: str = "training_data"):
        self.training_data_dir = Path(training_data_dir)
        self.features_dir = self.training_data_dir / "features"
        self.features_dir.mkdir(exist_ok=True)
        
        self.phase_labels = [
            "point_interval",           # 0: ãƒã‚¤ãƒ³ãƒˆé–“
            "rally",                   # 1: ãƒ©ãƒªãƒ¼ä¸­
            "serve_front_deuce",      # 3: æ‰‹å‰ãƒ‡ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒ‰ã‹ã‚‰ã®ã‚µãƒ¼ãƒ–
            "serve_front_ad",         # 4: æ‰‹å‰ã‚¢ãƒ‰ã‚µã‚¤ãƒ‰ã‹ã‚‰ã®ã‚µãƒ¼ãƒ–
            "serve_back_deuce",       # 5: å¥¥ãƒ‡ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒ‰ã‹ã‚‰ã®ã‚µãƒ¼ãƒ–
            "serve_back_ad",          # 6: å¥¥ã‚¢ãƒ‰ã‚µã‚¤ãƒ‰ã‹ã‚‰ã®ã‚µãƒ¼ãƒ–
            "changeover"              # 7: ãƒã‚§ãƒ³ã‚¸ã‚³ãƒ¼ãƒˆé–“
        ]
        self.label_to_id = {label: idx for idx, label in enumerate(self.phase_labels)}
        
        print(f"ç‰¹å¾´é‡æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.training_data_dir}")
        print(f"ç‰¹å¾´é‡ä¿å­˜å…ˆ: {self.features_dir}")
        print(f"å¯¾è±¡å±€é¢æ•°: {len(self.phase_labels)}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def load_phase_annotations(self, video_name: str = None) -> Dict[str, Any]:
        """å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        pattern = "phase_annotations_*.json"
        if video_name:
            pattern = f"phase_annotations_{video_name}_*.json"
        
        annotation_files = list(self.training_data_dir.glob(pattern))
        
        if not annotation_files:
            print(f"âš ï¸  å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
            return {}
        
        all_annotations = {}
        for file_path in annotation_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                video_key = data.get('video_name', file_path.stem)
                all_annotations[video_key] = data
                print(f"âœ… å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿: {file_path.name}")
                print(f"   å‹•ç”»: {video_key}, å±€é¢å¤‰æ›´æ•°: {len(data.get('phase_changes', []))}")
                
            except Exception as e:
                print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
        
        return all_annotations
    
    def load_tracking_features(self, video_name: str = None) -> Dict[str, Dict]:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰"""
        pattern = "tracking_features_*.json"
        if video_name:
            pattern = f"tracking_features_{video_name}_*.json"
        
        tracking_files = list(self.training_data_dir.glob(pattern))
        
        if not tracking_files:
            print(f"âš ï¸  ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
            return {}
        
        all_tracking = {}
        for file_path in tracking_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å‹•ç”»åã‚’æ¨å®š
                filename_parts = file_path.stem.split('_')
                if len(filename_parts) >= 3:
                    # tracking_features_video_name_timestamp ã®å½¢å¼ã‚’æƒ³å®š
                    video_key = '_'.join(filename_parts[2:-1])  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’é™¤å»
                else:
                    video_key = file_path.stem
                
                # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ–°å½¢å¼ã‹æ—§å½¢å¼ã‹ï¼‰
                if isinstance(data, dict) and 'metadata' in data and 'frames' in data:
                    # æ–°å½¢å¼ï¼šãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãŒåˆ†é›¢ã•ã‚Œã¦ã„ã‚‹
                    all_tracking[video_key] = data
                    print(f"âœ… ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆæ–°å½¢å¼ï¼‰: {file_path.name}")
                    print(f"   å‹•ç”»: {video_key}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(data['frames'])}")
                    if 'frame_skip' in data['metadata']:
                        print(f"   ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {data['metadata']['frame_skip']}")
                elif isinstance(data, list):
                    # æ—§å½¢å¼ï¼šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®ã¿ã®ãƒªã‚¹ãƒˆ
                    all_tracking[video_key] = {
                        'metadata': {'frame_skip': 1, 'legacy_format': True},
                        'frames': data
                    }
                    print(f"âœ… ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆæ—§å½¢å¼ï¼‰: {file_path.name}")
                    print(f"   å‹•ç”»: {video_key}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(data)}")
                    print(f"   æ³¨æ„: æ—§å½¢å¼ã®ãŸã‚ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãªã—")
                else:
                    print(f"âš ï¸  ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿å½¢å¼: {file_path.name}")
                    print(f"   ãƒ‡ãƒ¼ã‚¿å‹: {type(data)}")
                    if isinstance(data, dict):
                        print(f"   ã‚­ãƒ¼: {list(data.keys())[:10]}")
                    continue
                
            except Exception as e:
                print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
        
        return all_tracking
    
    def load_court_coordinates(self, video_name: str = None) -> Dict[str, Dict]:
        """ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        pattern = "court_coords_*.json"
        if video_name:
            pattern = f"court_coords_{video_name}_*.json"
        
        court_files = list(self.training_data_dir.glob(pattern))
        
        if not court_files:
            print(f"âš ï¸  ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
            return {}
        
        all_court_coords = {}
        for file_path in court_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å‹•ç”»åã‚’æ¨å®š
                filename_parts = file_path.stem.split('_')
                if len(filename_parts) >= 3:
                    video_key = '_'.join(filename_parts[2:])  # court_coords_ã‚’é™¤ã
                else:
                    video_key = file_path.stem
                
                all_court_coords[video_key] = data
                print(f"âœ… ã‚³ãƒ¼ãƒˆåº§æ¨™èª­ã¿è¾¼ã¿: {file_path.name}")
                print(f"   å‹•ç”»: {video_key}")
                
            except Exception as e:
                print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
        
        return all_court_coords
    
    # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚°ãƒ»æ¤œè¨¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def match_video_data(self, phase_annotations: Dict, tracking_features: Dict, court_coordinates: Dict = None) -> List[Tuple[str, Dict, Dict, Dict]]:
        """å‹•ç”»åã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã€ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ æ›´æ–°ãƒ»è¨ºæ–­å¼·åŒ–ï¼‰"""
        matched_data = []
        
        print("\n=== ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚° ===")
        print(f"å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»æ•°: {len(phase_annotations)}")
        print(f"ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡å‹•ç”»æ•°: {len(tracking_features)}")
        print(f"ã‚³ãƒ¼ãƒˆåº§æ¨™å‹•ç”»æ•°: {len(court_coordinates) if court_coordinates else 0}")
        
        print("\n--- åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ« ---")
        print("å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³:")
        for key in phase_annotations.keys():
            print(f"  - {key}")
        print("ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡:")
        for key in tracking_features.keys():
            print(f"  - {key}")
        if court_coordinates:
            print("ã‚³ãƒ¼ãƒˆåº§æ¨™:")
            for key in court_coordinates.keys():
                print(f"  - {key}")
        
        print("\n--- ãƒãƒƒãƒãƒ³ã‚°å‡¦ç† ---")
        
        for video_name in phase_annotations.keys():
            tracking_data = None
            court_data = None
            tracking_match_type = "ãªã—"
            court_match_type = "ãªã—"
            tracking_matched_key = ""
            court_matched_key = ""
            
            print(f"\nğŸ¯ å‡¦ç†ä¸­: {video_name}")
            
            # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒãƒ³ã‚°
            if video_name in tracking_features:
                tracking_data = tracking_features[video_name]
                tracking_match_type = "å®Œå…¨ä¸€è‡´"
                tracking_matched_key = video_name
                print(f"  ğŸ“Š ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°: âœ… å®Œå…¨ä¸€è‡´ - {video_name}")
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
                actual_frame_count = self.get_actual_frame_count(tracking_data)
                print(f"      å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {actual_frame_count}")
                
                if actual_frame_count <= 10:
                    print(f"      âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒç•°å¸¸ã«å°‘ãªã„ã§ã™")
            else:
                # éƒ¨åˆ†ãƒãƒƒãƒã‚’è©¦è¡Œ
                for tracking_key in tracking_features.keys():
                    if video_name in tracking_key:
                        tracking_data = tracking_features[tracking_key]
                        tracking_match_type = "éƒ¨åˆ†ä¸€è‡´(å‹•ç”»åãŒã‚­ãƒ¼ã«å«ã¾ã‚Œã‚‹)"
                        tracking_matched_key = tracking_key
                        print(f"  ğŸ“Š ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°: âœ… éƒ¨åˆ†ä¸€è‡´ - {video_name} âŠ† {tracking_key}")
                        
                        actual_frame_count = self.get_actual_frame_count(tracking_data)
                        print(f"      å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {actual_frame_count}")
                        break
                    elif tracking_key in video_name:
                        tracking_data = tracking_features[tracking_key]
                        tracking_match_type = "éƒ¨åˆ†ä¸€è‡´(ã‚­ãƒ¼ãŒå‹•ç”»åã«å«ã¾ã‚Œã‚‹)"
                        tracking_matched_key = tracking_key
                        print(f"  ğŸ“Š ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°: âœ… éƒ¨åˆ†ä¸€è‡´ - {tracking_key} âŠ† {video_name}")
                        
                        actual_frame_count = self.get_actual_frame_count(tracking_data)
                        print(f"      å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {actual_frame_count}")
                        break
                
                if not tracking_data:
                    print(f"  ğŸ“Š ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°: âŒ ãƒãƒƒãƒãªã—")
            
            # ã‚³ãƒ¼ãƒˆåº§æ¨™ã®ãƒãƒƒãƒãƒ³ã‚°
            if court_coordinates:
                if video_name in court_coordinates:
                    court_data = court_coordinates[video_name]
                    court_match_type = "å®Œå…¨ä¸€è‡´"
                    court_matched_key = video_name
                    print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… å®Œå…¨ä¸€è‡´ - {video_name}")
                else:
                    # éƒ¨åˆ†ãƒãƒƒãƒã‚’è©¦è¡Œ
                    for court_key in court_coordinates.keys():
                        if video_name in court_key:
                            court_data = court_coordinates[court_key]
                            court_match_type = "éƒ¨åˆ†ä¸€è‡´(å‹•ç”»åãŒã‚­ãƒ¼ã«å«ã¾ã‚Œã‚‹)"
                            court_matched_key = court_key
                            print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… éƒ¨åˆ†ä¸€è‡´ - {video_name} âŠ† {court_key}")
                            break
                        elif court_key in video_name:
                            court_data = court_coordinates[court_key]
                            court_match_type = "éƒ¨åˆ†ä¸€è‡´(ã‚­ãƒ¼ãŒå‹•ç”»åã«å«ã¾ã‚Œã‚‹)"
                            court_matched_key = court_key
                            print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âœ… éƒ¨åˆ†ä¸€è‡´ - {court_key} âŠ† {video_name}")
                            break
                    if not court_data:
                        print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âŒ ãƒãƒƒãƒãªã—")
            else:
                print(f"  ğŸ¾ ã‚³ãƒ¼ãƒˆåº§æ¨™: âŒ ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            # çµæœã®åˆ¤å®š
            if tracking_data:
                matched_data.append((
                    video_name,
                    phase_annotations[video_name],
                    tracking_data,  # æ–°å½¢å¼: {'metadata': {...}, 'frames': [...]}
                    court_data
                ))
                
                frame_count = self.get_actual_frame_count(tracking_data)
                print(f"  âœ… ãƒãƒƒãƒãƒ³ã‚°æˆåŠŸ:")
                print(f"     å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {video_name}")
                print(f"     ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°: {tracking_matched_key} ({tracking_match_type})")
                print(f"     å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
                if isinstance(tracking_data, dict) and 'metadata' in tracking_data:
                    frame_skip = tracking_data['metadata'].get('frame_skip', 1)
                    print(f"     ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {frame_skip}")
                if court_data:
                    print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: {court_matched_key} ({court_match_type})")
                else:
                    print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: ãªã—")
            else:
                print(f"  âŒ ãƒãƒƒãƒãƒ³ã‚°å¤±æ•—: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        print(f"\n=== ãƒãƒƒãƒãƒ³ã‚°çµæœã‚µãƒãƒªãƒ¼ ===")
        print(f"âœ… æˆåŠŸã—ãŸãƒãƒƒãƒãƒ³ã‚°: {len(matched_data)}")
        print(f"âŒ å¤±æ•—ã—ãŸãƒãƒƒãƒãƒ³ã‚°: {len(phase_annotations) - len(matched_data)}")
        
        if matched_data:
            print("\nğŸ“‹ æˆåŠŸã—ãŸãƒãƒƒãƒãƒ³ã‚°ä¸€è¦§:")
            for i, (video_name, _, tracking_data, court_data) in enumerate(matched_data, 1):
                frame_count = self.get_actual_frame_count(tracking_data)
                court_status = "ã‚ã‚Š" if court_data else "ãªã—"
                print(f"  {i}. {video_name}")
                print(f"     ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
                print(f"     ã‚³ãƒ¼ãƒˆåº§æ¨™: {court_status}")
        
        print(f"æœ€çµ‚ãƒãƒƒãƒãƒ³ã‚°æ•°: {len(matched_data)}")
        return matched_data
    
    def get_actual_frame_count(self, tracking_data) -> int:
        """å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«é–¢ä¿‚ãªãï¼‰"""
        if isinstance(tracking_data, list):
            return len(tracking_data)
        elif isinstance(tracking_data, dict):
            if 'frames' in tracking_data:
                frames = tracking_data['frames']
                return len(frames) if hasattr(frames, '__len__') else 0
            elif 'frame_data' in tracking_data:
                frame_data = tracking_data['frame_data']
                return len(frame_data) if hasattr(frame_data, '__len__') else 0
            else:
                # æ•°å€¤ã‚­ãƒ¼ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                numeric_keys = [k for k in tracking_data.keys() if str(k).isdigit()]
                return len(numeric_keys)
        else:
            return 0

    def validate_tracking_data_consistency(self, tracking_data_dict: Dict) -> Dict:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã‚’æ¤œè¨¼ï¼ˆè¨˜éŒ²ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
        validation_result = {
            'is_valid': True,
            'warnings': [],
            'frame_count': 0,
            'frame_skip_detected': False,
            'recorded_frame_skip': 1,
            'actual_frame_skip_interval': 1,
            'missing_frames': [],
            'duplicate_frames': [],
            'interpolated_count': 0,
            'metadata_available': False,
            'processing_mode': 'unknown'
        }
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯
        if isinstance(tracking_data_dict, list):
            # æ—§å½¢å¼
            tracking_data = tracking_data_dict
            validation_result['warnings'].append("æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        elif isinstance(tracking_data_dict, dict) and 'frames' in tracking_data_dict:
            # æ–°å½¢å¼
            tracking_data = tracking_data_dict['frames']
            metadata = tracking_data_dict.get('metadata', {})
            validation_result['metadata_available'] = True
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ã‚’å–å¾—
            recorded_skip = metadata.get('frame_skip', 1)
            processing_mode = metadata.get('processing_mode', 'unknown')
            
            validation_result['recorded_frame_skip'] = recorded_skip
            validation_result['processing_mode'] = processing_mode
            
            if recorded_skip > 1:
                validation_result['frame_skip_detected'] = True
                validation_result['warnings'].append(
                    f"è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {recorded_skip} (ãƒ¢ãƒ¼ãƒ‰: {processing_mode})"
                )
            
            # ä»–ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚‚æ¤œè¨¼
            if 'original_fps' in metadata:
                validation_result['original_fps'] = metadata['original_fps']
            if 'processing_fps' in metadata:
                validation_result['processing_fps'] = metadata['processing_fps']
            if 'total_original_frames' in metadata:
                validation_result['total_original_frames'] = metadata['total_original_frames']
        else:
            validation_result['is_valid'] = False
            validation_result['warnings'].append("ä¸æ˜ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã™")
            return validation_result
        
        validation_result['frame_count'] = len(tracking_data)
        
        if not tracking_data:
            validation_result['is_valid'] = False
            validation_result['warnings'].append("ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return validation_result
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        frame_numbers = [data.get('frame_number', 0) for data in tracking_data]
        frame_numbers.sort()
        
        # é‡è¤‡ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒã‚§ãƒƒã‚¯
        from collections import Counter
        frame_counts = Counter(frame_numbers)
        duplicates = [frame for frame, count in frame_counts.items() if count > 1]
        if duplicates:
            validation_result['duplicate_frames'] = duplicates
            validation_result['warnings'].append(f"é‡è¤‡ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {duplicates}")
        
        # å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã®æ¤œå‡ºã¨è¨˜éŒ²å€¤ã¨ã®æ¯”è¼ƒ
        intervals = []
        missing_frames = []
        
        for i in range(1, len(frame_numbers)):
            interval = frame_numbers[i] - frame_numbers[i-1]
            if interval > 1:
                intervals.append(interval)
                # æ¬ æãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¨˜éŒ²
                for missing in range(frame_numbers[i-1] + 1, frame_numbers[i]):
                    missing_frames.append(missing)
            elif interval == 1:
                intervals.append(1)
        
        if intervals:
            # æœ€ã‚‚é »ç¹ãªé–“éš”ã‚’ã‚¹ã‚­ãƒƒãƒ—é–“éš”ã¨ã—ã¦åˆ¤å®š
            interval_counts = Counter(intervals)
            most_common_interval = interval_counts.most_common(1)[0][0]
            
            validation_result['actual_frame_skip_interval'] = most_common_interval
            
            # è¨˜éŒ²ã•ã‚ŒãŸå€¤ã¨å®Ÿéš›ã®å€¤ã‚’æ¯”è¼ƒ
            recorded_skip = validation_result['recorded_frame_skip']
            if recorded_skip > 1:
                if most_common_interval == recorded_skip:
                    validation_result['warnings'].append(
                        f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æ•´åˆæ€§ç¢ºèª: è¨˜éŒ²å€¤({recorded_skip}) = å®Ÿæ¸¬å€¤({most_common_interval})"
                    )
                else:
                    validation_result['warnings'].append(
                        f"âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ä¸æ•´åˆ: è¨˜éŒ²å€¤({recorded_skip}) â‰  å®Ÿæ¸¬å€¤({most_common_interval})"
                    )
            elif most_common_interval > 1:
                validation_result['warnings'].append(
                    f"âš ï¸  è¨˜éŒ²ãªã—ã‚¹ã‚­ãƒƒãƒ—æ¤œå‡º: å®Ÿæ¸¬é–“éš”({most_common_interval})"
                )
        
        validation_result['missing_frames'] = missing_frames
        
        # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚«ã‚¦ãƒ³ãƒˆ
        interpolated_count = sum(1 for data in tracking_data if data.get('interpolated', False))
        validation_result['interpolated_count'] = interpolated_count
        
        if interpolated_count > 0:
            validation_result['warnings'].append(f"è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {interpolated_count}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªã®è©•ä¾¡
        ball_detection_rate = sum(1 for data in tracking_data if data.get('ball_detected', 0)) / len(tracking_data)
        validation_result['ball_detection_rate'] = ball_detection_rate
        
        if ball_detection_rate < 0.3:
            validation_result['warnings'].append(f"ãƒœãƒ¼ãƒ«æ¤œå‡ºç‡ãŒä½ã„ã§ã™: {ball_detection_rate:.1%}")
        
        return validation_result
    
    # ãƒ‡ãƒ¼ã‚¿è¨ºæ–­ãƒ»ä»£æ›¿èª­ã¿è¾¼ã¿ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def diagnose_tracking_data_structure(self, tracking_data_dict: Dict, video_name: str):
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®è©³ç´°è¨ºæ–­"""
        print(f"\n=== {video_name} ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨ºæ–­ ===")
        
        if isinstance(tracking_data_dict, dict):
            print("ãƒ‡ãƒ¼ã‚¿æ§‹é€ : è¾æ›¸å‹")
            print(f"ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚­ãƒ¼: {list(tracking_data_dict.keys())}")
            
            if 'frames' in tracking_data_dict:
                frames_data = tracking_data_dict['frames']
                print(f"framesè¦ç´ å‹: {type(frames_data)}")
                print(f"framesè¦ç´ æ•°: {len(frames_data) if hasattr(frames_data, '__len__') else 'N/A'}")
                
                if isinstance(frames_data, list) and len(frames_data) > 0:
                    sample_frame = frames_data[0]
                    print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ å‹: {type(sample_frame)}")
                    if isinstance(sample_frame, dict):
                        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚­ãƒ¼æ•°: {len(sample_frame.keys())}")
                        print(f"ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚­ãƒ¼ä¾‹: {list(sample_frame.keys())[:10]}")
                
            if 'metadata' in tracking_data_dict:
                metadata = tracking_data_dict['metadata']
                print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata}")
        
        elif isinstance(tracking_data_dict, list):
            print("ãƒ‡ãƒ¼ã‚¿æ§‹é€ : ãƒªã‚¹ãƒˆå‹")
            print(f"è¦ç´ æ•°: {len(tracking_data_dict)}")
            if len(tracking_data_dict) > 0:
                sample = tracking_data_dict[0]
                print(f"ã‚µãƒ³ãƒ—ãƒ«è¦ç´ å‹: {type(sample)}")
        
        else:
            print(f"ãƒ‡ãƒ¼ã‚¿æ§‹é€ : ä¸æ˜ãªå‹ - {type(tracking_data_dict)}")
    
    def attempt_alternative_data_loading(self, video_name: str) -> List[Dict]:
        """ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è©¦è¡Œ"""
        print(f"=== {video_name} ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è©¦è¡Œ ===")
        
        # tracking_features_*.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥å†èª­ã¿è¾¼ã¿
        pattern = f"tracking_features_{video_name}_*.json"
        tracking_files = list(self.training_data_dir.glob(pattern))
        
        if not tracking_files:
            print(f"å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
            return []
        
        for file_path in tracking_files:
            try:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«å†èª­ã¿è¾¼ã¿è©¦è¡Œ: {file_path.name}")
                
                with open(file_path, 'r', encoding='utf-8') as f:
                    raw_data = json.load(f)
                
                print(f"ç”Ÿãƒ‡ãƒ¼ã‚¿å‹: {type(raw_data)}")
                
                # æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¯¾å¿œ
                if isinstance(raw_data, list):
                    print(f"ãƒªã‚¹ãƒˆå½¢å¼: {len(raw_data)}è¦ç´ ")
                    return raw_data
                    
                elif isinstance(raw_data, dict):
                    print(f"è¾æ›¸å½¢å¼ã‚­ãƒ¼: {list(raw_data.keys())}")
                    
                    # 'frames'ã‚­ãƒ¼ã‚’å„ªå…ˆ
                    if 'frames' in raw_data:
                        frames = raw_data['frames']
                        print(f"framesã‚­ãƒ¼: {type(frames)}, è¦ç´ æ•°: {len(frames) if hasattr(frames, '__len__') else 'N/A'}")
                        if isinstance(frames, list):
                            return frames
                    
                    # 'frame_data'ã‚­ãƒ¼ã‚’è©¦è¡Œ
                    if 'frame_data' in raw_data:
                        frame_data = raw_data['frame_data']
                        print(f"frame_dataã‚­ãƒ¼: {type(frame_data)}, è¦ç´ æ•°: {len(frame_data) if hasattr(frame_data, '__len__') else 'N/A'}")
                        if isinstance(frame_data, list):
                            return frame_data
                    
                    # æ•°å€¤ã‚­ãƒ¼ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ï¼‰ã‚’æ¢ç´¢
                    numeric_keys = [k for k in raw_data.keys() if str(k).isdigit()]
                    if numeric_keys:
                        print(f"æ•°å€¤ã‚­ãƒ¼æ¤œå‡º: {len(numeric_keys)}å€‹")
                        # æ•°å€¤ã‚­ãƒ¼ã‹ã‚‰è¾æ›¸ã‚’æ§‹ç¯‰
                        frame_list = []
                        for key in sorted(numeric_keys, key=int):
                            frame_data = raw_data[key]
                            if isinstance(frame_data, dict):
                                frame_data['frame_number'] = int(key)
                                frame_list.append(frame_data)
                        
                        if frame_list:
                            print(f"æ•°å€¤ã‚­ãƒ¼ã‹ã‚‰æ§‹ç¯‰: {len(frame_list)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                            return frame_list
                
                print("âš ï¸  èªè­˜å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
                
            except Exception as e:
                print(f"ä»£æ›¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return []
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ æ­£è¦åŒ–ãƒ»è£œé–“ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def normalize_frame_numbers(self, tracking_data_dict: Dict) -> List[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’æ­£è¦åŒ–ã—ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚’è€ƒæ…®ã—ãŸå±•é–‹ã‚’è¡Œã†"""
        print("=== ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–ãƒ»å±•é–‹å‡¦ç† ===")
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯
        if isinstance(tracking_data_dict, list):
            # æ—§å½¢å¼ã®å ´åˆã¯å¾“æ¥ã®å‡¦ç†
            print("âš ï¸  æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return self.legacy_normalize_frame_numbers(tracking_data_dict)
        
        # æ–°å½¢å¼ã®å‡¦ç†ï¼šãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚’è€ƒæ…®ã—ãŸå±•é–‹
        metadata = tracking_data_dict.get('metadata', {})
        frame_skip = metadata.get('frame_skip', 1)
        
        print(f"âœ… è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æƒ…å ±: {frame_skip}")
        
        if frame_skip == 1:
            # ã‚¹ã‚­ãƒƒãƒ—ãªã—ã®å ´åˆã¯é€šå¸¸ã®æ­£è¦åŒ–ã®ã¿
            frames_data = tracking_data_dict.get('frames', [])
            print("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ãªã— - é€šå¸¸ã®æ­£è¦åŒ–ã‚’å®Ÿè¡Œ")
            return frames_data
        else:
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚ã‚Šã®å ´åˆã¯å±•é–‹å‡¦ç†
            print(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—({frame_skip})ã‚’æ¤œå‡º - å…ƒã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¸ã®å±•é–‹ã‚’å®Ÿè¡Œ")
            expanded_frames = self.expand_frames_to_original_sequence(tracking_data_dict)
            return expanded_frames
    
    def legacy_normalize_frame_numbers(self, tracking_data: List[Dict]) -> List[Dict]:
        """æ—§å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·æ­£è¦åŒ–"""
        if not tracking_data:
            return []
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã§ã‚½ãƒ¼ãƒˆ
        sorted_data = sorted(tracking_data, key=lambda x: x.get('frame_number', 0))
        
        # é€£ç¶šã—ãŸç•ªå·ã«æ­£è¦åŒ–
        for i, frame_data in enumerate(tqdm(sorted_data, desc="æ—§å½¢å¼ãƒ•ãƒ¬ãƒ¼ãƒ æ­£è¦åŒ–", leave=False)):
            frame_data['original_frame_number'] = frame_data.get('frame_number', 0)
            frame_data['frame_number'] = i
            frame_data['interpolated'] = False
        
        return sorted_data
    
    def expand_frames_to_original_sequence(self, tracking_data_dict: Dict) -> List[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã®å‹•ç”»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å±•é–‹"""
        print("=== ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å±•é–‹å‡¦ç† ===")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        metadata = tracking_data_dict['metadata']
        frames_data = tracking_data_dict['frames']
        frame_skip = metadata.get('frame_skip', 1)
        total_original_frames = metadata.get('total_original_frames')
        
        print(f"è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {frame_skip}")
        print(f"å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(frames_data)}")
        if total_original_frames:
            print(f"å…ƒå‹•ç”»ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_original_frames}")
        
        # å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã§ã‚½ãƒ¼ãƒˆ
        sorted_frames = sorted(frames_data, key=lambda x: x.get('frame_number', 0))
        
        if not sorted_frames:
            print("å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return []
        
        # æœ€åˆã¨æœ€å¾Œã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’å–å¾—
        first_processed_frame = sorted_frames[0].get('frame_number', 0)
        last_processed_frame = sorted_frames[-1].get('frame_number', 0)
        
        print(f"æœ€åˆã®å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ : {first_processed_frame}")
        print(f"æœ€å¾Œã®å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ : {last_processed_frame}")
        
        # å…ƒå‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’æ¨å®šï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆï¼‰
        if total_original_frames is None:
            estimated_total = last_processed_frame + frame_skip
            total_original_frames = estimated_total
            print(f"æ¨å®šç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {estimated_total}")
        
        # å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        processed_frame_map = {}
        for frame_data in sorted_frames:
            original_frame_num = frame_data.get('frame_number', 0)
            processed_frame_map[original_frame_num] = frame_data
        
        # å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å†æ§‹ç¯‰
        expanded_frames = []
        interpolated_count = 0
        
        for original_frame_num in tqdm(range(total_original_frames), desc="ãƒ•ãƒ¬ãƒ¼ãƒ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å±•é–‹", leave=False):
            if original_frame_num in processed_frame_map:
                # å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã®ã¾ã¾ä½¿ç”¨
                frame_data = processed_frame_map[original_frame_num].copy()
                frame_data['original_frame_number'] = original_frame_num
                frame_data['interpolated'] = False
                expanded_frames.append(frame_data)
            else:
                # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                interpolated_frame = self.create_interpolated_frame_from_skip(
                    original_frame_num, processed_frame_map, frame_skip
                )
                expanded_frames.append(interpolated_frame)
                interpolated_count += 1
        
        print(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ å±•é–‹å®Œäº†:")
        print(f"   å±•é–‹å¾Œç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(expanded_frames)}")
        print(f"   å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(sorted_frames)}")
        print(f"   è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {interpolated_count}")
        print(f"   è£œé–“ç‡: {interpolated_count/len(expanded_frames)*100:.1f}%")
        
        return expanded_frames
    
    def create_interpolated_frame_from_skip(self, target_frame_num: int, 
                                          processed_frame_map: Dict, frame_skip: int) -> Dict:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã«ã‚ˆã‚‹æ¬ æã‚’è£œé–“ã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        # å‰å¾Œã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã™
        prev_frame_data = None
        next_frame_data = None
        
        # å‰ã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã™
        for i in range(target_frame_num - 1, -1, -1):
            if i in processed_frame_map:
                prev_frame_data = processed_frame_map[i]
                break
        
        # æ¬¡ã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã™
        max_search_range = target_frame_num + frame_skip * 2
        for i in range(target_frame_num + 1, max_search_range):
            if i in processed_frame_map:
                next_frame_data = processed_frame_map[i]
                break
        
        # è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        interpolated_frame = {
            'frame_number': target_frame_num,
            'original_frame_number': target_frame_num,
            'interpolated': True,
            'timestamp': '',
            'ball_detected': 0,
            'ball_x': None,
            'ball_y': None,
            'ball_x_normalized': 0,
            'ball_y_normalized': 0,
            'ball_movement_score': 0,
            'ball_tracking_confidence': 0,
            'ball_velocity_x': 0,
            'ball_velocity_y': 0,
            'ball_speed': 0,
            'player_front_count': 0,
            'player_back_count': 0,
            'total_players': 0,
            'candidate_balls_count': 0,
            'disappeared_count': 0,
            'trajectory_length': 0,
            'prediction_active': 0
        }
        
        # å‰å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã¯è£œé–“
        if prev_frame_data and next_frame_data:
            prev_frame_num = prev_frame_data.get('frame_number', 0)
            next_frame_num = next_frame_data.get('frame_number', 0)
            
            if next_frame_num > prev_frame_num:
                # ç·šå½¢è£œé–“ã®æ¯”ç‡ã‚’è¨ˆç®—
                ratio = (target_frame_num - prev_frame_num) / (next_frame_num - prev_frame_num)
                ratio = max(0, min(1, ratio))
                
                # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ç·šå½¢è£œé–“
                numeric_keys = [
                    'ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized',
                    'ball_velocity_x', 'ball_velocity_y', 'ball_speed',
                    'ball_movement_score', 'ball_tracking_confidence',
                    'player_front_x', 'player_front_y', 'player_front_x_normalized', 'player_front_y_normalized',
                    'player_back_x', 'player_back_y', 'player_back_x_normalized', 'player_back_y_normalized',
                    'player_front_confidence', 'player_back_confidence',
                    'player_distance', 'player_distance_normalized'
                ]
                
                for key in numeric_keys:
                    prev_val = prev_frame_data.get(key)
                    next_val = next_frame_data.get(key)
                    
                    if prev_val is not None and next_val is not None:
                        interpolated_val = prev_val + (next_val - prev_val) * ratio
                        interpolated_frame[key] = interpolated_val
                    elif prev_val is not None:
                        interpolated_frame[key] = prev_val
                    elif next_val is not None:
                        interpolated_frame[key] = next_val
        
        elif prev_frame_data:
            # å‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚ã‚‹å ´åˆã€å€¤ã‚’ç¶™æ‰¿
            for key in ['ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized',
                       'player_front_x', 'player_front_y', 'player_back_x', 'player_back_y']:
                if key in prev_frame_data:
                    interpolated_frame[key] = prev_frame_data[key]
        
        elif next_frame_data:
            # æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚ã‚‹å ´åˆã€å€¤ã‚’ç¶™æ‰¿
            for key in ['ball_x', 'ball_y', 'ball_x_normalized', 'ball_y_normalized',
                       'player_front_x', 'player_front_y', 'player_back_x', 'player_back_y']:
                if key in next_frame_data:
                    interpolated_frame[key] = next_frame_data[key]
        
        return interpolated_frame
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def safe_create_dataframe_from_tracking_data(self, tracking_data: List[Dict], video_name: str) -> pd.DataFrame:
        """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®‰å…¨ã«DataFrameã‚’ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼å¯¾ç­–å¼·åŒ–ï¼‰"""
        if not tracking_data:
            print("âš ï¸  ç©ºã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿")
            return pd.DataFrame()
        
        try:
            # æ–¹æ³•1: æ¨™æº–çš„ãªDataFrameä½œæˆã‚’è©¦è¡Œ
            if all(isinstance(frame, dict) for frame in tracking_data):
                return pd.DataFrame(tracking_data)
            else:
                print("âš ï¸  éè¾æ›¸å½¢å¼ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                # è¾æ›¸å½¢å¼ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
                valid_frames = [frame for frame in tracking_data if isinstance(frame, dict)]
                if valid_frames:
                    return pd.DataFrame(valid_frames)
                else:
                    print("âŒ æœ‰åŠ¹ãªè¾æ›¸å½¢å¼ãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return pd.DataFrame()
                
        except ValueError as e:
            if "Mixing dicts with non-Series" in str(e):
                print(f"âš ï¸  DataFrameä½œæˆã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º: {e}")
                return self.handle_mixed_data_types_error(tracking_data, video_name)
            else:
                print(f"âŒ äºˆæœŸã—ãªã„DataFrameä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
                return pd.DataFrame()
        except Exception as e:
            print(f"âŒ DataFrameä½œæˆã§ä¾‹å¤–ç™ºç”Ÿ: {e}")
            return self.handle_mixed_data_types_error(tracking_data, video_name)
    
    def handle_mixed_data_types_error(self, tracking_data: List[Dict], video_name: str) -> pd.DataFrame:
        """æ··åˆãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        print("=== æ··åˆãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼å¯¾å‡¦ä¸­ ===")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è©³ç´°åˆ†æ
            print(f"ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(tracking_data)}")
            if tracking_data:
                sample_frame = tracking_data[0]
                print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ å‹: {type(sample_frame)}")
                if isinstance(sample_frame, dict):
                    print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ¼æ•°: {len(sample_frame.keys())}")
                    print(f"ã‚­ãƒ¼ä¾‹: {list(sample_frame.keys())[:10]}")
            
            # æ”¹å–„ã•ã‚ŒãŸæ­£è¦åŒ–å‡¦ç†
            normalized_frames = []
            for i, frame in enumerate(tracking_data):
                if isinstance(frame, dict):
                    normalized_frame = {'frame_number': i}  # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’è¨­å®š
                    
                    for key, value in frame.items():
                        try:
                            # å€¤ã®å‹ã«å¿œã˜ã¦é©åˆ‡ã«å‡¦ç†
                            if value is None:
                                normalized_frame[key] = 0
                            elif isinstance(value, (int, float)):
                                normalized_frame[key] = float(value)
                            elif isinstance(value, bool):
                                normalized_frame[key] = int(value)
                            elif isinstance(value, str):
                                # æ•°å€¤ã«å¤‰æ›å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                                try:
                                    normalized_frame[key] = float(value)
                                except ValueError:
                                    normalized_frame[key] = 0
                            elif isinstance(value, (list, tuple)):
                                # ãƒªã‚¹ãƒˆã®å ´åˆã¯é•·ã•ã¾ãŸã¯æœ€åˆã®å€¤ã‚’ä½¿ç”¨
                                if len(value) > 0:
                                    first_val = value[0]
                                    if isinstance(first_val, (int, float)):
                                        normalized_frame[key] = float(first_val)
                                    else:
                                        normalized_frame[key] = len(value)
                                else:
                                    normalized_frame[key] = 0
                            elif isinstance(value, dict):
                                # è¾æ›¸ã®å ´åˆã¯å±•é–‹ã¾ãŸã¯è¦ç´„
                                if 'x' in value and 'y' in value:
                                    normalized_frame[f'{key}_x'] = float(value.get('x', 0))
                                    normalized_frame[f'{key}_y'] = float(value.get('y', 0))
                                elif len(value) == 1:
                                    # å˜ä¸€ã‚­ãƒ¼ã®å ´åˆã¯ãã®å€¤ã‚’ä½¿ç”¨
                                    single_key = list(value.keys())[0]
                                    single_val = value[single_key]
                                    if isinstance(single_val, (int, float)):
                                        normalized_frame[key] = float(single_val)
                                    else:
                                        normalized_frame[key] = 1
                                else:
                                    normalized_frame[key] = len(value)
                            else:
                                # ãã®ä»–ã®å‹ã¯0ã«è¨­å®š
                                normalized_frame[key] = 0
                        except Exception as e:
                            print(f"ã‚­ãƒ¼ '{key}' ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                            normalized_frame[key] = 0
                    
                    normalized_frames.append(normalized_frame)
                else:
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {i} ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(frame)}")
            
            if normalized_frames:
                print(f"âœ… ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–å®Œäº†: {len(normalized_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                
                # DataFrameã®å®‰å…¨ãªä½œæˆ
                try:
                    # å…¨ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§å…±é€šã®ã‚­ãƒ¼ã‚»ãƒƒãƒˆã‚’ä½œæˆ
                    all_keys = set()
                    for frame in normalized_frames:
                        all_keys.update(frame.keys())
                    
                    # æ¬ æã‚­ãƒ¼ã‚’è£œå®Œ
                    for frame in normalized_frames:
                        for key in all_keys:
                            if key not in frame:
                                frame[key] = 0
                    
                    df = pd.DataFrame(normalized_frames)
                    print(f"DataFrameä½œæˆæˆåŠŸ: {df.shape}")
                    return df
                    
                except Exception as df_error:
                    print(f"DataFrameä½œæˆã§ã‚¨ãƒ©ãƒ¼: {df_error}")
                    # æœ€å°é™ã®DataFrameã‚’ä½œæˆ
                    basic_df = pd.DataFrame({
                        'frame_number': range(len(normalized_frames)),
                        'ball_detected': [frame.get('ball_detected', 0) for frame in normalized_frames],
                        'ball_x': [frame.get('ball_x', 0) for frame in normalized_frames],
                        'ball_y': [frame.get('ball_y', 0) for frame in normalized_frames]
                    })
                    print(f"åŸºæœ¬DataFrameä½œæˆ: {basic_df.shape}")
                    return basic_df
            else:
                print("âŒ æ­£è¦åŒ–å¯èƒ½ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
                return pd.DataFrame()
                
        except Exception as e2:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã§ã‚‚ã‚¨ãƒ©ãƒ¼: {e2}")
            # ç©ºã®DataFrameã‚’è¿”ã™
            return pd.DataFrame()
    
    # ãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰
    def interpolate_phase_labels(self, phase_changes: List[Dict], total_frames: int, fps: float) -> np.ndarray:
        """å±€é¢å¤‰æ›´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®å±€é¢ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ"""
        frame_labels = np.full(total_frames, -1, dtype=int)  # -1: ãƒ©ãƒ™ãƒ«æœªè¨­å®š
        
        if not phase_changes:
            return frame_labels
        
        # å±€é¢å¤‰æ›´ã‚’æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_changes = sorted(phase_changes, key=lambda x: x['frame_number'])
        
        for i, change in enumerate(tqdm(sorted_changes, desc="å±€é¢ãƒ©ãƒ™ãƒ«è£œé–“", leave=False)):
            start_frame = int(change['frame_number'])
            phase_label = change['phase']
            
            # ãƒ©ãƒ™ãƒ«IDã«å¤‰æ›
            if phase_label in self.label_to_id:
                label_id = self.label_to_id[phase_label]
            else:
                print(f"âš ï¸  æœªçŸ¥ã®å±€é¢ãƒ©ãƒ™ãƒ«: {phase_label}")
                continue
            
            # æ¬¡ã®å¤‰æ›´ã¾ã§ã€ã¾ãŸã¯å‹•ç”»çµ‚äº†ã¾ã§åŒã˜ãƒ©ãƒ™ãƒ«ã‚’é©ç”¨
            if i + 1 < len(sorted_changes):
                end_frame = int(sorted_changes[i + 1]['frame_number'])
            else:
                end_frame = total_frames
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ãƒã‚§ãƒƒã‚¯
            start_frame = max(0, min(start_frame, total_frames - 1))
            end_frame = max(start_frame + 1, min(end_frame, total_frames))
            
            frame_labels[start_frame:end_frame] = label_id
        
        return frame_labels
    
    # ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰
    def extract_features_from_video(self, video_name: str, phase_data: Dict, tracking_data_dict: Dict, court_coords: Dict = None) -> pd.DataFrame:
            """å˜ä¸€å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆå‡¦ç†é †åºã‚’predictãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨çµ±ä¸€ï¼‰"""
            print(f"\n--- ç‰¹å¾´é‡æŠ½å‡º: {video_name} ---")

            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã¨æ­£è¦åŒ–
            print("  ã‚¹ãƒ†ãƒƒãƒ—1/3: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã¨ãƒ•ãƒ¬ãƒ¼ãƒ æ­£è¦åŒ–...")
            validation_result = self.validate_tracking_data_consistency(tracking_data_dict)
            if validation_result['frame_count'] <= 10:
                print(f"âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒç•°å¸¸ã«å°‘ãªã„ãŸã‚ã€ä»£æ›¿èª­ã¿è¾¼ã¿ã‚’è©¦è¡Œã—ã¾ã™...")
                alternative_data = self.attempt_alternative_data_loading(video_name)
                if alternative_data:
                    print(f"âœ… ä»£æ›¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(alternative_data)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                    tracking_data_dict = {'metadata': tracking_data_dict.get('metadata', {}), 'frames': alternative_data}

            normalized_tracking_data = self.normalize_frame_numbers(tracking_data_dict)
            if not normalized_tracking_data:
                print("âŒ æ­£è¦åŒ–å¾Œã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                return pd.DataFrame()
            
            features_df = self.safe_create_dataframe_from_tracking_data(normalized_tracking_data, video_name)
            if features_df.empty:
                print("âŒ DataFrameä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return pd.DataFrame()

            # ã‚¹ãƒ†ãƒƒãƒ—2: ç‰¹å¾´é‡è¨ˆç®—ï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾è±¡ï¼‰
            # ã“ã®æ™‚ç‚¹ã§ã¯ã€ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã‚ãšã€å‹•ç”»å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã§ç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
            print("  ã‚¹ãƒ†ãƒƒãƒ—2/3: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾è±¡)...")
            
            # å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’'original_frame_number'ã¨ã—ã¦ç¢ºå®Ÿã«ä¿æŒ
            if 'frame_number' in features_df.columns:
                features_df['original_frame_number'] = features_df['frame_number']
            # 'frame_number'åˆ—ã¯å¾Œã§ä½¿ã†ãŒã€ä¸€æ—¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦ãƒªã‚»ãƒƒãƒˆ
            features_df['frame_number'] = range(len(features_df))
            
            # 'interpolated'åˆ—ã®å­˜åœ¨ã‚’ä¿è¨¼
            if 'interpolated' not in features_df.columns:
                features_df['interpolated'] = False
            
            # ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°ã‚’é †ç•ªã«é©ç”¨
            features_df = self.handle_missing_values(features_df)
            features_df = self.create_court_features(features_df, court_coords)
            features_df = self.create_temporal_features(features_df)
            features_df = self.create_contextual_features(features_df)
            print("  ã‚¹ãƒ†ãƒƒãƒ—2/3: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†")

            # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ©ãƒ™ãƒ«ä»˜ä¸ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            # å…¨ã¦ã®ç‰¹å¾´é‡è¨ˆç®—ãŒçµ‚ã‚ã£ãŸå¾Œã§ã€æ­£è§£ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ã—ã€ä¸è¦ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
            print("  ã‚¹ãƒ†ãƒƒãƒ—3/3: å±€é¢ãƒ©ãƒ™ãƒ«ã®ä»˜ä¸ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°...")
            
            total_frames = len(features_df)
            fps = phase_data.get('fps', 30.0)
            phase_changes = phase_data.get('phase_changes', [])
            frame_labels = self.interpolate_phase_labels(phase_changes, total_frames, fps)
            
            # ãƒ©ãƒ™ãƒ«åˆ—ã‚’è¿½åŠ 
            if len(frame_labels) == len(features_df):
                features_df['label'] = frame_labels
            else:
                print(f"âš ï¸  ãƒ©ãƒ™ãƒ«æ•°({len(frame_labels)})ã¨ãƒ•ãƒ¬ãƒ¼ãƒ æ•°({len(features_df)})ãŒä¸ä¸€è‡´ã€‚å°ã•ã„æ–¹ã«åˆã‚ã›ã¾ã™ã€‚")
                min_len = min(len(frame_labels), len(features_df))
                features_df = features_df.iloc[:min_len]
                features_df['label'] = frame_labels[:min_len]

            features_df['video_name'] = video_name
            
            # ãƒ©ãƒ™ãƒ«ãŒ-1ï¼ˆæœªå®šç¾©ï¼‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å¤–ã—ã¦ã€æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
            features_df = features_df[features_df['label'] != -1].copy()
            
            print(f"æœ€çµ‚çš„ãªãƒ©ãƒ™ãƒ«ä»˜ããƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(features_df)}")
            if len(features_df) == 0:
                print("âš ï¸  æœ‰åŠ¹ãªãƒ©ãƒ™ãƒ«ã‚’æŒã¤ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
                return pd.DataFrame()
                
            # æœ€çµ‚çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
            print("æœ€çµ‚çš„ãªãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:")
            label_counts = features_df['label'].value_counts().sort_index()
            for label_id, count in label_counts.items():
                phase_name = self.phase_labels[label_id] if label_id < len(self.phase_labels) else f"Unknown_{label_id}"
                print(f"  {label_id} ({phase_name}): {count}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
            print(f"æœ€çµ‚ç‰¹å¾´é‡æ•°: {len(features_df.columns)}")
            return features_df
    
    # ç‰¹å¾´é‡ä½œæˆãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def create_temporal_features(self, features_df: pd.DataFrame, window_sizes: List[int] = [3, 5, 10, 15]) -> pd.DataFrame:
        """æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆNumbaé«˜é€ŸåŒ–å¯¾å¿œï¼‰"""
        temporal_df = features_df.copy()
        
        numeric_columns = features_df.select_dtypes(include=[np.number]).columns
        target_columns = [col for col in numeric_columns if col not in ['frame_number', 'original_frame_number']]
        
        print(f"æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆå¯¾è±¡: {len(target_columns)}ç‰¹å¾´é‡ (Numbaé«˜é€ŸåŒ–å¯¾å¿œ)")
        
        is_interpolated = features_df.get('interpolated', pd.Series([False] * len(features_df))).values
        
        print("  ãƒ‡ãƒ¼ã‚¿ã‚’NumPyé…åˆ—ã«å¤‰æ›ä¸­...")
        data_matrix = features_df[target_columns].values.astype(np.float64)
        data_matrix = np.nan_to_num(data_matrix, nan=0.0)
        
        new_features = {}
        
        for window in tqdm(window_sizes, desc="æ™‚ç³»åˆ—ç‰¹å¾´é‡(ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ¥)", leave=False):
            print(f"  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º {window} ã®ç‰¹å¾´é‡ä½œæˆä¸­... (Numba é«˜é€ŸåŒ–)")
            
            ma_results, std_results, max_results, min_results = vectorized_rolling_stats(
                data_matrix, window, is_interpolated
            )
            
            for i, col in enumerate(target_columns):
                new_features[f'{col}_ma_{window}'] = ma_results[:, i]
                new_features[f'{col}_std_{window}'] = std_results[:, i]
                new_features[f'{col}_max_{window}'] = max_results[:, i]
                new_features[f'{col}_min_{window}'] = min_results[:, i]
                
                if window <= 5:
                    diff1, diff2 = self.vectorized_diff_features(
                        data_matrix[:, i], is_interpolated
                    )
                    new_features[f'{col}_diff'] = diff1
                    new_features[f'{col}_diff_abs'] = np.abs(diff1)
                    new_features[f'{col}_diff2'] = diff2
                    new_features[f'{col}_diff2_abs'] = np.abs(diff2)
                
                if window == 5:
                    trend_values = self.vectorized_rolling_trend(data_matrix[:, i], window)
                    new_features[f'{col}_trend_{window}'] = trend_values
                    
                    ma_vals = ma_results[:, i]
                    std_vals = std_results[:, i]
                    cv_values = np.divide(std_vals, np.abs(ma_vals), 
                                        out=np.zeros_like(std_vals), where=ma_vals!=0)
                    new_features[f'{col}_cv_{window}'] = cv_values
        
        new_features['data_quality'] = (~is_interpolated).astype(float)
        
        interpolation_kernel = np.ones(10) / 10
        interpolation_ratio = np.convolve(is_interpolated.astype(float), interpolation_kernel, mode='same')
        new_features['interpolation_ratio'] = interpolation_ratio
        
        print("  æ–°ã—ã„ç‰¹å¾´é‡ã‚’DataFrameã«çµ±åˆä¸­...")
        for feature_name, feature_values in new_features.items():
            temporal_df[feature_name] = feature_values
        
        print(f"æ™‚ç³»åˆ—ç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(new_features)}ç‰¹å¾´é‡è¿½åŠ ")
        return temporal_df
    
    def vectorized_diff_features(self, data_array: np.ndarray,
                            is_interpolated: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸå·®åˆ†ç‰¹å¾´é‡è¨ˆç®—"""
        diff1 = np.diff(data_array, prepend=data_array[0])

        if np.any(is_interpolated):
            diff_weights = (~is_interpolated).astype(float) * 1.0 + is_interpolated.astype(float) * 0.5
            diff1 = diff1 * diff_weights

        diff2 = np.diff(diff1, prepend=diff1[0])

        return diff1, diff2

    def vectorized_rolling_trend(self, data_array: np.ndarray, window: int) -> np.ndarray:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸç§»å‹•ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        n = len(data_array)
        trend_values = np.zeros(n)
        half_window = window // 2

        padded_data = np.pad(data_array, half_window, mode='edge')

        x = np.arange(window) - half_window
        x_mean = np.mean(x)
        x_centered = x - x_mean
        x_var = np.sum(x_centered ** 2)

        if x_var == 0:
            return trend_values

        for i in range(n):
            y = padded_data[i:i+window]
            y_mean = np.mean(y)
            y_centered = y - y_mean

            covariance = np.sum(x_centered * y_centered)
            trend_values[i] = covariance / x_var

        return trend_values
    
    def create_contextual_features(self, features_df: pd.DataFrame) -> pd.DataFrame:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆçœŸã®NumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        context_df = features_df.copy()
        
        print("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆä¸­... (çœŸã®NumPyé«˜é€ŸåŒ–)")
        
        available_fields = set(context_df.columns)
        data_length = len(context_df)
        
        numeric_data = {}
        for field in available_fields:
            if context_df[field].dtype in [np.number, 'float64', 'float32', 'int64', 'int32']:
                numeric_data[field] = context_df[field].fillna(0).values
        
        ball_activity = self.calculate_ball_activity_vectorized(numeric_data, available_fields, data_length)
        context_df['ball_activity'] = ball_activity
        
        players_interaction, players_confidence_avg = self.calculate_player_features_vectorized(
            numeric_data, available_fields, data_length
        )
        context_df['players_interaction'] = players_interaction
        context_df['players_confidence_avg'] = players_confidence_avg
        
        distance_features = self.calculate_distances_vectorized(numeric_data, available_fields, data_length)
        for feature_name, feature_values in distance_features.items():
            context_df[feature_name] = feature_values
        
        position_features = self.calculate_position_features_vectorized(numeric_data, available_fields, data_length)
        for feature_name, feature_values in position_features.items():
            context_df[feature_name] = feature_values
        
        tracking_quality = self.calculate_tracking_quality_vectorized(numeric_data, available_fields, data_length)
        context_df['tracking_quality'] = tracking_quality
        
        temporal_context_features = self.calculate_temporal_context_vectorized(
            numeric_data, available_fields, data_length
        )
        for feature_name, feature_values in temporal_context_features.items():
            context_df[feature_name] = feature_values
        
        added_features = len(context_df.columns) - len(features_df.columns)
        print(f"  ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†: {added_features}ç‰¹å¾´é‡è¿½åŠ ")
        return context_df
    
    def calculate_ball_activity_vectorized(self, numeric_data: Dict[str, np.ndarray],
                                        available_fields: set, data_length: int) -> np.ndarray:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒœãƒ¼ãƒ«æ´»å‹•åº¦è¨ˆç®—"""
        components = []
        if 'ball_detected' in available_fields: components.append(numeric_data['ball_detected'])
        if 'ball_movement_score' in available_fields: components.append(numeric_data['ball_movement_score'])
        elif 'ball_speed' in available_fields: components.append(numeric_data['ball_speed'] / 100.0)
        if 'ball_tracking_confidence' in available_fields: components.append(numeric_data['ball_tracking_confidence'])

        if components:
            ball_activity = np.ones(data_length)
            for component in components:
                ball_activity *= component
            return ball_activity
        else:
            return np.zeros(data_length)

    def calculate_player_features_vectorized(self, numeric_data: Dict[str, np.ndarray],
                                        available_fields: set, data_length: int) -> Tuple[np.ndarray, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ç‰¹å¾´é‡è¨ˆç®—"""
        player_counts = []
        if 'player_front_count' in available_fields: player_counts.append(numeric_data['player_front_count'])
        if 'player_back_count' in available_fields: player_counts.append(numeric_data['player_back_count'])

        players_interaction = np.mean(player_counts, axis=0) if player_counts else np.zeros(data_length)

        confidence_components = []
        if 'player_front_confidence' in available_fields: confidence_components.append(numeric_data['player_front_confidence'])
        if 'player_back_confidence' in available_fields: confidence_components.append(numeric_data['player_back_confidence'])

        players_confidence_avg = np.mean(confidence_components, axis=0) if confidence_components else np.zeros(data_length)

        return players_interaction, players_confidence_avg

    def calculate_distances_vectorized(self, numeric_data: Dict[str, np.ndarray],
                                    available_fields: set, data_length: int) -> Dict[str, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸè·é›¢è¨ˆç®—"""
        distance_features = {}

        ball_pos_available = all(col in available_fields for col in ['ball_x', 'ball_y'])
        front_pos_available = all(col in available_fields for col in ['player_front_x', 'player_front_y'])
        back_pos_available = all(col in available_fields for col in ['player_back_x', 'player_back_y'])

        if ball_pos_available and front_pos_available:
            dist = np.sqrt((numeric_data['ball_x'] - numeric_data['player_front_x'])**2 + (numeric_data['ball_y'] - numeric_data['player_front_y'])**2)
            distance_features['ball_to_front_distance'] = np.where(np.isnan(dist) | np.isinf(dist), 1000, dist)
        else:
            distance_features['ball_to_front_distance'] = np.full(data_length, 1000.0)

        if ball_pos_available and back_pos_available:
            dist = np.sqrt((numeric_data['ball_x'] - numeric_data['player_back_x'])**2 + (numeric_data['ball_y'] - numeric_data['player_back_y'])**2)
            distance_features['ball_to_back_distance'] = np.where(np.isnan(dist) | np.isinf(dist), 1000, dist)
        else:
            distance_features['ball_to_back_distance'] = np.full(data_length, 1000.0)

        if 'ball_to_front_distance' in distance_features and 'ball_to_back_distance' in distance_features:
            front_dist = distance_features['ball_to_front_distance']
            back_dist = distance_features['ball_to_back_distance']
            distance_features['ball_closer_to_front'] = (front_dist < back_dist).astype(int)
        else:
            distance_features['ball_closer_to_front'] = np.zeros(data_length, dtype=int)

        return distance_features

    def calculate_position_features_vectorized(self, numeric_data: Dict[str, np.ndarray],
                                            available_fields: set, data_length: int) -> Dict[str, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸä½ç½®ç‰¹å¾´é‡è¨ˆç®—"""
        position_features = {}

        if all(col in available_fields for col in ['ball_x_normalized', 'ball_y_normalized']):
            ball_x_norm = np.nan_to_num(numeric_data['ball_x_normalized'], nan=0.5)
            ball_y_norm = np.nan_to_num(numeric_data['ball_y_normalized'], nan=0.5)

            position_features['ball_in_upper_half'] = (ball_x_norm < 0.5).astype(int)
            position_features['ball_in_left_half'] = (ball_y_norm < 0.5).astype(int)

            in_center = ((ball_x_norm > 0.3) & (ball_x_norm < 0.7) & (ball_y_norm > 0.3) & (ball_y_norm < 0.7))
            position_features['ball_in_center'] = in_center.astype(int)
        else:
            position_features.update({
                'ball_in_upper_half': np.zeros(data_length, dtype=int),
                'ball_in_left_half': np.zeros(data_length, dtype=int),
                'ball_in_center': np.zeros(data_length, dtype=int)
            })

        return position_features

    def calculate_tracking_quality_vectorized(self, numeric_data: Dict[str, np.ndarray],
                                            available_fields: set, data_length: int) -> np.ndarray:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°å“è³ªè¨ˆç®—"""
        quality_components, weights = [], []
        if 'ball_detected' in available_fields: quality_components.append(numeric_data['ball_detected']); weights.append(0.4)
        if 'ball_tracking_confidence' in available_fields: quality_components.append((numeric_data['ball_tracking_confidence'] > 0.5).astype(int)); weights.append(0.3)
        if 'candidate_balls_count' in available_fields: quality_components.append((numeric_data['candidate_balls_count'] > 0).astype(int)); weights.append(0.2)
        if 'disappeared_count' in available_fields: quality_components.append((numeric_data['disappeared_count'] == 0).astype(int)); weights.append(0.1)

        if quality_components:
            quality_array = np.array(quality_components)
            weights_array = np.array(weights).reshape(-1, 1)
            weighted_sum = np.sum(quality_array * weights_array, axis=0)
            total_weight = np.sum(weights_array)
            return weighted_sum / total_weight if total_weight > 0 else np.zeros(data_length)
        else:
            return np.zeros(data_length)

    def calculate_temporal_context_vectorized(self, numeric_data: Dict[str, np.ndarray],
                                            available_fields: set, data_length: int) -> Dict[str, np.ndarray]:
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸæ™‚ç³»åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡è¨ˆç®—"""
        print("    æ™‚ç³»åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆä¸­... (çœŸã®NumPyé«˜é€ŸåŒ–)")
        temporal_features = {}

        if 'ball_detected' in available_fields:
            ball_detected = numeric_data['ball_detected']
            for window in [3, 5, 10]:
                kernel = np.ones(window) / window
                temporal_features[f'ball_detection_stability_{window}'] = np.convolve(ball_detected, kernel, mode='same')

        if all(col in available_fields for col in ['ball_x', 'ball_y']):
            x_diff = np.diff(numeric_data['ball_x'], prepend=numeric_data['ball_x'][0])
            y_diff = np.diff(numeric_data['ball_y'], prepend=numeric_data['ball_y'][0])
            movement_distance = np.sqrt(x_diff**2 + y_diff**2)
            temporal_features['ball_movement_distance'] = movement_distance
            for window in [3, 5]:
                temporal_features[f'ball_movement_stability_{window}'] = self.fast_rolling_std_vectorized(movement_distance, window)

        for player in ['front', 'back']:
            if all(f'player_{player}_{coord}' in available_fields for coord in ['x', 'y']):
                x_diff = np.diff(numeric_data[f'player_{player}_x'], prepend=numeric_data[f'player_{player}_x'][0])
                y_diff = np.diff(numeric_data[f'player_{player}_y'], prepend=numeric_data[f'player_{player}_y'][0])
                movement_dist = np.sqrt(x_diff**2 + y_diff**2)
                temporal_features[f'player_{player}_movement_distance'] = movement_dist
                for window in [5, 10]:
                    kernel = np.ones(window) / window
                    temporal_features[f'player_{player}_activity_{window}'] = np.convolve(movement_dist, kernel, mode='same')

        movement_cols = [k for k in temporal_features if 'movement_distance' in k]
        if movement_cols:
            movement_matrix = np.array([temporal_features[col] for col in movement_cols])
            scene_dynamics = np.mean(movement_matrix, axis=0)
            temporal_features['scene_dynamics'] = scene_dynamics
            for window in [5, 10]:
                kernel = np.ones(window) / window
                temporal_features[f'scene_dynamics_ma_{window}'] = np.convolve(scene_dynamics, kernel, mode='same')
                temporal_features[f'scene_dynamics_std_{window}'] = self.fast_rolling_std_vectorized(scene_dynamics, window)

        if 'ball_movement_distance' in temporal_features:
            movement_dist = temporal_features['ball_movement_distance']
            kernel = np.ones(5) / 5
            movement_ma = np.convolve(movement_dist, kernel, mode='same')
            spike_mask = movement_dist > movement_ma * 2
            temporal_features['ball_movement_spike'] = spike_mask.astype(int)
            for window in [10, 20]:
                kernel = np.ones(window)
                temporal_features[f'ball_events_frequency_{window}'] = np.convolve(spike_mask.astype(float), kernel, mode='same')

        return temporal_features

    def fast_rolling_std_vectorized(self, values: np.ndarray, window: int) -> np.ndarray:
        """å®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸé«˜é€Ÿç§»å‹•æ¨™æº–åå·®è¨ˆç®—"""
        n= len(values)

        padded_values = np.pad(values, window//2, mode='edge')
        kernel = np.ones(window)
        moving_sum = np.convolve(padded_values, kernel, mode='valid')
        moving_mean = moving_sum / window
        moving_sum_sq = np.convolve(padded_values**2, kernel, mode='valid')
        moving_mean_sq = moving_sum_sq / window
        variance = np.clip(moving_mean_sq - moving_mean**2, 0, None)

        if len(variance) > n:
            variance = variance[:n]
        return np.sqrt(variance)
    
    def create_court_features(self, features_df: pd.DataFrame, court_coords: Dict) -> pd.DataFrame:
            """ã‚³ãƒ¼ãƒˆåº§æ¨™ã‚’ä½¿ç”¨ã—ãŸç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
            if not court_coords:
                print("ã‚³ãƒ¼ãƒˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return features_df
            
            court_df = features_df.copy()
            print("ã‚³ãƒ¼ãƒˆåº§æ¨™ç‰¹å¾´é‡ã‚’ä½œæˆä¸­... (NumPyé«˜é€ŸåŒ–)")
            
            # --- ãƒœãƒ¼ãƒ«ä½ç½®ã®ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»å¤‰æ› ---
            if all(col in court_df.columns for col in ['ball_x', 'ball_y']):
                ball_court_coords = self.transform_to_court_coordinates(
                    court_df['ball_x'].values, 
                    court_df['ball_y'].values, 
                    court_coords
                )
                
                court_df['ball_court_x'] = ball_court_coords['x']
                court_df['ball_court_y'] = ball_court_coords['y']
                
                ball_court_x = ball_court_coords['x']
                ball_court_y = ball_court_coords['y']
                
                # --- â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒå¾©å…ƒã™ã‚‹ç‰¹å¾´é‡è¨ˆç®— â˜…â˜…â˜… ---
                
                # ã‚³ãƒ¼ãƒˆä¸Šã®ä½ç½®ã«åŸºã¥ãç‰¹å¾´é‡ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
                court_df['ball_in_court'] = ((ball_court_x >= 0) & (ball_court_x <= 1) &
                                            (ball_court_y >= 0) & (ball_court_y <= 1)).astype(int)
                
                # ã‚³ãƒ¼ãƒˆä¸Šã®é ˜åŸŸç‰¹å¾´é‡ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
                court_df['ball_in_front_court'] = (ball_court_y > 0.5).astype(int)
                court_df['ball_in_back_court'] = (ball_court_y <= 0.5).astype(int)
                court_df['ball_in_left_court'] = (ball_court_x <= 0.5).astype(int)
                court_df['ball_in_right_court'] = (ball_court_x > 0.5).astype(int)
                
                # å„ç¨®è·é›¢ã®è¨ˆç®—ï¼ˆNumPyé…åˆ—ã§ä¸€æ‹¬è¨ˆç®—ï¼‰
                net_y = 0.5
                court_df['ball_distance_to_net'] = np.abs(ball_court_y - net_y)
                court_df['ball_distance_to_left_line'] = ball_court_x
                court_df['ball_distance_to_right_line'] = 1 - ball_court_x
                court_df['ball_distance_to_sideline'] = np.minimum(
                    court_df['ball_distance_to_left_line'],
                    court_df['ball_distance_to_right_line']
                )
                court_df['ball_distance_to_front_baseline'] = 1 - ball_court_y
                court_df['ball_distance_to_back_baseline'] = ball_court_y
                court_df['ball_distance_to_baseline'] = np.minimum(
                    court_df['ball_distance_to_front_baseline'],
                    court_df['ball_distance_to_back_baseline']
                )
            
            # --- ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½ç½®ã®ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»å¤‰æ› ---
            for player in ['front', 'back']:
                x_col, y_col = f'player_{player}_x', f'player_{player}_y'
                if x_col in court_df.columns and y_col in court_df.columns:
                    player_court_coords = self.transform_to_court_coordinates(
                        court_df[x_col].values, court_df[y_col].values, court_coords
                    )
                    court_df[f'player_{player}_court_x'] = player_court_coords['x']
                    court_df[f'player_{player}_court_y'] = player_court_coords['y']
                    
                    player_court_x, player_court_y = player_court_coords['x'], player_court_coords['y']
                    
                    court_df[f'player_{player}_in_court'] = ((player_court_x >= 0) & (player_court_x <= 1) &
                                                            (player_court_y >= 0) & (player_court_y <= 1)).astype(int)
                    court_df[f'player_{player}_distance_to_net'] = np.abs(player_court_y - 0.5)
            
            # --- ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“ã®é–¢ä¿‚ç‰¹å¾´é‡ï¼ˆã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ï¼‰ ---
            if all(col in court_df.columns for col in ['player_front_court_x', 'player_back_court_x']):
                front_x, front_y = court_df['player_front_court_x'].values, court_df['player_front_court_y'].values
                back_x, back_y = court_df['player_back_court_x'].values, court_df['player_back_court_y'].values
                
                court_df['players_court_distance'] = np.sqrt((front_x - back_x)**2 + (front_y - back_y)**2)
                court_df['players_correct_sides'] = (front_y > back_y).astype(int)
            
            # --- ãƒœãƒ¼ãƒ«ã¨ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é–¢ä¿‚ç‰¹å¾´é‡ï¼ˆã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ï¼‰ ---
            if 'ball_court_x' in court_df.columns:
                ball_court_x, ball_court_y = court_df['ball_court_x'].values, court_df['ball_court_y'].values
                for player in ['front', 'back']:
                    if f'player_{player}_court_x' in court_df.columns:
                        player_x, player_y = court_df[f'player_{player}_court_x'].values, court_df[f'player_{player}_court_y'].values
                        court_df[f'ball_to_{player}_court_distance'] = np.sqrt((ball_court_x - player_x)**2 + (ball_court_y - player_y)**2)
            
            print(f"ã‚³ãƒ¼ãƒˆç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(court_df.columns) - len(features_df.columns)}ç‰¹å¾´é‡è¿½åŠ ")
            return court_df
        
    # ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»è¨ˆç®—ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def calculate_court_geometry(self, court_coords: Dict) -> Dict:
        """ã‚³ãƒ¼ãƒˆåº§æ¨™ã‹ã‚‰å¹¾ä½•å­¦çš„æƒ…å ±ã‚’è¨ˆç®—"""
        # åŸºæœ¬çš„ãªã‚³ãƒ¼ãƒˆæƒ…å ±ã‚’è¨ˆç®—
        top_left = np.array(court_coords['top_left_corner'])
        top_right = np.array(court_coords['top_right_corner'])
        bottom_left = np.array(court_coords['bottom_left_corner'])
        bottom_right = np.array(court_coords['bottom_right_corner'])
        
        # ã‚³ãƒ¼ãƒˆã®å¹…ã¨é«˜ã•
        court_width_top = np.linalg.norm(top_right - top_left)
        court_width_bottom = np.linalg.norm(bottom_right - bottom_left)
        court_height_left = np.linalg.norm(bottom_left - top_left)
        court_height_right = np.linalg.norm(bottom_right - top_right)
        
        court_info = {
            'width_top': court_width_top,
            'width_bottom': court_width_bottom,
            'height_left': court_height_left,
            'height_right': court_height_right,
            'avg_width': (court_width_top + court_width_bottom) / 2,
            'avg_height': (court_height_left + court_height_right) / 2
        }
        
        return court_info
    
    def transform_to_court_coordinates(self, x_coords: np.ndarray, y_coords: np.ndarray, 
                                     court_coords: Dict) -> Dict[str, np.ndarray]:
        """ç”»åƒåº§æ¨™ã‚’ã‚³ãƒ¼ãƒˆåº§æ¨™ç³»ã«å¤‰æ›ï¼ˆNumPyé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        tl, tr, bl, br = (np.array(court_coords[k]) for k in ['top_left_corner', 'top_right_corner', 'bottom_left_corner', 'bottom_right_corner'])
        
        court_x = np.full_like(x_coords, -1.0, dtype=float)
        court_y = np.full_like(y_coords, -1.0, dtype=float)
        valid_mask = ~(np.isnan(x_coords) | np.isnan(y_coords))
        if not np.any(valid_mask): return {'x': court_x, 'y': court_y}

        valid_x, valid_y = x_coords[valid_mask], y_coords[valid_mask]
        
        try:
            top_ratio = (valid_x - tl[0]) / (tr[0] - tl[0]) if (tr[0] - tl[0]) != 0 else np.full_like(valid_x, 0.5)
            bottom_ratio = (valid_x - bl[0]) / (br[0] - bl[0]) if (br[0] - bl[0]) != 0 else np.full_like(valid_x, 0.5)
            y_ratio = (valid_y - (top_ratio * tr[1] + (1 - top_ratio) * tl[1])) / \
                      ((bottom_ratio * br[1] + (1 - bottom_ratio) * bl[1]) - (top_ratio * tr[1] + (1 - top_ratio) * tl[1]))

            valid_court_x = y_ratio * bottom_ratio + (1 - y_ratio) * top_ratio
            valid_court_y = y_ratio
            
            court_x[valid_mask] = np.clip(valid_court_x, -0.5, 1.5)
            court_y[valid_mask] = np.clip(valid_court_y, -0.5, 1.5)
        except (ZeroDivisionError, ValueError):
            pass
        
        return {'x': court_x, 'y': court_y}
    
    def handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¬ æå€¤ã‚’å‡¦ç†ï¼ˆå®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰"""
        df_cleaned = df.copy()
        position_columns = ['ball_x', 'ball_y', 'player_front_x', 'player_front_y', 'player_back_x', 'player_back_y']
        
        for col in position_columns:
            if col in df_cleaned.columns:
                values = df_cleaned[col].values
                mask = pd.isna(values)
                if np.any(mask):
                    valid_indices = np.where(~mask)[0]
                    if len(valid_indices) > 0:
                        first_valid = values[valid_indices[0]]
                        values[:valid_indices[0]] = first_valid
                        for i in range(1, len(values)):
                            if mask[i]: values[i] = values[i-1]
                    else:
                        values[:] = 0
                    df_cleaned[col] = values
        
        numeric_columns = df_cleaned.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if col not in position_columns:
                df_cleaned[col] = np.nan_to_num(df_cleaned[col].values, nan=0)
        
        return df_cleaned
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ»çµ±åˆãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def extract_all_features(self, video_name: str = None) -> pd.DataFrame:
        """ã™ã¹ã¦ã®å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦DataFrameã‚’çµ±åˆ"""
        print("=== ç‰¹å¾´é‡æŠ½å‡ºé–‹å§‹ ===")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        print("1. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        phase_annotations = self.load_phase_annotations(video_name)
        tracking_features = self.load_tracking_features(video_name)
        court_coordinates = self.load_court_coordinates(video_name)
        
        if not phase_annotations:
            print("âŒ å±€é¢ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        if not tracking_features:
            print("âŒ ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒãƒ³ã‚°
        print("\n2. ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒãƒ³ã‚°ä¸­...")
        matched_data = self.match_video_data(phase_annotations, tracking_features, court_coordinates)
        
        if not matched_data:
            print("âŒ ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        # å„å‹•ç”»ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        print("\n3. ç‰¹å¾´é‡æŠ½å‡ºä¸­...")
        all_features = []
        total_videos = len(matched_data)
        print(f"å‡¦ç†å¯¾è±¡å‹•ç”»æ•°: {total_videos}")
        
        for i, (video_name, phase_data, tracking_data, court_coords) in enumerate(tqdm(matched_data, desc="å‹•ç”»åˆ¥ç‰¹å¾´é‡æŠ½å‡º"), 1):
            print(f"\n--- å‹•ç”»å‡¦ç†é€²æ—: [{i}/{total_videos}] - {video_name} ---")
            
            try:
                features_df = self.extract_features_from_video(
                    video_name, phase_data, tracking_data, court_coords
                )
                
                if not features_df.empty:
                    all_features.append(features_df)
                    print(f"âœ… ç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {len(features_df)}è¡Œ")
                else:
                    print(f"âš ï¸  ç‰¹å¾´é‡ãŒç©ºã§ã™")
                    
            except Exception as e:
                print(f"âŒ ç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # ç‰¹å¾´é‡ã‚’çµ±åˆ
        if all_features:
            print(f"\n4. ç‰¹å¾´é‡çµ±åˆä¸­... ({len(all_features)}å‹•ç”»)")
            combined_features = pd.concat(all_features, ignore_index=True)
            
            print(f"âœ… çµ±åˆå®Œäº†:")
            print(f"   ç·è¡Œæ•°: {len(combined_features)}")
            print(f"   ç·ç‰¹å¾´é‡æ•°: {len(combined_features.columns)}")
            print(f"   å‹•ç”»æ•°: {combined_features['video_name'].nunique()}")
            
            # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã‚’è¡¨ç¤º
            print("\nğŸ“Š å…¨ä½“ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:")
            label_counts = combined_features['label'].value_counts().sort_index()
            for label_id, count in label_counts.items():
                phase_name = self.phase_labels[label_id] if label_id < len(self.phase_labels) else f"Unknown_{label_id}"
                percentage = count / len(combined_features) * 100
                print(f"   {label_id} ({phase_name}): {count}ãƒ•ãƒ¬ãƒ¼ãƒ  ({percentage:.1f}%)")
            
            return combined_features
        else:
            print("âŒ æŠ½å‡ºã§ããŸç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
    
    def save_features(self, features_df: pd.DataFrame, filename: str = None) -> str:
        """ç‰¹å¾´é‡ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if features_df.empty:
            print("âš ï¸  ä¿å­˜ã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"tennis_features_{timestamp}.csv"
        
        output_path = self.features_dir / filename
        
        try:
            features_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"âœ… ç‰¹å¾´é‡ä¿å­˜å®Œäº†: {output_path}")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_path.stat().st_size / (1024*1024):.2f} MB")
            return str(output_path)
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def save_feature_info(self, features_df: pd.DataFrame, filename: str = None) -> str:
        """ç‰¹å¾´é‡ã®è©³ç´°æƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if features_df.empty:
            print("âš ï¸  ä¿å­˜ã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return ""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"tennis_features_info_{timestamp}.json"
        
        output_path = self.features_dir / filename
        
        try:
            # ç‰¹å¾´é‡æƒ…å ±ã‚’ä½œæˆ
            feature_info = {
                'creation_time': datetime.now().isoformat(),
                'total_frames': len(features_df),
                'total_features': len(features_df.columns),
                'videos': features_df['video_name'].nunique(),
                'video_list': features_df['video_name'].unique().tolist(),
                'phase_labels': self.phase_labels,
                'label_distribution': features_df['label'].value_counts().sort_index().to_dict(),
                'feature_columns': features_df.columns.tolist(),
                'feature_types': {
                    'temporal': [col for col in features_df.columns if any(suffix in col for suffix in ['_ma_', '_std_', '_max_', '_min_', '_diff', '_trend_', '_cv_'])],
                    'contextual': [col for col in features_df.columns if any(keyword in col for keyword in ['activity', 'interaction', 'confidence', 'distance', 'movement', 'stability', 'dynamics', 'quality'])],
                    'court': [col for col in features_df.columns if 'court' in col],
                    'basic': [col for col in features_df.columns if col.startswith(('ball_', 'player_')) and not any(suffix in col for suffix in ['_ma_', '_std_', '_max_', '_min_', '_diff', '_trend_', '_cv_', '_court'])]
                },
                'data_quality': {
                    'interpolated_frames': int(features_df.get('interpolated', pd.Series([False] * len(features_df))).sum()),
                    'interpolation_rate': float(features_df.get('interpolated', pd.Series([False] * len(features_df))).mean()),
                    'missing_values': features_df.isnull().sum().to_dict()
                }
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(feature_info, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… ç‰¹å¾´é‡æƒ…å ±ä¿å­˜å®Œäº†: {output_path}")
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def run_feature_extraction(self, video_name: str = None, save_results: bool = True) -> Tuple[pd.DataFrame, str, str]:
        """ç‰¹å¾´é‡æŠ½å‡ºã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ"""
        print("ğŸ¾ ãƒ†ãƒ‹ã‚¹å‹•ç”»ç‰¹å¾´é‡æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹")
        print("=" * 50)
        
        # ç‰¹å¾´é‡æŠ½å‡º
        features_df = self.extract_all_features(video_name)
        
        if features_df.empty:
            print("âŒ ç‰¹å¾´é‡æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame(), "", ""
        
        feature_file = ""
        info_file = ""
        
        if save_results:
            print("\n5. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
            feature_file = self.save_features(features_df)
            info_file = self.save_feature_info(features_df)
        
        print("\nğŸ‰ ç‰¹å¾´é‡æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹å®Œäº†!")
        print("=" * 50)
        
        return features_df, feature_file, info_file
    
    def analyze_features(self, features_df: pd.DataFrame):
        """ç‰¹å¾´é‡ã®çµ±è¨ˆåˆ†æã‚’è¡¨ç¤º"""
        if features_df.empty:
            print("âš ï¸  åˆ†æã™ã‚‹ç‰¹å¾´é‡ãŒç©ºã§ã™")
            return
        
        print("\nğŸ“ˆ ç‰¹å¾´é‡åˆ†æçµæœ")
        print("=" * 30)
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(features_df):,}")
        print(f"   ç‰¹å¾´é‡æ•°: {len(features_df.columns)}")
        print(f"   å‹•ç”»æ•°: {features_df['video_name'].nunique()}")
        
        # å‹•ç”»åˆ¥çµ±è¨ˆ
        print(f"\nğŸ¬ å‹•ç”»åˆ¥ãƒ•ãƒ¬ãƒ¼ãƒ æ•°:")
        video_counts = features_df['video_name'].value_counts()
        for video, count in video_counts.items():
            print(f"   {video}: {count:,}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        
        # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ
        print(f"\nğŸ·ï¸  ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:")
        label_counts = features_df['label'].value_counts().sort_index()
        for label_id, count in label_counts.items():
            phase_name = self.phase_labels[label_id] if label_id < len(self.phase_labels) else f"Unknown_{label_id}"
            percentage = count / len(features_df) * 100
            print(f"   {label_id} ({phase_name}): {count:,}ãƒ•ãƒ¬ãƒ¼ãƒ  ({percentage:.1f}%)")
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ª
        if 'interpolated' in features_df.columns:
            interpolated_count = features_df['interpolated'].sum()
            interpolation_rate = interpolated_count / len(features_df) * 100
            print(f"\nğŸ”§ ãƒ‡ãƒ¼ã‚¿å“è³ª:")
            print(f"   è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {interpolated_count:,}")
            print(f"   è£œé–“ç‡: {interpolation_rate:.1f}%")
        
        # æ¬ æå€¤
        missing_counts = features_df.isnull().sum()
        missing_cols = missing_counts[missing_counts > 0]
        if len(missing_cols) > 0:
            print(f"\nâš ï¸  æ¬ æå€¤:")
            for col, count in missing_cols.items():
                rate = count / len(features_df) * 100
                print(f"   {col}: {count:,} ({rate:.1f}%)")
        else:
            print(f"\nâœ… æ¬ æå€¤: ãªã—")

if __name__ == "__main__":
    # ç‰¹å¾´é‡æŠ½å‡ºå™¨ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    # training_dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜éšå±¤ã«ã‚ã‚‹ã‹ã€
    # ã‚‚ã—ãã¯é©åˆ‡ãªãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
    # ä¾‹: extractor = TennisFeatureExtractor(training_data_dir="path/to/your/training_data")
    extractor = TennisFeatureExtractor(training_data_dir="training_data")

    # ç‰¹å®šã®å‹•ç”»ã®ã¿ã‚’å‡¦ç†ã™ã‚‹å ´åˆ (ä¾‹: "video1")
    # video_to_process = "your_video_name_here" # å¿…è¦ã«å¿œã˜ã¦å‹•ç”»åã‚’æŒ‡å®š
    video_to_process = None # Noneã®å ´åˆã€å…¨å‹•ç”»ã‚’å‡¦ç†

    # ç‰¹å¾´é‡æŠ½å‡ºã‚’å®Ÿè¡Œ
    # save_results=True ã«ã™ã‚‹ã¨ã€æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡ãŒCSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã™ã€‚
    # Falseã«ã™ã‚‹ã¨ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚
    features_dataframe, saved_feature_path, saved_info_path = extractor.run_feature_extraction(
        video_name=video_to_process,
        save_results=True
    )

    if not features_dataframe.empty:
        print(f"\n--- ç‰¹å¾´é‡æŠ½å‡ºæˆåŠŸ ---")
        if saved_feature_path:
            print(f"ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {saved_feature_path}")
        if saved_info_path:
            print(f"ç‰¹å¾´é‡æƒ…å ±ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {saved_info_path}")

        # æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡ã®åˆ†æ
        extractor.analyze_features(features_dataframe)
    else:
        print("\n--- ç‰¹å¾´é‡æŠ½å‡ºå¤±æ•— ---")
        print("å‡¦ç†ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒãªã‹ã£ãŸã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    print("\nãƒ¡ã‚¤ãƒ³å‡¦ç†å®Œäº†")
