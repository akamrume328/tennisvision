  # --- 実験1: ベースラインモデル ---
  # 狙い：最もシンプルで高速なモデル。他の複雑なモデルと比較するための基準点。
  - name: "Baseline_Simple_LSTM_128"
    model_type: "simple"
    lstm_units: [128]
    dropout_rate: 0.3
    enable_confidence_weighting: true
    batch_size: 64

  # --- 実験2: 双方向モデル（高性能が期待される本命） ---
  # 狙い：過去と未来の両方の情報を使うため、精度向上が最も期待できる構成の一つ。
  - name: "Main_Bidirectional_LSTM_128x64"
    model_type: "bidirectional"
    lstm_units: [128, 64] # 2層の双方向LSTM
    dropout_rate: 0.3
    enable_confidence_weighting: true
    batch_size: 64

  # --- 実験3: 深層モデル（より複雑な特徴を捉える） ---
  # 狙い：層を深くすることで、より複雑な時間的パターンを学習できるか検証する。
  - name: "Deep_Stacked_LSTM_128x3"
    model_type: "stacked"
    lstm_units: [128, 128, 64] # 3層のLSTM
    dropout_rate: 0.4 # 層が深いので過学習防止にドロップアウトを少し強める
    enable_confidence_weighting: true
    batch_size: 32 # モデルが大きいためバッチサイズを少し小さくする

  # --- 実験4: ワイドモデル（表現力を高める） ---
  # 狙い：層は深くないが、隠れ層のユニット数を増やしてモデルの表現力を高める。
  - name: "Wide_Simple_LSTM_256"
    model_type: "simple"
    lstm_units: [256]
    dropout_rate: 0.3
    enable_confidence_weighting: true
    batch_size: 64

  # --- 実験5: 正則化強化モデル ---
  # 狙い：本命の双方向モデルで過学習が見られる場合に試す。ドロップアウトを強くして汎化性能の向上を狙う。
  - name: "Regularized_BiLSTM_128x64"
    model_type: "bidirectional"
    lstm_units: [128, 64]
    dropout_rate: 0.5 # ドロップアウト率を高めに設定
    enable_confidence_weighting: true
    batch_size: 64
  
  # --- 実験6: 信頼度重み付けの効果検証 ---
  # 狙い：ベースラインモデルから信頼度重み付け機能だけをオフにし、この機能が精度にどれだけ貢献しているかを比較する。
  - name: "Baseline_NoConfidenceWeight"
    model_type: "simple"
    lstm_units: [128]
    dropout_rate: 0.3
    enable_confidence_weighting: false # 信頼度重み付けを無効化
    batch_size: 64

      # --- 実験7: 軽量モデル ---
  # 狙い：ユニット数を64に減らし、パラメータ数を大幅に削減。速度を優先しつつ、どの程度の精度を維持できるか確認する。
  - name: "Fast_Simple_LSTM_64"
    model_type: "simple"
    lstm_units: [64]
    dropout_rate: 0.2 # モデルが単純なのでドロップアウトを少し弱める
    enable_confidence_weighting: true
    batch_size: 128 # モデルが軽いのでバッチサイズを大きくしてGPU効率を上げる

  # --- 実験8: 超軽量モデル（最速候補） ---
  # 狙い：ユニット数を32まで削減し、速度を最優先。精度は落ちる可能性があるが、最速のベースラインとして性能を測定する。
  - name: "Fastest_Simple_LSTM_32"
    model_type: "simple"
    lstm_units: [32]
    dropout_rate: 0.2
    enable_confidence_weighting: true
    batch_size: 128

  # --- 実験9: 短期シーケンスモデル ---
  # 狙い：入力する時系列の長さを半分（30→15）にし、計算量を削減。短い情報からでも分類可能か検証する。
  # 注意：この設定は共通設定の `sequence_length` を上書きします。
  - name: "Fast_ShortSeq_LSTM_64"
    model_type: "simple"
    sequence_length: 15 # シーケンス長を短くする
    lstm_units: [64]
    dropout_rate: 0.2
    enable_confidence_weighting: true
    batch_size: 128

  # --- グループ1: 最高の精度を追求する ---
  # 前回のNo.2モデル構造(Wide)とNo.1のシーケンス長を組み合わせ、最高精度を狙う本命モデル。
  - name: "AccuracyKing_Wide_Seq15_LSTM256"
    model_type: "simple"
    sequence_length: 15
    lstm_units: [256]
    dropout_rate: 0.3
    enable_confidence_weighting: false # 効果が薄そうなのでオフ
    batch_size: 64

  # 前回は振るわなかった双方向モデルが、短いシーケンスで性能を発揮するかを再検証する。
  - name: "AccuracyTry_BiLSTM_Seq15_LSTM128"
    model_type: "bidirectional"
    sequence_length: 15
    lstm_units: [128, 64]
    dropout_rate: 0.3
    enable_confidence_weighting: false
    batch_size: 64

  # --- グループ2: 最適なシーケンス長を探る ---
  # 前回の王者`Fast_ShortSeq_LSTM_64`(Seq15)を基準に、さらに短いシーケンスを試す。
  - name: "SeqHunt_Seq10_LSTM64"
    model_type: "simple"
    sequence_length: 10
    lstm_units: [64]
    dropout_rate: 0.2
    enable_confidence_weighting: false
    batch_size: 128

  # Seq15を基準に、少し長いシーケンスを試す。
  - name: "SeqHunt_Seq20_LSTM64"
    model_type: "simple"
    sequence_length: 20
    lstm_units: [64]
    dropout_rate: 0.2
    enable_confidence_weighting: false
    batch_size: 128
    
  # --- グループ3: 速度と精度の限界を探る ---
  # 最速モデル構造(Fastest)に、最高のシーケンス長(15)を組み合わせ、速度と精度の究極のバランスを探る。
  - name: "SpeedKing_Fastest_Seq15_LSTM32"
    model_type: "simple"
    sequence_length: 15
    lstm_units: [32]
    dropout_rate: 0.2
    enable_confidence_weighting: false
    batch_size: 128

    # シーケンス長を45フレーム（1.5秒相当）に伸ばした場合。
  - name: "LongSeq_Seq45_LSTM64"
    model_type: "simple"
    sequence_length: 45
    lstm_units: [64]
    dropout_rate: 0.2
    enable_confidence_weighting: false
    batch_size: 128

  # シーケンス長を60フレーム（2秒相当）に伸ばした場合。
  - name: "LongSeq_Seq60_LSTM64"
    model_type: "simple"
    sequence_length: 60
    lstm_units: [64]
    dropout_rate: 0.2
    enable_confidence_weighting: false
    batch_size: 128
